{"version":3,"file":"unicity-sdk.js","mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;;;;;;;;;;;;;;;;;;ACVA;AACA;AACA;AACA;AACA;AAC0C;AACqB;AACP;AACxD;AACO;AACP;AACA;AACA,gCAAgC,wDAAI,YAAY,gEAAW;AAC3D,mBAAmB;AACnB;AACA;AACO;AACP,6BAA6B,qEAAW,GAAG,+BAA+B;AAC1E,aAAa;AACb;AACA,yC;;;;;;;;;;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACsD;AACO;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD;AACnD,qCAAqC;AACrC,8BAA8B;AAC9B,iBAAiB,kDAAO,KAAK;AAC7B,+BAA+B;AAC/B,aAAa;AACb;AACA;AACA,YAAY,uCAAuC;AACnD,kCAAkC;AAClC,8BAA8B;AAC9B;AACA;AACA,+BAA+B;AAC/B,kCAAkC,wBAAwB;AAC1D;AACA;AACA;AACA,4BAA4B;AAC5B,sBAAsB;AACtB;AACA;AACA,sDAAsD;AACtD,gCAAgC;AAChC,6BAA6B;AAC7B,qCAAqC;AACrC,iCAAiC;AACjC,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sBAAsB;AAC1C;AACA;AACA;AACA,iCAAiC,kBAAkB;AACnD;AACA;AACA;AACA,gCAAgC,gBAAgB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,qBAAqB;AACtD;AACA,wBAAwB,gDAAgD;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,qBAAqB;AACtD;AACA,2BAA2B;AAC3B,wBAAwB,+BAA+B;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE;AACjE;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,sDAAsD;AACtD;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,iDAAM;AACxB,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,kDAAO;AACxB,4DAA4D;AAC5D;AACA;AACA,2BAA2B,QAAQ;AACnC;AACA,wBAAwB,aAAa;AACrC;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA,sDAAsD,OAAO;AAC7D;AACA;AACA;AACA;AACA;AACA,4BAA4B,gBAAgB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C,wDAAwD;AACxD,iBAAiB,kDAAO;AACxB;AACA;AACA,iCAAiC,eAAe;AAChD;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY;AACpC;AACA;AACA,gCAAgC,gBAAgB;AAChD;AACA;AACA,4BAA4B,oBAAoB;AAChD;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACO;AACP,IAAI,0DAAa;AACjB,IAAI,yDAAc;AAClB;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,WAAW,oDAAO;AAClB;AACA,aAAa,mBAAmB;AAChC,KAAK;AACL;AACA,iC;;;;;;;;;;;;;;;;;;;;ACjYkD;AAC6C;AAC/F;AACA,cAAc,sDAAe;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,QAAQ;AACrC,6BAA6B,QAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,cAAc;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,IAAI,iDAAM;AACV,IAAI,iDAAM;AACV;AACA;AACA;AACA,gBAAgB,sDAAW,CAAC,sDAAW;AACvC,YAAY,8CAA8C;AAC1D;AACA;AACA;AACA,sBAAsB,sDAAW;AACjC;AACA,4CAA4C;AAC5C;AACA,kBAAkB,sDAAW;AAC7B,aAAa,sDAAW;AACxB,oBAAoB,UAAU;AAC9B;AACA,iBAAiB,sDAAW;AAC5B;AACA,gCAAgC,sDAAW;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,IAAI,iDAAM;AACV,IAAI,iDAAM;AACV;AACA;AACA;AACA;AACA;AACA,yBAAyB,OAAO,SAAS,sDAAW;AACpD;AACA;AACA;AACA,uBAAuB,mBAAmB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,6EAA6E;AACjG;AACA;AACO;AACP,IAAI,yDAAc;AAClB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,YAAY,mCAAmC;AAC/C,IAAI,iDAAM;AACV;AACA,2CAA2C,sDAAW;AACtD;AACA,0CAA0C;AAC1C;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,WAAW;AAC/B;AACA,wBAAwB,OAAO;AAC/B;AACA;AACA,mBAAmB,gDAAG;AACtB;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD;AACzD;AACA,iCAAiC,0DAAa;AAC9C,mCAAmC;AACnC,iDAAiD;AACjD,iBAAiB;AACjB;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,4CAA4C;AAC1F;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,8CAA8C,kDAAkD;AAChG;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,yC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5LA;AACA;AACA;AACA;AACA;AACA;AACA;AAC8C;AACyF;AACvI;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC,yCAAyC;AACzC,yCAAyC;AACzC,yCAAyC;AACzC,yCAAyC;AACzC,yCAAyC;AACzC,yCAAyC;AACzC,yCAAyC;AACzC,yCAAyC;AACzC,yCAAyC;AACzC,kCAAkC;AAClC,kCAAkC;AAClC,yCAAyC;AACzC,mCAAmC;AACnC;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC,8BAA8B;AAC9B,mCAAmC;AACnC;AACA;AACA;AACA;AACA,gCAAgC;AAChC;AACA;AACA,mCAAmC;AACnC;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA,uDAAuD;AACvD,2CAA2C;AAC3C;AACA;AACA,2BAA2B;AAC3B,8BAA8B;AAC9B,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,WAAW,yDAAc;AACzB;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA,QAAQ,4DAAO;AACf;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,sDAAsD;AAC7D;AACA;AACA,YAAY,uCAAuC;AACnD;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA,cAAc,kDAAO;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C;AAC9C,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,kCAAkC,0DAAe,eAAe,0DAAe;AAC/E;AACA;AACA;AACA,0BAA0B,0DAAe,UAAU,0DAAe;AAClE,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,sDAAW;AACtB;AACA;AACA;AACA;AACA,uBAAuB,0DAAe,SAAS,0DAAe;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,0DAAe,QAAQ,0DAAe;AAC7D;AACA;AACA,kBAAkB,0DAAe,sBAAsB,0DAAe;AACtE;AACA,mC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxcA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA,kDAAkD;AAClD;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,aAAa;AACxD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,kBAAkB;AACtC;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,+BAA+B;AAC/B;AACA,qCAAqC;AACrC;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,SAAS;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,oBAAoB,mBAAmB;AACvC;AACA;AACA;AACA;AACA;AACA,6BAA6B,mBAAmB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,oBAAoB,cAAc;AAClC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,0DAA0D;AAC1D;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,kBAAkB,SAAS;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,uBAAuB,4BAA4B;AACnD;AACO;AACP;AACA,0CAA0C;AAC1C,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B,0BAA0B;AAC1B,eAAe;AACf;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;AACA;AACA,mCAAmC;AACnC,iBAAiB;AACjB;AACA;AACA,mCAAmC;AACnC,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D;AACnD,8DAA8D;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,WAAW,WAAW,YAAY,IAAI;AACpD,kCAAkC,oBAAoB,IAAI,aAAa,GAAG;AAC1E;AACA,kCAAkC,UAAU,IAAI,SAAS;AACzD,kCAAkC,oBAAoB,IAAI,SAAS;AACnE,kCAAkC,2BAA2B;AAC7D,kCAAkC,wBAAwB;AAC1D;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;AC3VA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAC4D;AAC5D;AACkH;AAClH;AAC2N;AAC3N;AACA;AACA,QAAQ,gDAAK;AACb;AACA,QAAQ,gDAAK;AACb;AACA;AACA,iBAAiB,wDAAa;AAC9B,IAAI,yDAAc;AAClB;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,YAAY,cAAc;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,SAAS;AACpC;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,oBAAoB,SAAS;AAC7B;AACA;AACA;AACA;AACA;AACA,wBAAwB,8DAAmB;AAC3C;AACA;AACA;AACA,2CAA2C,8DAAmB;AAC9D,sBAAsB,8DAAmB;AACzC;AACA,SAAS;AACT;AACA;AACA,oBAAoB,SAAS;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,SAAS;AAC7B;AACA;AACA,sBAAsB,8DAAmB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,oBAAoB,SAAS;AAC7B;AACA;AACA;AACA;AACA,mBAAmB,0DAAe;AAClC,SAAS;AACT,KAAK;AACL;AACA;AACA,gBAAgB,+BAA+B;AAC/C,qBAAqB,sDAAW;AAChC,gBAAgB,+BAA+B;AAC/C;AACA;AACA,gBAAgB,2BAA2B;AAC3C,gBAAgB,2BAA2B;AAC3C;AACA;AACA,iBAAiB;AACjB,KAAK;AACL;AACA,gBAAgB,uBAAuB;AACvC;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,WAAW,qDAAU,CAAC,0DAAe;AACrC;AACA;AACA;AACA;AACO;AACP;AACA,YAAY,KAAK,SAAS;AAC1B,eAAe,kDAAK;AACpB;AACA;AACA;AACA,mBAAmB,sDAAW;AAC9B,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,gBAAgB,OAAO;AACvB,8BAA8B;AAC9B,kCAAkC;AAClC,oDAAoD;AACpD;AACA;AACA,gCAAgC;AAChC,8CAA8C;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,kDAAO;AACtB;AACA;AACA;AACA;AACA,gBAAgB,uEAAuE;AACvF;AACA,gBAAgB,kDAAO;AACvB,sBAAsB,qDAAU;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,0DAAe,CAAC,sDAAW;AACjD;AACA;AACA;AACA;AACA;AACA,kBAAkB,gDAAG,UAAU;AAC/B,QAAQ,mDAAQ,8BAA8B;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,mDAAQ;AACjC,gBAAgB,sBAAsB;AACtC;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,iBAAiB;AACjB,KAAK;AACL;AACA;AACA,4BAA4B,mDAAQ;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,OAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,0DAAa;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,sDAAW;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,oDAAS;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,IAAI;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,yBAAyB;AAC7C,oBAAoB,yBAAyB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA,oBAAoB,yBAAyB;AAC7C,0DAA0D;AAC1D,qCAAqC;AACrC;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,yBAAyB;AAC7C,oBAAoB,yBAAyB;AAC7C,0DAA0D;AAC1D;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,aAAa;AACjC,YAAY,mDAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,wBAAwB;AACtD,kBAAkB,uBAAuB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,aAAa;AACjC,YAAY,mDAAQ;AACpB,6BAA6B;AAC7B,8BAA8B,wBAAwB;AACtD;AACA,wBAAwB,uBAAuB;AAC/C,sBAAsB,iBAAiB;AACvC,sBAAsB,iBAAiB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,OAAO;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,6BAA6B;AACjD;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA,oBAAoB,6BAA6B;AACjD;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA,YAAY,gDAAK;AACjB;AACA;AACA;AACA;AACA,YAAY,gDAAK;AACjB,mBAAmB,qDAAU;AAC7B;AACA;AACA;AACA;AACA;AACA,sDAAsD;AACtD,YAAY,mBAAmB;AAC/B,iBAAiB,+CAAI;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,wDAAa;AAC9B,IAAI,yDAAc;AAClB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL,2BAA2B,qBAAqB;AAChD;AACA;AACA;AACA;AACA,YAAY,QAAQ;AACpB;AACA,+BAA+B,sCAAsC;AACrE;AACO;AACP;AACA,YAAY,8CAA8C;AAC1D,wCAAwC;AACxC,8CAA8C;AAC9C;AACA,eAAe,gDAAG;AAClB;AACA;AACA,eAAe,mDAAM;AACrB;AACA,YAAY,2FAA2F;AACvG;AACA;AACA;AACA;AACA,wBAAwB,kDAAW;AACnC,YAAY,gDAAK;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,0DAAe;AACzC,qBAAqB,kDAAO;AAC5B;AACA,mDAAmD;AACnD;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,0DAAe;AACnD;AACA;AACA;AACA;AACA;AACA,YAAY,mDAAQ,4BAA4B;AAChD,YAAY,mDAAQ,4BAA4B;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,sDAAW;AAC7B;AACA;AACA;AACA;AACA;AACA,oBAAoB,OAAO,YAAY,sDAAW;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sBAAsB;AAC1C,oCAAoC,sDAAW,uBAAuB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC,sCAAsC;AACtC,qCAAqC;AACrC,kEAAkE;AAClE;AACA,sDAAsD;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,qDAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,qDAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,6DAAgB;AAC3C,mBAAmB,2DAAc;AACjC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA,uCAAuC;AACvC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,0DAA0D;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sDAAW;AAC/B;AACA;AACA,iCAAiC;AACjC,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,0DAAe,SAAS;AAChD,yDAAyD;AACzD;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;AACA;AACA,uBAAuB,kDAAO;AAC9B;AACA;AACA;AACA;AACA,QAAQ,mDAAQ;AAChB;AACA,eAAe,0DAAe;AAC9B;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC,cAAc,mCAAmC,QAAQ;AACzD;AACA,yBAAyB;AACzB,kBAAkB,sDAAW;AAC7B;AACA;AACA,sBAAsB,sDAAW;AACjC;AACA;AACA;AACA;AACA,sDAAsD;AACtD;AACA;AACA;AACA;AACA,kEAAkE;AAClE,0BAA0B,sDAAW,sBAAsB;AAC3D;AACA,qBAAqB,sDAAW,eAAe;AAC/C,yBAAyB;AACzB;AACA;AACA;AACA,wCAAwC;AACxC;AACA,wBAAwB;AACxB,gCAAgC;AAChC,yDAAyD;AACzD,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA,kDAAkD;AAClD;AACA;AACA,oEAAoE;AACpE;AACA;AACA,uCAAuC;AACvC,+BAA+B;AAC/B;AACA,sDAAsD;AACtD;AACA,iBAAiB;AACjB;AACA,6BAA6B;AAC7B,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,cAAc,mCAAmC;AACjE;AACA,qBAAqB,yDAAc;AACnC,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,sDAAW;AAC7B,oBAAoB,sDAAW;AAC/B,gBAAgB,wBAAwB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,kDAAO;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,OAAO;AACvB,0CAA0C;AAC1C,4BAA4B;AAC5B,iCAAiC;AACjC,iCAAiC;AACjC,0EAA0E;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE;AACxE;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,0BAA0B,iBAAiB;AAC3C;AACA,kBAAkB;AAClB,2DAA2D;AAC3D;AACA;AACA;AACA,uCAAuC;AACvC,iCAAiC;AACjC,iCAAiC;AACjC,6BAA6B;AAC7B,8BAA8B;AAC9B,4CAA4C;AAC5C;AACA,sBAAsB;AACtB,iCAAiC;AACjC,+BAA+B;AAC/B,8BAA8B;AAC9B,kCAAkC;AAClC,+BAA+B;AAC/B,gCAAgC;AAChC,8BAA8B;AAC9B,8BAA8B;AAC9B,oCAAoC;AACpC,+BAA+B;AAC/B,wCAAwC;AACxC,+BAA+B;AAC/B,gCAAgC;AAChC,uCAAuC;AACvC,uCAAuC;AACvC;AACA,yBAAyB,SAAS;AAClC,+BAA+B;AAC/B,sCAAsC;AACtC,yCAAyC;AACzC,6CAA6C;AAC7C,oCAAoC;AACpC,oCAAoC;AACpC,qCAAqC;AACrC,yCAAyC;AACzC,0CAA0C;AAC1C;AACA,iBAAiB;AACjB;AACA;AACA;AACA,2CAA2C;AAC3C,uCAAuC;AACvC;AACA,iCAAiC;AACjC,sCAAsC;AACtC,oCAAoC;AACpC,sCAAsC;AACtC,kCAAkC;AAClC,uCAAuC;AACvC,+CAA+C,kBAAkB;AACjE,yCAAyC;AACzC,2CAA2C;AAC3C,qBAAqB,2BAA2B;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,IAAI,0DAAa;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,mCAAmC;AACnC,2BAA2B;AAC3B,gCAAgC;AAChC,mCAAmC;AACnC,mCAAmC;AACnC,mEAAmE;AACnE,mCAAmC;AACnC,2BAA2B;AAC3B,2BAA2B;AAC3B,mCAAmC;AACnC,gCAAgC;AAChC,gCAAgC;AAChC,gCAAgC;AAChC,mCAAmC;AACnC,gCAAgC;AAChC,8BAA8B;AAC9B,gBAAgB,iBAAiB,uBAAuB;AACxD,4BAA4B;AAC5B,8BAA8B;AAC9B,sCAAsC;AACtC,wCAAwC;AACxC,gDAAgD;AAChD,uCAAuC;AACvC,wBAAwB,0DAAa;AACrC,gCAAgC;AAChC,iBAAiB;AACjB;AACA;AACA,uC;;;;;;;;;;;;;;;;;;;;;;;;;ACjsCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAC4C;AACM;AACD;AACsB;AACd;AAC4D;AACrD;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC;AAChC,kCAAkC;AAClC,gBAAgB,0DAAI;AACpB,gBAAgB,0DAAI;AACpB,iBAAiB,0DAAI;AACrB,iBAAiB,0DAAI;AACrB,iBAAiB,0DAAI;AACrB,iBAAiB,0DAAI;AACrB,kBAAkB,0DAAI;AACtB,kBAAkB,0DAAI;AACtB,kBAAkB,0DAAI;AACtB,gBAAgB,0DAAI;AACpB,gBAAgB,0DAAI;AACpB,iBAAiB,0DAAI;AACrB;AACA;AACA;AACA;AACA,aAAa,2DAAK,qCAAqC,eAAe;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,YAAY;AACxB;AACA;AACA,2CAA2C;AAC3C,0CAA0C,KAAK,cAAc;AAC7D;AACA;AACA;AACO,kBAAkB,6DAAW;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E;AAC7E;AACA;AACA,qBAAqB,yDAAG;AACxB,qBAAqB,yDAAG;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,SAAS;AACT,KAAK;AACL,CAAC,EAAE,sDAAM;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,0DAAM;AAC3B,eAAe,+DAAW;AAC1B;AACA;AACA,WAAW,0DAAM,CAAC,+DAAW;AAC7B;AACA;AACA;AACA,wBAAwB,mEAAe;AACvC,oBAAoB,yDAAG;AACvB,oBAAoB,yDAAG;AACvB;AACA;AACA;AACA;AACA,2DAA2D;AAC3D,sCAAsC,aAAa;AACnD;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,4DAAQ,2BAA2B;AACvC;AACA,wCAAwC;AACxC,wBAAwB;AACxB;AACA,sBAAsB;AACtB,oCAAoC;AACpC;AACA;AACA;AACA,YAAY,+DAAe;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD;AAClD;AACA;AACA;AACA;AACA;AACA,oDAAoD,gEAAW;AAC/D,cAAc,+DAAW;AACzB,YAAY,uBAAuB,mCAAmC;AACtE,cAAc,+DAAW,0BAA0B;AACnD,+DAA+D;AAC/D,wDAAwD;AACxD,gCAAgC;AAChC;AACA,mDAAmD;AACnD,YAAY,uBAAuB,2BAA2B;AAC9D,oCAAoC;AACpC,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,+DAAW;AAC3B,cAAc,+DAAW;AACzB,gBAAgB,+DAAW;AAC3B;AACA,oCAAoC,wBAAwB;AAC5D,4CAA4C,2BAA2B;AACvE,aAAa,2DAAO;AACpB;AACA,6CAA6C,4BAA4B;AACzE,aAAa,2DAAO;AACpB;AACA,8DAA8D;AAC9D,2CAA2C;AAC3C;AACA,0BAA0B;AAC1B,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,UAAU;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB,uBAAuB;AACvB;AACA,WAAW;AACX,KAAK;AACL,CAAC;AACD,sCAAsC,sEAAU;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,6EAAmB;AACzD;AACA;AACA;AACA,CAAC;AACD;AACO,gDAAgD,wEAAY;AACnE,YAAY,OAAO;AACnB;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,sDAAM;AAChB,CAAC;AACM;AACA;AACP,qC;;;;;;;;;;;;;;;;;;;;;;AC9RA;AACA;AACA;AACA;AACwF;AACxF;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,2CAAI;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,qDAAU;AAC9B;AACA;AACA,QAAQ,kDAAO;AACf,eAAe,kDAAO;AACtB,QAAQ,iDAAM;AACd,gBAAgB,yBAAyB;AACzC;AACA,0BAA0B,UAAU;AACpC;AACA;AACA;AACA,iCAAiC,qDAAU;AAC3C,uBAAuB,uBAAuB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,kDAAO;AACf,QAAQ,kDAAO;AACf;AACA;AACA;AACA;AACA,gBAAgB,+BAA+B;AAC/C,cAAc,MAAM;AACpB;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,cAAc;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,qDAAU;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY;AACpC;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,qDAAqD;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,+B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,oBAAoB,SAAS;AAC7B,gBAAgB,OAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACgL;AAChL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAe,GAAG,EAAC;AACnB,gC;;;;;;;;;;;;;;AClEO;AACP,kC;;;;;;;;;;;;;;;;ACDA;AACA;AACA;AACA;AAC0E;AACnE,mBAAmB,2CAAI;AAC9B;AACA;AACA;AACA;AACA,QAAQ,gDAAK;AACb,oBAAoB,kDAAO;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gBAAgB;AACxC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gBAAgB;AACxC;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACA,QAAQ,kDAAO;AACf;AACA;AACA;AACA;AACA,QAAQ,kDAAO;AACf,QAAQ,iDAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE;AACjE,gBAAgB,yDAAyD;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,OAAO;AACnB,YAAY,SAAS;AACrB;AACA;AACO;AACP;AACA,gC;;;;;;;;;;;;;;;;;;;;;ACrFA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAC4C;AACW;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACO,mBAAmB,0CAAM;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,gBAAgB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,QAAQ;AAChC;AACA,yBAAyB,QAAQ;AACjC,wBAAwB,+CAAI;AAC5B;AACA,cAAc,gBAAgB;AAC9B,wBAAwB,QAAQ;AAChC;AACA;AACA,oBAAoB,2CAAG;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,2CAAG;AACvB;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,+CAAI;AAC3B;AACA;AACA,gBAAgB,+CAAI;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACA;AACO,6BAA6B,uDAAY;AAChD;AACA;AACA,uCAAuC,YAAY;AACnD;AACA;AACA;AACA;AACA;AACO,kBAAkB,0CAAM;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,aAAa;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,QAAQ;AAChC;AACA;AACA,cAAc,aAAa;AAC3B,wBAAwB,QAAQ;AAChC;AACA;AACA,oBAAoB,2CAAG;AACvB;AACA;AACA;AACA;AACA,oBAAoB,2CAAG;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,+CAAI;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B,uDAAY;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,wBAAwB,0CAAM;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,qBAAqB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,QAAQ;AAChC;AACA;AACA;AACA;AACA;AACA,4BAA4B,WAAW;AACvC;AACA,0DAA0D;AAC1D,sDAAsD;AACtD,kEAAkE;AAClE,4BAA4B,QAAQ;AACpC,4BAA4B,+CAAI;AAChC,uCAAuC,+CAAI,gCAAgC;AAC3E;AACA;AACA,4BAA4B,QAAQ;AACpC,4BAA4B,+CAAI;AAChC,uCAAuC,+CAAI,gCAAgC;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,kCAAkC,uDAAY;AACrD,kC;;;;;;;;;;;;;;;;ACxRA;AACA;AACA;AACA;AACA;AACA;AACA;AAC+E;AAC/E;AACO,kBAAkB,iDAAU;AACnC;AACO,kBAAkB,iDAAU;AACnC,qC;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACwF;AACvD;AACsB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,0CAAM;AAClC;AACA;AACA;AACA;AACA,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B;AACA;AACA,gBAAgB,yBAAyB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,QAAQ;AAChC;AACA,yBAAyB,QAAQ;AACjC;AACA;AACA,uBAAuB,+CAAI,WAAW,+CAAI;AAC1C,uBAAuB,+CAAI,WAAW,+CAAI;AAC1C;AACA;AACA;AACA,cAAc,yBAAyB;AACvC,wBAAwB,QAAQ;AAChC,2BAA2B,+CAAI,SAAS,+CAAI,UAAU,+CAAI;AAC1D,qCAAqC,2CAAG;AACxC,2BAA2B,+CAAI,SAAS,+CAAI,UAAU,+CAAI;AAC1D,iCAAiC,2CAAG;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACO;AACP;AACA;AACA,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,0CAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,0CAAM;AAClC;AACA;AACA;AACA;AACA;AACA,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B;AACA;AACA;AACA,gBAAgB,iEAAiE;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,QAAQ;AAChC;AACA;AACA;AACA,yBAAyB,QAAQ;AACjC;AACA;AACA;AACA,wBAAwB,2CAAU,kBAAkB,2CAAU,kBAAkB,0CAAS;AACzF,wBAAwB,2CAAU,kBAAkB,2CAAU,kBAAkB,0CAAS;AACzF;AACA;AACA;AACA,wBAAwB,2CAAU,iBAAiB,2CAAU,iBAAiB,0CAAS;AACvF,wBAAwB,2CAAU,iBAAiB,2CAAU,iBAAiB,0CAAS;AACvF;AACA,yBAAyB,0CAAS;AAClC,yBAAyB,0CAAS;AAClC;AACA;AACA;AACA,cAAc,iEAAiE;AAC/E;AACA,wBAAwB,QAAQ;AAChC;AACA,4BAA4B,2CAAU,eAAe,2CAAU,eAAe,2CAAU;AACxF,4BAA4B,2CAAU,eAAe,2CAAU,eAAe,2CAAU;AACxF;AACA;AACA;AACA;AACA;AACA,yBAAyB,0CAAS;AAClC,wBAAwB,0CAAS;AACjC;AACA;AACA,4BAA4B,2CAAU,eAAe,2CAAU,eAAe,2CAAU;AACxF,4BAA4B,2CAAU,eAAe,2CAAU,eAAe,2CAAU;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,eAAe,EAAE,wCAAO;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,0CAAS;AACjC,iBAAiB,0CAAS;AAC1B;AACA;AACA;AACA,WAAW,eAAe,EAAE,wCAAO;AACnC,WAAW,eAAe,EAAE,wCAAO;AACnC,WAAW,eAAe,EAAE,wCAAO;AACnC,WAAW,eAAe,EAAE,wCAAO;AACnC,WAAW,eAAe,EAAE,wCAAO;AACnC,WAAW,eAAe,EAAE,wCAAO;AACnC,WAAW,eAAe,EAAE,wCAAO;AACnC,WAAW,eAAe,EAAE,wCAAO;AACnC;AACA;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACA,QAAQ,gDAAK;AACb;AACA;AACA;AACO;AACP;AACA;AACA,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B,kBAAkB,6CAAS;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,+BAA+B,uDAAY;AAClD;AACO,+BAA+B,uDAAY;AAClD;AACO,+BAA+B,uDAAY;AAClD;AACO,+BAA+B,uDAAY;AAClD;AACA;AACA;AACA;AACO,mCAAmC,uDAAY;AACtD;AACA;AACA;AACA;AACO,mCAAmC,uDAAY;AACtD,gC;;;;;;;;;;;;;;;;;;ACtXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACwG;AACxG;AACO,eAAe,4CAAO;AAC7B;AACO,eAAe,4CAAO;AAC7B;AACO,eAAe,4CAAO;AAC7B;AACO,eAAe,4CAAO;AAC7B,kC;;;;;;;;;;;;;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACoN;AACpN;AACO,eAAe,4CAAO;AAC7B;AACO,eAAe,4CAAO;AAC7B;AACO,eAAe,4CAAO;AAC7B;AACO,eAAe,4CAAO;AAC7B;AACO,mBAAmB,gDAAW;AACrC;AACO,mBAAmB,gDAAW;AACrC;AACO,mBAAmB,gDAAW;AACrC;AACO,mBAAmB,gDAAW;AACrC,kC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAC8C;AAC9C;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP,oBAAoB,mBAAmB;AACvC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACO;AACP,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,aAAa;AACxD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,kBAAkB;AACtC;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,+BAA+B;AAC/B;AACA,qCAAqC;AACrC;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,SAAS;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACO;AACP;AACA,oBAAoB,WAAW;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,0DAA0D;AAC1D;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,oBAAoB,mBAAmB;AACvC;AACA;AACA;AACA;AACA;AACA,6BAA6B,mBAAmB;AAChD;AACA;AACA;AACA;AACA;AACA;AACO;AACP,gCAAgC;AAChC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACO;AACP;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACO;AACA;AACA;AACP;AACO;AACP,QAAQ,wDAAM,WAAW,wDAAM;AAC/B,eAAe,wDAAM;AACrB;AACA;AACA,QAAQ,wDAAM,WAAW,wDAAM;AAC/B,+BAA+B,wDAAM;AACrC;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;ACxR2C;AACU;AACA;AACN;AACK;AACU;AACP;AACP;AAChD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,+DAAY,yBAAyB,4DAAS,2BAA2B,uDAAQ;AAClI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,6DAAW;AAChC,iCAAiC,6DAAW,0BAA0B,6DAAW,0BAA0B,4DAAS,QAAQ,6DAAW,2BAA2B,uDAAQ,aAAa,6DAAW;AAClM;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6DAAW;AAC1B,YAAY,6DAAW;AACvB,YAAY,6DAAW;AACvB,YAAY,6DAAW;AACvB,YAAY,6DAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,+DAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sEAAc;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,oDAAS;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAM;AACrB;AACA,sBAAsB,+DAAY;AAClC,+BAA+B;AAC/B,qBAAqB;AACrB,sBAAsB,0BAA0B;AAChD;AACA;;;;;;;;;;;;;;;;;;;;;;;ACxImD;AACR;AACU;AACA;AACN;AACW;AACV;AAChD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,CAAC,4EAA4E;AAC7E;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,kEAAc,qDAAqD,4DAAa,6DAA6D,uDAAQ;AACvL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,6DAAW;AAChC,8BAA8B,6DAAW,uBAAuB,4DAAa;AAC7E,gCAAgC,6DAAW,uBAAuB,uDAAQ;AAC1E,kCAAkC,kEAAc;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6DAAW;AAC1B;AACA,4CAA4C,6DAAW;AACvD,8CAA8C,6DAAW;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,oDAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAM;AACrB;AACA,UAAU;AACV,UAAU;AACV,4BAA4B,yCAAyC;AACrE;AACA;;;;;;;;;;;;;;;;;;AC/HmD;AACM;AACF;AACvD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,2DAAU,CAAC,iEAAa;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,+DAAY;AAChC,gBAAgB,+DAAY;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,+DAAY,oBAAoB;AAC5D;AACA;;;;;;;;;;;;;;;;;;;ACxD+C;AACI;AACM;AACF;AACvD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,2DAAU,CAAC,iEAAa;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,uDAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,uDAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,+DAAY,2BAA2B;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,qBAAqB;AACjD;AACA;;;;;;;;;;;;;;;;;;ACvFmD;AACR;AACI;AAC/C;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,oDAAS,2BAA2B,uDAAQ,iCAAiC,4DAAa;AACrI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AChE2C;AACU;AACN;AACI;AACM;AACL;AACU;AACP;AACP;AAChD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wDAAwD;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,6DAAW;AACrC,YAAY,6DAAW;AACvB,YAAY,6DAAW;AACvB;AACA;AACA;AACA;AACA,+BAA+B,2DAAU,CAAC,iEAAa;AACvD;AACA;AACA;AACA,eAAe,6DAAW;AAC1B,YAAY,6DAAW;AACvB,YAAY,6DAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAM;AACrB;AACA,mBAAmB;AACnB,kBAAkB;AAClB,sBAAsB;AACtB,sBAAsB;AACtB,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4FAA4F,oDAAS,mCAAmC,uDAAQ,mCAAmC,uDAAQ;AAC3L;AACA;AACA;AACA;AACA,2BAA2B,4DAAS;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,+DAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sEAAc,8EAA8E,+DAAY;AACvH;AACA;;;;;;;;;;;;;;;AC/JO;AACP;AACA;AACA;AACA,CAAC,0BAA0B;;;;;;;;;;;;;;;;;;;ACJY;AACI;AACA;AACY;AAChD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,gDAAO;AACjE,yBAAyB,oDAAS;AAClC,sBAAsB,oDAAS;AAC/B;AACA;AACA;AACA;AACA,kBAAkB,oDAAS;AAC3B;AACA;AACA,0DAA0D,gDAAO;AACjE,yBAAyB,oDAAS;AAClC,sBAAsB,oDAAS;AAC/B;AACA,gBAAgB,mBAAmB;AACnC;AACA;AACA;AACA,0DAA0D,gDAAO;AACjE,yBAAyB,oDAAS;AAClC,sBAAsB,oDAAS;AAC/B;AACA,gBAAgB,mBAAmB;AACnC;AACA;AACA;AACA,0DAA0D,gDAAO;AACjE,yBAAyB,oDAAS;AAClC,sBAAsB,oDAAS;AAC/B;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,gDAAO;AACjE,yBAAyB,oDAAS;AAClC,sBAAsB,oDAAS;AAC/B;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA,uBAAuB,+DAAY;AACnC;AACA;AACA;AACA;AACA,0DAA0D,gDAAO;AACjE,yBAAyB,oDAAS;AAClC,sBAAsB,oDAAS;AAC/B;AACA,gBAAgB,wBAAwB;AACxC,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,oDAAS;AAC3B;AACA;AACA,2EAA2E,gDAAO;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,oDAAS;AAC1B,iBAAiB,oDAAS;AAC1B,iBAAiB,oDAAS;AAC1B;AACA,8BAA8B,oDAAS;AACvC;AACA;AACA;AACA,sBAAsB,oDAAS;AAC/B;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,gDAAO;AACtE;AACA;AACA;AACA;AACA,iBAAiB,oDAAS;AAC1B,iBAAiB,oDAAS;AAC1B;AACA;AACA,iBAAiB,oDAAS;AAC1B,gCAAgC,YAAY;AAC5C;AACA;AACA;AACA,iBAAiB,oDAAS;AAC1B,gCAAgC,YAAY;AAC5C;AACA;AACA;AACA;AACA,iBAAiB,oDAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,oDAAS;AAC/B;AACA;AACA;AACA;AACA;AACA,sBAAsB,oDAAS;AAC/B;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC/J2C;AACA;AACY;AAChD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,oDAAS;AAC/B;AACA;AACA,mCAAmC,oDAAS;AAC5C;AACA;AACA;AACA,YAAY,oDAAS;AACrB;AACA;AACA;AACA;AACA;AACA,mCAAmC,oDAAS;AAC5C;AACA;AACA;AACA,YAAY,oDAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,oDAAS;AAC5C;AACA;AACA;AACA,YAAY,oDAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,oDAAS;AAC5C;AACA;AACA;AACA,YAAY,oDAAS;AACrB;AACA;AACA;AACA;AACA;AACA,kFAAkF,+DAAY;AAC9F;AACA;AACA;AACA;AACA,4BAA4B,cAAc;AAC1C;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,oDAAS;AAC5C;AACA;AACA;AACA,YAAY,oDAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,oDAAS;AAC5C;AACA;AACA,+BAA+B,oDAAS;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,oDAAS;AAC/B;AACA;AACA;AACA,gCAAgC,OAAO;AACvC;AACA;AACA;AACA,sBAAsB,oDAAS;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACtIO;AACP;;;;;;;;;;;;;;;ACDO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;;;;;;;;;;;;;;;;;;;;ACVoB;AACR;AACU;AACA;AACE;AAChD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,oDAAS;AAC/B;AACA;AACA;AACA;AACA;AACA,oCAAoC,+DAAY;AAChD;AACA;AACA,oCAAoC,6DAAW;AAC/C;AACA;AACA,eAAe,+DAAY;AAC3B;AACA;AACA,eAAe,6DAAW;AAC1B;AACA;AACA,eAAe,+DAAY,2BAA2B,+DAAY;AAClE;AACA;AACA,mBAAmB,4DAAa,iBAAiB,GAAG,+DAAY,oBAAoB;AACpF;AACA;;;;;;;;;;;;;;;;;;;;;;ACrDoD;AACE;AACA;AACb;AACU;AACgC;AAC5E;AACP,KAAK,4DAAa,aAAa,8DAAS;AACxC,KAAK,4DAAa,UAAU,wDAAM;AAClC,KAAK,4DAAa,UAAU,wDAAM;AAClC,KAAK,4DAAa,UAAU,wDAAM;AAClC,KAAK,4DAAa,UAAU,wDAAM;AAClC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,eAAe,eAAe;AAC9B;AACA;AACA;AACA;AACA,sBAAsB,4FAA6B;AACnD;AACA;AACA;AACA;AACA;AACA,eAAe,YAAY;AAC3B,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,kDAAQ;AAC3C;AACA;;;;;;;;;;;;;;;AC9CO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;;;;;;;;;;;;;;;ACPvC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACRO;AACP;AACA,6CAA6C,UAAU;AACvD;AACA;AACA;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,gBAAgB,cAAc,kBAAkB;AAChD;AACA,kBAAkB,eAAe;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,QAAQ,UAAU,aAAa,eAAe;AAChE;AACA;;;;;;;;;;;;;;;;;;ACrBkC;AACuB;AACM;AAC/D;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,gDAAI;AACxB;AACA;AACA;AACA,aAAa;AACb,uBAAuB,oCAAoC;AAC3D;AACA,SAAS;AACT;AACA,sBAAsB,wEAAmB;AACzC;AACA;AACA;AACA,sBAAsB,kEAAgB;AACtC;AACA;AACA;AACA;;;;;;;;;;;;;;;ACrCA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACXqD;AACA;AACE;AAChD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,6DAAW;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,+DAAY;AAC5C;AACA;AACA,eAAe,+DAAY;AAC3B;AACA;AACA,eAAe,6DAAW;AAC1B;AACA;AACA;AACA;AACA;AACA,kBAAkB,+DAAY,uBAAuB;AACrD;AACA;;;;;;;;;;;;;;;;;;;ACvCoD;AACT;AACQ;AACM;AACzD;AACA;AACA,gBAAgB;AAChB;AACO;AACP;AACA;AACA;AACA;AACA,eAAe,YAAY;AAC3B;AACA;AACA;AACA;AACA,0BAA0B,8DAAS;AACnC;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,8DAAS;AACxB;AACA;AACA,2BAA2B,2DAAU,CAAC,iEAAa;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,8DAAS;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,YAAY;AAC3B,eAAe,YAAY;AAC3B,eAAe,YAAY;AAC3B;AACA;AACA,+BAA+B,8DAAS,2CAA2C,mBAAmB;AACtG;AACA;AACA;AACA,eAAe,YAAY;AAC3B,eAAe,YAAY;AAC3B;AACA;AACA;AACA;AACA;AACA,aAAa,sBAAsB;AACnC;AACA;AACA,0BAA0B,8DAAS;AACnC,mCAAmC,oDAAS;AAC5C;AACA;;;;;;;;;;;;;;;;;ACxEuD;AACP;AACzC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAM;AACrB,aAAa,sBAAsB;AACnC,gBAAgB;AAChB,iBAAiB,+DAAY;AAC7B,eAAe,SAAS;AACxB;AACA;;;;;;;;;;;;;;;;;;;;;;;;AC1BmE;AACd;AACA;AACN;AACI;AACM;AACiB;AACb;AACb;AACzC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,uDAAQ,iEAAiE,4EAAqB;AACnI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,6DAAW;AAChC,qCAAqC,uDAAQ,oBAAoB,qEAAe,QAAQ,6DAAW,2BAA2B,6DAAW,kCAAkC,4EAAqB;AAChM;AACA;AACA,eAAe,6DAAW;AAC1B;AACA,YAAY,6DAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,uBAAuB;AAC/C;AACA;AACA;AACA;AACA,iCAAiC,2DAAU,CAAC,iEAAa;AACzD,4BAA4B,6DAAW;AACvC,oBAAoB,6DAAW,kBAAkB,qEAAe;AAChE,4BAA4B,6DAAW,2BAA2B,6DAAW;AAC7E,oBAAoB,6DAAW,kBAAkB,qEAAe;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,2DAAU,CAAC,iEAAa;AAC5D,wBAAwB,6DAAW;AACnC;AACA,sBAAsB,6DAAW;AACjC,wBAAwB,6DAAW;AACnC,wBAAwB,6DAAW,kBAAkB,qEAAe;AACpE;AACA,sBAAsB,6DAAW;AACjC;AACA,sBAAsB,6DAAW;AACjC,mCAAmC,6DAAW,sCAAsC,6DAAW;AAC/F,wBAAwB,6DAAW,kBAAkB,qEAAe;AACpE;AACA,sBAAsB,6DAAW;AACjC;AACA;AACA;AACA;AACA,mBAAmB,kFAAsB;AACzC;AACA;AACA,eAAe,4DAAM;AACrB;AACA,gBAAgB;AAChB;AACA,YAAY;AACZ;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;AC/G6C;AACQ;AACA;AACN;AACc;AACN;AACP;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,uDAAQ;AACzE;AACA;AACA,qBAAqB,6DAAW;AAChC,gDAAgD,qEAAe,QAAQ,6DAAW,2BAA2B,uDAAQ;AACrH;AACA;AACA,eAAe,6DAAW;AAC1B,YAAY,6DAAW,kBAAkB,qEAAe;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,SAAS,GAAG,qBAAqB;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0EAA0E,+DAAY;AACtF;AACA;AACA,qBAAqB,6DAAW;AAChC,+CAA+C,qEAAe,QAAQ,6DAAW,2BAA2B,6DAAW,uBAAuB,6DAAW;AACzJ;AACA;AACA,eAAe,6DAAW,cAAc,6DAAW,6BAA6B,6DAAW;AAC3F;AACA;AACA,mDAAmD,+DAAY;AAC/D;AACA;AACA,8CAA8C,cAAc,+DAAY,8BAA8B;AACtG;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,sDAAU;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,6DAAW;AAChC,yCAAyC,qEAAe,QAAQ,6DAAW,2BAA2B,6DAAW,+DAA+D,6DAAW;AAC3L;AACA;AACA,eAAe,6DAAW;AAC1B,YAAY,6DAAW,kBAAkB,qEAAe;AACxD,sCAAsC,6DAAW;AACjD,qCAAqC,6DAAW;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAM;AACrB;AACA,gBAAgB;AAChB,kBAAkB;AAClB,mBAAmB,mCAAmC;AACtD;AACA;;;;;;;;;;;;;;;;AC3IuD;AAChD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,UAAU;AACvB,iBAAiB,+DAAY;AAC7B;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACtB6D;AACQ;AAChB;AACA;AACN;AACI;AACM;AACI;AACb;AACzC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,uDAAQ,+CAA+C,sEAAkB;AAC3G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,6DAAW;AAChC,sBAAsB,6DAAW;AACjC,kCAAkC,uDAAQ,wCAAwC,sEAAkB;AACpG;AACA;AACA,eAAe,6DAAW;AAC1B;AACA,YAAY,6DAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,uBAAuB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,2DAAU,CAAC,iEAAa;AACjE,4BAA4B,qEAAe;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,2DAAU,CAAC,iEAAa;AAC5D;AACA;AACA;AACA;AACA,mBAAmB,8EAAsB;AACzC;AACA;AACA,eAAe,4DAAM;AACrB;AACA,gBAAgB;AAChB;AACA,YAAY;AACZ;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACnF6C;AACQ;AACA;AACN;AACc;AACN;AACP;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,+DAAY;AAChE;AACA;AACA,qBAAqB,6DAAW;AAChC,4CAA4C,6DAAW,uBAAuB,6DAAW;AACzF;AACA;AACA,eAAe,6DAAW,cAAc,6DAAW,6BAA6B,6DAAW;AAC3F;AACA;AACA,8BAA8B,+DAAY;AAC1C;AACA;AACA,2CAA2C,cAAc,+DAAY,8BAA8B;AACnG;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,sDAAU;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uFAAuF,uDAAQ;AAC/F;AACA;AACA,qBAAqB,6DAAW;AAChC,sCAAsC,qEAAe,QAAQ,6DAAW,2BAA2B,6DAAW,uBAAuB,uDAAQ,YAAY,6DAAW;AACpK;AACA;AACA,eAAe,6DAAW;AAC1B,YAAY,6DAAW,kBAAkB,qEAAe;AACxD,sCAAsC,6DAAW;AACjD,qCAAqC,6DAAW;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAM;AACrB;AACA,gBAAgB;AAChB,kBAAkB;AAClB,mBAAmB,mCAAmC;AACtD;AACA;;;;;;;;;;;;;;;ACpGO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACTO;AACP;AACA;AACA,eAAe,YAAY;AAC3B,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,iBAAiB,QAAQ;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,iBAAiB,YAAY;AAC7B;AACA;AACA;AACA,4BAA4B,QAAQ;AACpC;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AChC6D;AACtD;AACP;AACA;AACA,eAAe,YAAY;AAC3B;AACA;AACA;AACA,eAAe,+DAAU;AACzB;AACA;AACA;AACA;AACA,iBAAiB,YAAY;AAC7B;AACA;AACA,eAAe,+DAAU;AACzB;AACA;;;;;;;;;;;;;;;AClBA;AACA;AACA,WAAW,sBAAsB;AACjC,WAAW,WAAW;AACtB,aAAa,QAAQ;AACrB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC,uBAAuB,mBAAmB,EAAE,qFAAqF;AACjI,wBAAwB,iBAAiB;AACzC;AACA;AACA;AACA;AACA;AACA,uBAAuB,YAAY,EAAE,YAAY;AACjD,wBAAwB,qBAAqB;AAC7C,2BAA2B,wBAAwB,EAAE,YAAY;AACjE;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC/BU;AACV,yC;;;;;;;;;;;;;;;;;;;;;ACD8E;AACR;AAC4B;AAC/B;AACV;AACc;AACH;AACpE;AACA;AACA;AACO,2CAA2C,4EAAqB;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,gFAAS;AACzC,oCAAoC,wFAAa;AACjD,mBAAmB,gFAAiB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,4CAA4C;AACjF;AACA,8BAA8B,4GAAsB;AACpD,6DAA6D,cAAc;AAC3E;AACA,+BAA+B,kEAAU;AACzC,8DAA8D,iFAAkB;AAChF;AACA;AACA,wD;;;;;;;;;;;;;;;;;;;;;;;;;;ACzC8E;AACoB;AAC5B;AAC4B;AACnB;AACK;AACP;AAClB;AAClB;AACgB;AACE;AAC3D;AACA;AACA;AACA;AACO,sBAAsB,uFAAY;AACzC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,8FAAc;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mBAAmB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,4BAA4B;AAC1D;AACA,sBAAsB,4GAAgC;AACtD;AACA;AACA,8CAA8C,yFAAa;AAC3D;AACA;AACA;AACA;AACA;AACA,mBAAmB,qEAAW;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,oEAAa;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,kDAAK;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,gFAAS;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,gFAAS;AACzC,oCAAoC,wFAAa;AACjD;AACA,8BAA8B,4GAAsB;AACpD,6DAA6D,cAAc;AAC3E;AACA,mBAAmB,kEAAU;AAC7B;AACA;AACA,iD;;;;;;;;;;;;;;ACvKA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AACvC,yC;;;;;;;;;;;;;;;;;;;;ACV2E;AACN;AACI;AACM;AACF;AAC1B;AACnD;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,qBAAqB,qBAAqB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAa;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,mFAAU,CAAC,yFAAa;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,4DAAa;AACpC,gEAAgE,4DAAa,QAAQ,QAAQ,OAAO;AACpG;AACA;AACA,mDAAmD,+EAAQ,UAAU,uFAAY;AACjF,YAAY,uFAAY;AACxB,4EAA4E,SAAS,QAAQ,uFAAY,0BAA0B;AACnI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW;AAC1B;AACA;AACA;AACA,kBAAkB,YAAY,KAAK,uFAAY,4BAA4B,EAAE,uFAAY,uBAAuB;AAChH;AACA;AACA,yC;;;;;;;;;;;AC3EU;AACV,oC;;;;;;;;;;;;;;;;;;ACDgF;AACkB;AACE;AACH;AACjG;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,2GAAoB;AACjD;AACA;AACA;AACA;AACA;AACA,4BAA4B,4GAAuB;AACnD;AACA,eAAe,8GAAwB;AACvC;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB,eAAe,0FAAc;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA,4EAA4E;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4C;;;;;;;;;;;ACtDU;AACV,6C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACDA;AAC2C;AACA;AACL;AACtC;AAC0C;AACC;AAC3C;AAC6C;AACG;AACN;AACO;AACF;AACK;AACP;AACI;AACjD;AACwC;AACI;AACX;AACO;AACL;AACG;AACD;AACrC;AACkD;AACP;AAC3C;AAC4C;AACS;AACR;AACI;AACjD;AACmC;AACQ;AAC3C,iC;;;;;;;;;;;;;;;;;;;;;;ACnC2E;AACA;AACN;AACI;AACM;AACF;AACP;AACnB;AACnD,aAAa,4DAAa;AAC1B;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,uFAAY,qBAAqB,+EAAQ;AACjG;AACA;AACA,qBAAqB,qFAAW;AAChC,qBAAqB,qFAAW;AAChC,qBAAqB,4DAAa;AAClC,gEAAgE,4DAAa,MAAM,QAAQ,KAAK;AAChG;AACA,wDAAwD,qFAAW,0BAA0B,+EAAQ;AACrG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mFAAU,CAAC,yFAAa;AAC3C,oBAAoB,qFAAW,cAAc,qFAAW;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,4DAAa;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mFAAU,CAAC,yFAAa;AAC3C,oBAAoB,qFAAW,oDAAoD,qFAAW;AAC9F;AACA;AACA;AACA;AACA;AACA,mBAAmB,uFAAY;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW;AAC1B,YAAY,qFAAW;AACvB,YAAY,qFAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,oFAAM;AACrB,sBAAsB,UAAU;AAChC,oBAAoB,qBAAqB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;;;;;;;;;ACrIkG;AAC5B;AACK;AACI;AACF;AACP;AACtE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,yFAAa;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,uFAAY;AAC/B,uBAAuB,uFAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW;AAC1B,YAAY,qFAAW;AACvB,YAAY,qFAAW;AACvB,YAAY,qFAAW;AACvB,YAAY,qFAAW,kBAAkB,yFAAa;AACtD,YAAY,qFAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,uFAAY,gEAAgE,uFAAY;AACpG;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,gFAAS;AACzC;AACA,0BAA0B,4GAAgC;AAC1D;AACA;AACA;AACA,eAAe,oFAAM;AACrB,sBAAsB,UAAU;AAChC,yBAAyB,uFAAY;AACrC,yBAAyB;AACzB,8BAA8B,yFAAa;AAC3C,qBAAqB,uFAAY;AACjC,oBAAoB,qBAAqB;AACzC;AACA;AACA;AACA;AACA;AACA,+BAA+B,uFAAY,uBAAuB,uFAAY;AAC9E;AACA;AACA,4C;;;;;;;;;;;AC7HU;AACV,sC;;;;;;;;;;;ACDU;AACV,6C;;;;;;;;;;;;;;;;;;;;;ACD2E;AACA;AACF;AACM;AACF;AACpB;AACN;AACnD,aAAa,4DAAa;AAC1B;AACA;AACA;AACO,8BAA8B,kEAAgB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,kEAAgB;AAC7B;AACA;AACA,uFAAuF,uFAAY,6CAA6C,uFAAY;AAC5J;AACA;AACA,qBAAqB,qFAAW;AAChC,qBAAqB,qFAAW;AAChC,qBAAqB,4DAAa;AAClC,gEAAgE,4DAAa,QAAQ,QAAQ,KAAK;AAClG;AACA,8BAA8B,qFAAW;AACzC,aAAa,yFAAa;AAC1B,uDAAuD,cAAc;AACrE;AACA,uEAAuE,qFAAW,0BAA0B,qFAAW,yCAAyC,qFAAW;AAC3K;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mFAAU,CAAC,yFAAa;AAC3C,oBAAoB,qFAAW;AAC/B,YAAY,qFAAW;AACvB;AACA,YAAY,qFAAW;AACvB,YAAY,qFAAW,kBAAkB,yFAAa;AACtD,YAAY,qFAAW;AACvB,YAAY,qFAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mFAAU,CAAC,yFAAa;AAC3C,oBAAoB,qFAAW;AAC/B;AACA;AACA;AACA,2C;;;;;;;;;;;;;;;;;;AC/FmD;AACI;AACJ;AACQ;AAC3D;AACA,8BAA8B,wBAAwB;AACtD;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB,4DAAa;AAC9B,uBAAuB,4DAAa;AACpC,iBAAiB,4DAAa;AAC9B,uBAAuB,gEAAe;AACtC,iBAAiB,4DAAa;AAC9B,uBAAuB,oEAAiB;AACxC;AACA,2DAA2D,UAAU;AACrE;AACA;AACA;AACA,gD;;;;;;;;;;;;;;ACxBA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AACvC,yC;;;;;;;;;;;;;;;;;;;;;ACZ2E;AACA;AACF;AACM;AACF;AACpB;AACN;AACnD,aAAa,4DAAa;AAC1B;AACA;AACA;AACO,gCAAgC,kEAAgB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,mFAAU,CAAC,yFAAa;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,kEAAgB;AAC7B;AACA;AACA,yFAAyF,uFAAY,6CAA6C,uFAAY;AAC9J;AACA;AACA,qBAAqB,qFAAW;AAChC,qBAAqB,qFAAW;AAChC,qBAAqB,4DAAa;AAClC,gEAAgE,4DAAa,UAAU,QAAQ,KAAK;AACpG;AACA,8BAA8B,qFAAW;AACzC,aAAa,yFAAa;AAC1B,uDAAuD,cAAc;AACrE;AACA,yEAAyE,qFAAW,0BAA0B,qFAAW,yCAAyC,qFAAW;AAC7K;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mFAAU,CAAC,yFAAa;AAC3C,oBAAoB,qFAAW;AAC/B,YAAY,qFAAW;AACvB;AACA,YAAY,qFAAW;AACvB,YAAY,qFAAW,kBAAkB,yFAAa;AACtD,YAAY,qFAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mFAAU,CAAC,yFAAa;AAC3C,oBAAoB,qFAAW,oDAAoD,qFAAW;AAC9F;AACA;AACA;AACA,6C;;;;;;;;;;;;;;;;;;;AChG6E;AACjB;AACL;AAC6C;AACR;AACrF;AACP;AACA;AACA;AACA;AACA;AACA,+CAA+C,4GAA+B;AAC9E,2CAA2C,oGAA2B;AACtE;AACA;AACA;AACA,6BAA6B,0DAAa;AAC1C,qEAAqE,cAAc,MAAM,0DAAa,CAAC;AACvG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,kDAAK,OAAO,4DAAU,wJAAwJ,uFAAY;AAC7M;AACA;AACA,iD;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5BgF;AACX;AACkB;AACP;AACH;AACH;AACU;AACd;AACrB;AACI;AACgB;AACW;AACjB;AACxD;AACP;AACA;AACA;AACA;AACA,wBAAwB,uBAAuB;AAC/C,mBAAmB,qEAAW,OAAO,qFAAmB,QAAQ,sDAAO,QAAQ,uFAAY,wBAAwB,0DAAS,QAAQ,uFAAY,0BAA0B,uFAAY,sCAAsC,2EAAa,8CAA8C,uFAAY,oCAAoC,+EAAQ,iGAAiG,0FAAc;AAC9b;AACA;AACA;AACA,iBAAiB,2EAAc;AAC/B;AACA;AACA,iEAAiE,UAAU;AAC3E;AACA;AACA;AACA;AACA;AACA,2CAA2C,yFAAoB,CAAC,0FAAc,kCAAkC,iGAAiB;AACjI;AACA,mBAAmB,+EAAe;AAClC;AACA;AACA,2D;;;;;;;;;;;;;;;;;;;;ACrCgF;AACX;AACQ;AACtB;AACQ;AACQ;AAChE;AACP;AACA;AACA;AACA;AACA,4CAA4C,sBAAsB;AAClE,mBAAmB,oEAAW,OAAO,4EAAe,cAAc,4DAAU,0HAA0H,uFAAY,wDAAwD,uFAAY,oCAAoC,+EAAQ,gDAAgD,uFAAY,mCAAmC,0FAAc;AAC/a;AACA;AACA,uD;;;;;;;;;;;ACfU;AACV,wC;;;;;;;;;;;;;;ACDA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4C;;;;;;;;;;;;;;;;;ACnB2E;AACL;AACtE;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW;AAC1B,YAAY,qFAAW;AACvB;AACA,YAAY,qFAAW;AACvB;AACA,YAAY,qFAAW;AACvB;AACA;AACA;AACA;AACA,eAAe,oFAAM;AACrB,gBAAgB,aAAa;AAC7B,gBAAgB;AAChB,kBAAkB;AAClB;AACA,cAAc;AACd;AACA,cAAc;AACd;AACA,cAAc;AACd;AACA,cAAc;AACd;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;AC9FkG;AAC5B;AACD;AACe;AACP;AACjB;AACA;AACE;AACE;AAChE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,oEAAa;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,oEAAa;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,8FAAc,kBAAkB,oEAAa;AAClF,YAAY,uFAAY;AACxB,YAAY,uFAAY;AACxB;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,yEAAe;AAC7C;AACA;AACA;AACA,2DAA2D,sEAAa;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,+EAAQ;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,gFAAS;AACzC;AACA,0BAA0B,4GAAgC;AAC1D;AACA;AACA,wC;;;;;;;;;;;;;;;;ACjH2E;AACE;AAC7E;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uFAAY;AAC3B;AACA;AACA;AACA,eAAe,qFAAW;AAC1B;AACA;AACA;AACA,0BAA0B,uFAAY,qBAAqB;AAC3D;AACA;AACA;AACA;AACA;AACA,6BAA6B,uFAAY,uBAAuB;AAChE;AACA;AACA,mC;;;;;;;;;;;;;;;;;;;ACxC2E;AACF;AACM;AACF;AACP;AACtE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,mFAAU,CAAC,yFAAa;AACvF,oBAAoB,qFAAW;AAC/B;AACA,YAAY,qFAAW,sBAAsB,qFAAW;AACxD;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,uFAAY;AAC3C;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW;AAC1B;AACA,YAAY,qFAAW,4BAA4B,qFAAW;AAC9D;AACA;AACA;AACA;AACA,eAAe,oFAAM;AACrB;AACA,YAAY;AACZ,kBAAkB,aAAa,uFAAY;AAC3C,kBAAkB,qBAAqB;AACvC;AACA;AACA,sC;;;;;;;;;;;;;;;;ACjE2E;AACE;AAC7E;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uFAAY;AAC3B;AACA;AACA;AACA,eAAe,qFAAW;AAC1B;AACA;AACA;AACA,4BAA4B,uFAAY,qBAAqB;AAC7D;AACA;AACA,qC;;;;;;;;;;;;;;;;;AChC2E;AACA;AACE;AAC7E;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,uFAAY;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qFAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,uFAAY;AAC3C;AACA;AACA;AACA,eAAe,uFAAY;AAC3B;AACA;AACA;AACA,eAAe,qFAAW;AAC1B;AACA;AACA;AACA;AACA;AACA,6BAA6B,uFAAY,uBAAuB;AAChE;AACA;AACA,kC;;;;;;;;;;;;;;;;;ACjD2E;AACQ;AACd;AAC9D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW;AAC1B;AACA,YAAY,qFAAW,yEAAyE,qFAAW,cAAc,qFAAW,kBAAkB,6FAAe;AACrK;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,0EAAc;AAChC;AACA;AACA;AACA,2C;;;;;;;;;;;;;;;AC5B2E;AACpE;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW;AAC1B;AACA;AACA,gD;;;;;;;;;;;;;;;;;;;AClB2E;AACA;AACQ;AACb;AACjC;AACrC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gFAAgF,8CAAM;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,qFAAW;AACnC;AACA,iCAAiC,qFAAW;AAC5C;AACA,gBAAgB,6FAAe,QAAQ,qFAAW;AAClD,gBAAgB,6FAAe,QAAQ,qFAAW;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4IAA4I,kBAAkB;AAC9J;AACA,uEAAuE,SAAS;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW,qEAAqE,qFAAW;AAC1G,YAAY,qFAAW,kBAAkB,6FAAe;AACxD,YAAY,qFAAW,kBAAkB,6FAAe;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,oFAAM;AACrB;AACA,UAAU;AACV,sCAAsC,IAAI,IAAI,MAAM;AACpD,wBAAwB;AACxB;AACA;AACA,yC;;;;;;;;;;;;;;AC5FA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;;;ACnBO;AACP;AACA;AACA,CAAC,wCAAwC;AACzC,0C;;;;;;;;;;;;;;;;;;;;ACJsE;AACK;AACF;AACM;AACF;AACP;AACtE;AACA;AACA;AACA;AACA,oBAAoB,uFAAY;AAChC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,gFAAS;AAC3C,wCAAwC,mFAAU,CAAC,yFAAa;AAChE,iDAAiD,mFAAU,CAAC,yFAAa;AACzE,oBAAoB,qFAAW;AAC/B;AACA;AACA;AACA,kCAAkC,qFAAW;AAC7C,kCAAkC,qFAAW;AAC7C,YAAY,qFAAW;AACvB,YAAY,qFAAW;AACvB,gCAAgC,qFAAW;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,uFAAY;AAC9B,uBAAuB,uFAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW;AAC1B;AACA;AACA,YAAY,qFAAW;AACvB,uCAAuC,qFAAW;AAClD,YAAY,qFAAW;AACvB,YAAY,qFAAW;AACvB,uCAAuC,qFAAW;AAClD,qCAAqC,qFAAW;AAChD;AACA;AACA;AACA;AACA,eAAe,oFAAM;AACrB;AACA,oBAAoB;AACpB,sBAAsB;AACtB,sBAAsB,uFAAY;AAClC,iBAAiB;AACjB,qBAAqB;AACrB,gBAAgB,uFAAY;AAC5B,gBAAgB;AAChB,kBAAkB;AAClB,gBAAgB,qBAAqB;AACrC;AACA;AACA,+C;;;;;;;;;;;;;;ACnIA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6C;;;;;;;;;;;;;;;;;;;;;;;;;;ACnB8E;AACR;AACK;AACN;AACQ;AAClB;AACJ;AACqB;AACS;AAC7B;AACJ;AACF;AAClD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,oFAAoB;AACzD,iCAAiC,gEAAY,KAAK,6FAAqB;AACvE;AACA;AACA;AACA,0BAA0B,gFAAS;AACnC,8BAA8B,wFAAa;AAC3C;AACA;AACA,sCAAsC,gEAAe,cAAc,6DAAU,2HAA2H,uFAAY,4DAA4D,uFAAY,wCAAwC,+EAAQ,oDAAoD,uFAAY;AAC5Y;AACA,sCAAsC,oEAAiB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,2DAAS;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW;AAC1B,YAAY,qFAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,2DAAS;AACxB;AACA;AACA,8C;;;;;;;;;;;;;;;;;AC7G2E;AACF;AACH;AACtE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,mFAAU;AACjD;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,oFAAM;AACrB;AACA,YAAY;AACZ,YAAY,+BAA+B;AAC3C;AACA;AACA,uC;;;;;;;;;;;;;;;;;;;AClD2E;AACF;AACM;AACF;AACP;AACtE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,mFAAU,CAAC,yFAAa;AACrE,oBAAoB,qFAAW;AAC/B;AACA,kCAAkC,qFAAW;AAC7C,YAAY,qFAAW;AACvB,YAAY,qFAAW;AACvB,YAAY,qFAAW,yBAAyB,qFAAW;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,uFAAY;AACjD;AACA;AACA,kBAAkB,uFAAY;AAC9B;AACA;AACA;AACA;AACA;AACA,eAAe,qFAAW;AAC1B;AACA,YAAY,qFAAW;AACvB,YAAY,qFAAW;AACvB,uCAAuC,qFAAW;AAClD,4BAA4B,qFAAW,mCAAmC,qFAAW;AACrF,YAAY,qFAAW;AACvB;AACA;AACA;AACA;AACA,eAAe,oFAAM;AACrB;AACA,UAAU;AACV,qBAAqB;AACrB,gBAAgB,uFAAY;AAC5B,gBAAgB;AAChB,mBAAmB,gBAAgB,uFAAY;AAC/C;AACA,YAAY;AACZ;AACA,gBAAgB,qBAAqB;AACrC;AACA;AACA,2C;;;;;;;;;;;;;;;;ACrGkG;AACH;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI,YAAY;AACzB,KAAK;AACL;AACO;AACP;AACA;AACA;AACA,mFAAmF,4GAAgC;AACnH;AACA;AACA;AACA;AACA,iCAAiC,yGAAmB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+C;;;;;;;;;;;;;;ACtCA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;;;ACjDA;AACA,iEAAe,EAAE,YAAY,EAAC;;;;;;;;;;;;;;;ACD9B,iEAAe,cAAc,EAAE,UAAU,EAAE,eAAe,EAAE,gBAAgB,EAAE,UAAU,GAAG,8EAA8E,EAAC;;;;;;;;;;;;;;;ACA1K;AACA;AACe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACVqC;AACrC;AACA,gBAAgB,SAAS;AACzB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,wDAAQ;AACjB;AACA;AACA;AACA;AACA,iEAAe,SAAS,EAAC;;;;;;;;;;;;;;;;;;AClCQ;AACN;AACsB;AACjD;AACA,QAAQ,kDAAM;AACd,eAAe,kDAAM;AACrB;AACA;AACA,sDAAsD,mDAAG;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,OAAO,GAAG,aAAa;AAC3E;AACA,wBAAwB,QAAQ;AAChC;AACA;AACA;AACA;AACA,WAAW,8DAAe;AAC1B;AACA,iEAAe,EAAE,EAAC;;;;;;;;;;;;;;;;AC1Ba;AAC/B;AACA,uCAAuC,iDAAK;AAC5C;AACA,iEAAe,QAAQ,EAAC;;;;;;;UCJxB;UACA;;UAEA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;UAEA;UACA;;UAEA;UACA;UACA;;;;;WCtBA;WACA;WACA;WACA;WACA,yCAAyC,wCAAwC;WACjF;WACA;WACA,E;;;;;WCPA,wF;;;;;WCAA;WACA;WACA;WACA,uDAAuD,iBAAiB;WACxE;WACA,gDAAgD,aAAa;WAC7D,E;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACNkD;AAClD;AACqH;AACV;AACE;AAC7G;AAC+G;AAC/G;AACwH;AACxH;AACA;AACA;AACA;AACoF;AACV;AAC1E;AAC+E;AACN;AACJ;AACrE;AAC6E;AAC7E;AACkH;AAC5C;AACQ;AACoB;AAC0B","sources":["webpack://unicity/webpack/universalModuleDefinition","webpack://unicity/./node_modules/@noble/curves/esm/_shortw_utils.js","webpack://unicity/./node_modules/@noble/curves/esm/abstract/curve.js","webpack://unicity/./node_modules/@noble/curves/esm/abstract/hash-to-curve.js","webpack://unicity/./node_modules/@noble/curves/esm/abstract/modular.js","webpack://unicity/./node_modules/@noble/curves/esm/abstract/utils.js","webpack://unicity/./node_modules/@noble/curves/esm/abstract/weierstrass.js","webpack://unicity/./node_modules/@noble/curves/esm/secp256k1.js","webpack://unicity/./node_modules/@noble/hashes/esm/_md.js","webpack://unicity/./node_modules/@noble/hashes/esm/_u64.js","webpack://unicity/./node_modules/@noble/hashes/esm/crypto.js","webpack://unicity/./node_modules/@noble/hashes/esm/hmac.js","webpack://unicity/./node_modules/@noble/hashes/esm/legacy.js","webpack://unicity/./node_modules/@noble/hashes/esm/ripemd160.js","webpack://unicity/./node_modules/@noble/hashes/esm/sha2.js","webpack://unicity/./node_modules/@noble/hashes/esm/sha256.js","webpack://unicity/./node_modules/@noble/hashes/esm/sha512.js","webpack://unicity/./node_modules/@noble/hashes/esm/utils.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/api/Authenticator.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/api/InclusionProof.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/api/LeafValue.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/api/RequestId.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/api/SubmitCommitmentRequest.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/api/SubmitCommitmentResponse.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/cbor/BitMask.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/cbor/CborDecoder.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/cbor/CborEncoder.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/cbor/CborError.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/cbor/MajorType.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/hash/DataHash.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/hash/DataHasher.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/hash/HashAlgorithm.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/hash/HashError.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/hash/UnsupportedHashAlgorithmError.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/json-rpc/JsonRpcDataError.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/json-rpc/JsonRpcHttpTransport.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/json-rpc/JsonRpcNetworkError.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/signing/Signature.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/signing/SigningService.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/smst/LeafBranch.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/smst/MerkleSumTreePath.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/smst/MerkleSumTreePathStep.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/smt/LeafBranch.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/smt/MerkleTreePath.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/smt/MerkleTreePathStep.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/smt/PathVerificationResult.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/util/BigintConverter.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/util/HexConverter.js","webpack://unicity/./node_modules/@unicitylabs/commons/lib/util/StringUtils.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/ISerializable.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/OfflineStateTransitionClient.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/StateTransitionClient.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/address/AddressScheme.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/address/DirectAddress.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/address/IAddress.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/api/AggregatorClient.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/api/IAggregatorClient.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/index.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/predicate/BurnPredicate.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/predicate/DefaultPredicate.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/predicate/IPredicate.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/predicate/IPredicateFactory.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/predicate/MaskedPredicate.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/predicate/PredicateJsonFactory.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/predicate/PredicateType.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/predicate/UnmaskedPredicate.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/serializer/token/TokenJsonDeserializer.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/serializer/transaction/MintTransactionJsonDeserializer.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/serializer/transaction/TransactionJsonDeserializer.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/token/NameTagToken.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/token/NameTagTokenData.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/token/Token.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/token/TokenFactory.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/token/TokenId.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/token/TokenState.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/token/TokenType.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/token/fungible/CoinId.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/token/fungible/SplitMintReason.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/token/fungible/SplitMintReasonProof.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/token/fungible/TokenCoinData.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/transaction/Commitment.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/transaction/MintReasonType.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/transaction/MintTransactionData.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/transaction/OfflineCommitment.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/transaction/OfflineTransaction.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/transaction/Transaction.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/transaction/TransactionData.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/utils/InclusionProofUtils.js","webpack://unicity/./node_modules/@unicitylabs/state-transition-sdk/lib/utils/JsonUtils.js","webpack://unicity/./node_modules/uuid/dist/esm-browser/native.js","webpack://unicity/./node_modules/uuid/dist/esm-browser/regex.js","webpack://unicity/./node_modules/uuid/dist/esm-browser/rng.js","webpack://unicity/./node_modules/uuid/dist/esm-browser/stringify.js","webpack://unicity/./node_modules/uuid/dist/esm-browser/v4.js","webpack://unicity/./node_modules/uuid/dist/esm-browser/validate.js","webpack://unicity/webpack/bootstrap","webpack://unicity/webpack/runtime/define property getters","webpack://unicity/webpack/runtime/hasOwnProperty shorthand","webpack://unicity/webpack/runtime/make namespace object","webpack://unicity/./src/index.ts"],"sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"unicity\"] = factory();\n\telse\n\t\troot[\"unicity\"] = factory();\n})(self, () => {\nreturn ","/**\n * Utilities for short weierstrass curves, combined with noble-hashes.\n * @module\n */\n/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\nimport { hmac } from '@noble/hashes/hmac';\nimport { concatBytes, randomBytes } from '@noble/hashes/utils';\nimport { weierstrass } from \"./abstract/weierstrass.js\";\n/** connects noble-curves to noble-hashes */\nexport function getHash(hash) {\n    return {\n        hash,\n        hmac: (key, ...msgs) => hmac(hash, key, concatBytes(...msgs)),\n        randomBytes,\n    };\n}\nexport function createCurve(curveDef, defHash) {\n    const create = (hash) => weierstrass({ ...curveDef, ...getHash(hash) });\n    return { ...create(defHash), create };\n}\n//# sourceMappingURL=_shortw_utils.js.map","/**\n * Methods for elliptic curve multiplication by scalars.\n * Contains wNAF, pippenger\n * @module\n */\n/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\nimport { nLength, validateField } from \"./modular.js\";\nimport { bitLen, bitMask, validateObject } from \"./utils.js\";\nconst _0n = BigInt(0);\nconst _1n = BigInt(1);\nfunction constTimeNegate(condition, item) {\n    const neg = item.negate();\n    return condition ? neg : item;\n}\nfunction validateW(W, bits) {\n    if (!Number.isSafeInteger(W) || W <= 0 || W > bits)\n        throw new Error('invalid window size, expected [1..' + bits + '], got W=' + W);\n}\nfunction calcWOpts(W, scalarBits) {\n    validateW(W, scalarBits);\n    const windows = Math.ceil(scalarBits / W) + 1; // W=8 33. Not 32, because we skip zero\n    const windowSize = 2 ** (W - 1); // W=8 128. Not 256, because we skip zero\n    const maxNumber = 2 ** W; // W=8 256\n    const mask = bitMask(W); // W=8 255 == mask 0b11111111\n    const shiftBy = BigInt(W); // W=8 8\n    return { windows, windowSize, mask, maxNumber, shiftBy };\n}\nfunction calcOffsets(n, window, wOpts) {\n    const { windowSize, mask, maxNumber, shiftBy } = wOpts;\n    let wbits = Number(n & mask); // extract W bits.\n    let nextN = n >> shiftBy; // shift number by W bits.\n    // What actually happens here:\n    // const highestBit = Number(mask ^ (mask >> 1n));\n    // let wbits2 = wbits - 1; // skip zero\n    // if (wbits2 & highestBit) { wbits2 ^= Number(mask); // (~);\n    // split if bits > max: +224 => 256-32\n    if (wbits > windowSize) {\n        // we skip zero, which means instead of `>= size-1`, we do `> size`\n        wbits -= maxNumber; // -32, can be maxNumber - wbits, but then we need to set isNeg here.\n        nextN += _1n; // +256 (carry)\n    }\n    const offsetStart = window * windowSize;\n    const offset = offsetStart + Math.abs(wbits) - 1; // -1 because we skip zero\n    const isZero = wbits === 0; // is current window slice a 0?\n    const isNeg = wbits < 0; // is current window slice negative?\n    const isNegF = window % 2 !== 0; // fake random statement for noise\n    const offsetF = offsetStart; // fake offset for noise\n    return { nextN, offset, isZero, isNeg, isNegF, offsetF };\n}\nfunction validateMSMPoints(points, c) {\n    if (!Array.isArray(points))\n        throw new Error('array expected');\n    points.forEach((p, i) => {\n        if (!(p instanceof c))\n            throw new Error('invalid point at index ' + i);\n    });\n}\nfunction validateMSMScalars(scalars, field) {\n    if (!Array.isArray(scalars))\n        throw new Error('array of scalars expected');\n    scalars.forEach((s, i) => {\n        if (!field.isValid(s))\n            throw new Error('invalid scalar at index ' + i);\n    });\n}\n// Since points in different groups cannot be equal (different object constructor),\n// we can have single place to store precomputes.\n// Allows to make points frozen / immutable.\nconst pointPrecomputes = new WeakMap();\nconst pointWindowSizes = new WeakMap();\nfunction getW(P) {\n    return pointWindowSizes.get(P) || 1;\n}\n/**\n * Elliptic curve multiplication of Point by scalar. Fragile.\n * Scalars should always be less than curve order: this should be checked inside of a curve itself.\n * Creates precomputation tables for fast multiplication:\n * - private scalar is split by fixed size windows of W bits\n * - every window point is collected from window's table & added to accumulator\n * - since windows are different, same point inside tables won't be accessed more than once per calc\n * - each multiplication is 'Math.ceil(CURVE_ORDER / ) + 1' point additions (fixed for any scalar)\n * - +1 window is neccessary for wNAF\n * - wNAF reduces table size: 2x less memory + 2x faster generation, but 10% slower multiplication\n *\n * @todo Research returning 2d JS array of windows, instead of a single window.\n * This would allow windows to be in different memory locations\n */\nexport function wNAF(c, bits) {\n    return {\n        constTimeNegate,\n        hasPrecomputes(elm) {\n            return getW(elm) !== 1;\n        },\n        // non-const time multiplication ladder\n        unsafeLadder(elm, n, p = c.ZERO) {\n            let d = elm;\n            while (n > _0n) {\n                if (n & _1n)\n                    p = p.add(d);\n                d = d.double();\n                n >>= _1n;\n            }\n            return p;\n        },\n        /**\n         * Creates a wNAF precomputation window. Used for caching.\n         * Default window size is set by `utils.precompute()` and is equal to 8.\n         * Number of precomputed points depends on the curve size:\n         * 2^(1) * (Math.ceil( / ) + 1), where:\n         * -  is the window size\n         * -  is the bitlength of the curve order.\n         * For a 256-bit curve and window size 8, the number of precomputed points is 128 * 33 = 4224.\n         * @param elm Point instance\n         * @param W window size\n         * @returns precomputed point tables flattened to a single array\n         */\n        precomputeWindow(elm, W) {\n            const { windows, windowSize } = calcWOpts(W, bits);\n            const points = [];\n            let p = elm;\n            let base = p;\n            for (let window = 0; window < windows; window++) {\n                base = p;\n                points.push(base);\n                // i=1, bc we skip 0\n                for (let i = 1; i < windowSize; i++) {\n                    base = base.add(p);\n                    points.push(base);\n                }\n                p = base.double();\n            }\n            return points;\n        },\n        /**\n         * Implements ec multiplication using precomputed tables and w-ary non-adjacent form.\n         * @param W window size\n         * @param precomputes precomputed tables\n         * @param n scalar (we don't check here, but should be less than curve order)\n         * @returns real and fake (for const-time) points\n         */\n        wNAF(W, precomputes, n) {\n            // Smaller version:\n            // https://github.com/paulmillr/noble-secp256k1/blob/47cb1669b6e506ad66b35fe7d76132ae97465da2/index.ts#L502-L541\n            // TODO: check the scalar is less than group order?\n            // wNAF behavior is undefined otherwise. But have to carefully remove\n            // other checks before wNAF. ORDER == bits here.\n            // Accumulators\n            let p = c.ZERO;\n            let f = c.BASE;\n            // This code was first written with assumption that 'f' and 'p' will never be infinity point:\n            // since each addition is multiplied by 2 ** W, it cannot cancel each other. However,\n            // there is negate now: it is possible that negated element from low value\n            // would be the same as high element, which will create carry into next window.\n            // It's not obvious how this can fail, but still worth investigating later.\n            const wo = calcWOpts(W, bits);\n            for (let window = 0; window < wo.windows; window++) {\n                // (n === _0n) is handled and not early-exited. isEven and offsetF are used for noise\n                const { nextN, offset, isZero, isNeg, isNegF, offsetF } = calcOffsets(n, window, wo);\n                n = nextN;\n                if (isZero) {\n                    // bits are 0: add garbage to fake point\n                    // Important part for const-time getPublicKey: add random \"noise\" point to f.\n                    f = f.add(constTimeNegate(isNegF, precomputes[offsetF]));\n                }\n                else {\n                    // bits are 1: add to result point\n                    p = p.add(constTimeNegate(isNeg, precomputes[offset]));\n                }\n            }\n            // Return both real and fake points: JIT won't eliminate f.\n            // At this point there is a way to F be infinity-point even if p is not,\n            // which makes it less const-time: around 1 bigint multiply.\n            return { p, f };\n        },\n        /**\n         * Implements ec unsafe (non const-time) multiplication using precomputed tables and w-ary non-adjacent form.\n         * @param W window size\n         * @param precomputes precomputed tables\n         * @param n scalar (we don't check here, but should be less than curve order)\n         * @param acc accumulator point to add result of multiplication\n         * @returns point\n         */\n        wNAFUnsafe(W, precomputes, n, acc = c.ZERO) {\n            const wo = calcWOpts(W, bits);\n            for (let window = 0; window < wo.windows; window++) {\n                if (n === _0n)\n                    break; // Early-exit, skip 0 value\n                const { nextN, offset, isZero, isNeg } = calcOffsets(n, window, wo);\n                n = nextN;\n                if (isZero) {\n                    // Window bits are 0: skip processing.\n                    // Move to next window.\n                    continue;\n                }\n                else {\n                    const item = precomputes[offset];\n                    acc = acc.add(isNeg ? item.negate() : item); // Re-using acc allows to save adds in MSM\n                }\n            }\n            return acc;\n        },\n        getPrecomputes(W, P, transform) {\n            // Calculate precomputes on a first run, reuse them after\n            let comp = pointPrecomputes.get(P);\n            if (!comp) {\n                comp = this.precomputeWindow(P, W);\n                if (W !== 1)\n                    pointPrecomputes.set(P, transform(comp));\n            }\n            return comp;\n        },\n        wNAFCached(P, n, transform) {\n            const W = getW(P);\n            return this.wNAF(W, this.getPrecomputes(W, P, transform), n);\n        },\n        wNAFCachedUnsafe(P, n, transform, prev) {\n            const W = getW(P);\n            if (W === 1)\n                return this.unsafeLadder(P, n, prev); // For W=1 ladder is ~x2 faster\n            return this.wNAFUnsafe(W, this.getPrecomputes(W, P, transform), n, prev);\n        },\n        // We calculate precomputes for elliptic curve point multiplication\n        // using windowed method. This specifies window size and\n        // stores precomputed values. Usually only base point would be precomputed.\n        setWindowSize(P, W) {\n            validateW(W, bits);\n            pointWindowSizes.set(P, W);\n            pointPrecomputes.delete(P);\n        },\n    };\n}\n/**\n * Pippenger algorithm for multi-scalar multiplication (MSM, Pa + Qb + Rc + ...).\n * 30x faster vs naive addition on L=4096, 10x faster than precomputes.\n * For N=254bit, L=1, it does: 1024 ADD + 254 DBL. For L=5: 1536 ADD + 254 DBL.\n * Algorithmically constant-time (for same L), even when 1 point + scalar, or when scalar = 0.\n * @param c Curve Point constructor\n * @param fieldN field over CURVE.N - important that it's not over CURVE.P\n * @param points array of L curve points\n * @param scalars array of L scalars (aka private keys / bigints)\n */\nexport function pippenger(c, fieldN, points, scalars) {\n    // If we split scalars by some window (let's say 8 bits), every chunk will only\n    // take 256 buckets even if there are 4096 scalars, also re-uses double.\n    // TODO:\n    // - https://eprint.iacr.org/2024/750.pdf\n    // - https://tches.iacr.org/index.php/TCHES/article/view/10287\n    // 0 is accepted in scalars\n    validateMSMPoints(points, c);\n    validateMSMScalars(scalars, fieldN);\n    const plength = points.length;\n    const slength = scalars.length;\n    if (plength !== slength)\n        throw new Error('arrays of points and scalars must have equal length');\n    // if (plength === 0) throw new Error('array must be of length >= 2');\n    const zero = c.ZERO;\n    const wbits = bitLen(BigInt(plength));\n    let windowSize = 1; // bits\n    if (wbits > 12)\n        windowSize = wbits - 3;\n    else if (wbits > 4)\n        windowSize = wbits - 2;\n    else if (wbits > 0)\n        windowSize = 2;\n    const MASK = bitMask(windowSize);\n    const buckets = new Array(Number(MASK) + 1).fill(zero); // +1 for zero array\n    const lastBits = Math.floor((fieldN.BITS - 1) / windowSize) * windowSize;\n    let sum = zero;\n    for (let i = lastBits; i >= 0; i -= windowSize) {\n        buckets.fill(zero);\n        for (let j = 0; j < slength; j++) {\n            const scalar = scalars[j];\n            const wbits = Number((scalar >> BigInt(i)) & MASK);\n            buckets[wbits] = buckets[wbits].add(points[j]);\n        }\n        let resI = zero; // not using this will do small speed-up, but will lose ct\n        // Skip first bucket, because it is zero\n        for (let j = buckets.length - 1, sumI = zero; j > 0; j--) {\n            sumI = sumI.add(buckets[j]);\n            resI = resI.add(sumI);\n        }\n        sum = sum.add(resI);\n        if (i !== 0)\n            for (let j = 0; j < windowSize; j++)\n                sum = sum.double();\n    }\n    return sum;\n}\n/**\n * Precomputed multi-scalar multiplication (MSM, Pa + Qb + Rc + ...).\n * @param c Curve Point constructor\n * @param fieldN field over CURVE.N - important that it's not over CURVE.P\n * @param points array of L curve points\n * @returns function which multiplies points with scaars\n */\nexport function precomputeMSMUnsafe(c, fieldN, points, windowSize) {\n    /**\n     * Performance Analysis of Window-based Precomputation\n     *\n     * Base Case (256-bit scalar, 8-bit window):\n     * - Standard precomputation requires:\n     *   - 31 additions per scalar  256 scalars = 7,936 ops\n     *   - Plus 255 summary additions = 8,191 total ops\n     *   Note: Summary additions can be optimized via accumulator\n     *\n     * Chunked Precomputation Analysis:\n     * - Using 32 chunks requires:\n     *   - 255 additions per chunk\n     *   - 256 doublings\n     *   - Total: (255  32) + 256 = 8,416 ops\n     *\n     * Memory Usage Comparison:\n     * Window Size | Standard Points | Chunked Points\n     * ------------|-----------------|---------------\n     *     4-bit   |     520         |      15\n     *     8-bit   |    4,224        |     255\n     *    10-bit   |   13,824        |   1,023\n     *    16-bit   |  557,056        |  65,535\n     *\n     * Key Advantages:\n     * 1. Enables larger window sizes due to reduced memory overhead\n     * 2. More efficient for smaller scalar counts:\n     *    - 16 chunks: (16  255) + 256 = 4,336 ops\n     *    - ~2x faster than standard 8,191 ops\n     *\n     * Limitations:\n     * - Not suitable for plain precomputes (requires 256 constant doublings)\n     * - Performance degrades with larger scalar counts:\n     *   - Optimal for ~256 scalars\n     *   - Less efficient for 4096+ scalars (Pippenger preferred)\n     */\n    validateW(windowSize, fieldN.BITS);\n    validateMSMPoints(points, c);\n    const zero = c.ZERO;\n    const tableSize = 2 ** windowSize - 1; // table size (without zero)\n    const chunks = Math.ceil(fieldN.BITS / windowSize); // chunks of item\n    const MASK = bitMask(windowSize);\n    const tables = points.map((p) => {\n        const res = [];\n        for (let i = 0, acc = p; i < tableSize; i++) {\n            res.push(acc);\n            acc = acc.add(p);\n        }\n        return res;\n    });\n    return (scalars) => {\n        validateMSMScalars(scalars, fieldN);\n        if (scalars.length > points.length)\n            throw new Error('array of scalars must be smaller than array of points');\n        let res = zero;\n        for (let i = 0; i < chunks; i++) {\n            // No need to double if accumulator is still zero.\n            if (res !== zero)\n                for (let j = 0; j < windowSize; j++)\n                    res = res.double();\n            const shiftBy = BigInt(chunks * windowSize - (i + 1) * windowSize);\n            for (let j = 0; j < scalars.length; j++) {\n                const n = scalars[j];\n                const curr = Number((n >> shiftBy) & MASK);\n                if (!curr)\n                    continue; // skip zero scalars chunks\n                res = res.add(tables[j][curr - 1]);\n            }\n        }\n        return res;\n    };\n}\nexport function validateBasic(curve) {\n    validateField(curve.Fp);\n    validateObject(curve, {\n        n: 'bigint',\n        h: 'bigint',\n        Gx: 'field',\n        Gy: 'field',\n    }, {\n        nBitLength: 'isSafeInteger',\n        nByteLength: 'isSafeInteger',\n    });\n    // Set defaults\n    return Object.freeze({\n        ...nLength(curve.n, curve.nBitLength),\n        ...curve,\n        ...{ p: curve.Fp.ORDER },\n    });\n}\n//# sourceMappingURL=curve.js.map","import { FpInvertBatch, mod } from \"./modular.js\";\nimport { abytes, bytesToNumberBE, concatBytes, utf8ToBytes, validateObject } from \"./utils.js\";\n// Octet Stream to Integer. \"spec\" implementation of os2ip is 2.5x slower vs bytesToNumberBE.\nconst os2ip = bytesToNumberBE;\n// Integer to Octet Stream (numberToBytesBE)\nfunction i2osp(value, length) {\n    anum(value);\n    anum(length);\n    if (value < 0 || value >= 1 << (8 * length))\n        throw new Error('invalid I2OSP input: ' + value);\n    const res = Array.from({ length }).fill(0);\n    for (let i = length - 1; i >= 0; i--) {\n        res[i] = value & 0xff;\n        value >>>= 8;\n    }\n    return new Uint8Array(res);\n}\nfunction strxor(a, b) {\n    const arr = new Uint8Array(a.length);\n    for (let i = 0; i < a.length; i++) {\n        arr[i] = a[i] ^ b[i];\n    }\n    return arr;\n}\nfunction anum(item) {\n    if (!Number.isSafeInteger(item))\n        throw new Error('number expected');\n}\n/**\n * Produces a uniformly random byte string using a cryptographic hash function H that outputs b bits.\n * [RFC 9380 5.3.1](https://www.rfc-editor.org/rfc/rfc9380#section-5.3.1).\n */\nexport function expand_message_xmd(msg, DST, lenInBytes, H) {\n    abytes(msg);\n    abytes(DST);\n    anum(lenInBytes);\n    // https://www.rfc-editor.org/rfc/rfc9380#section-5.3.3\n    if (DST.length > 255)\n        DST = H(concatBytes(utf8ToBytes('H2C-OVERSIZE-DST-'), DST));\n    const { outputLen: b_in_bytes, blockLen: r_in_bytes } = H;\n    const ell = Math.ceil(lenInBytes / b_in_bytes);\n    if (lenInBytes > 65535 || ell > 255)\n        throw new Error('expand_message_xmd: invalid lenInBytes');\n    const DST_prime = concatBytes(DST, i2osp(DST.length, 1));\n    const Z_pad = i2osp(0, r_in_bytes);\n    const l_i_b_str = i2osp(lenInBytes, 2); // len_in_bytes_str\n    const b = new Array(ell);\n    const b_0 = H(concatBytes(Z_pad, msg, l_i_b_str, i2osp(0, 1), DST_prime));\n    b[0] = H(concatBytes(b_0, i2osp(1, 1), DST_prime));\n    for (let i = 1; i <= ell; i++) {\n        const args = [strxor(b_0, b[i - 1]), i2osp(i + 1, 1), DST_prime];\n        b[i] = H(concatBytes(...args));\n    }\n    const pseudo_random_bytes = concatBytes(...b);\n    return pseudo_random_bytes.slice(0, lenInBytes);\n}\n/**\n * Produces a uniformly random byte string using an extendable-output function (XOF) H.\n * 1. The collision resistance of H MUST be at least k bits.\n * 2. H MUST be an XOF that has been proved indifferentiable from\n *    a random oracle under a reasonable cryptographic assumption.\n * [RFC 9380 5.3.2](https://www.rfc-editor.org/rfc/rfc9380#section-5.3.2).\n */\nexport function expand_message_xof(msg, DST, lenInBytes, k, H) {\n    abytes(msg);\n    abytes(DST);\n    anum(lenInBytes);\n    // https://www.rfc-editor.org/rfc/rfc9380#section-5.3.3\n    // DST = H('H2C-OVERSIZE-DST-' || a_very_long_DST, Math.ceil((lenInBytes * k) / 8));\n    if (DST.length > 255) {\n        const dkLen = Math.ceil((2 * k) / 8);\n        DST = H.create({ dkLen }).update(utf8ToBytes('H2C-OVERSIZE-DST-')).update(DST).digest();\n    }\n    if (lenInBytes > 65535 || DST.length > 255)\n        throw new Error('expand_message_xof: invalid lenInBytes');\n    return (H.create({ dkLen: lenInBytes })\n        .update(msg)\n        .update(i2osp(lenInBytes, 2))\n        // 2. DST_prime = DST || I2OSP(len(DST), 1)\n        .update(DST)\n        .update(i2osp(DST.length, 1))\n        .digest());\n}\n/**\n * Hashes arbitrary-length byte strings to a list of one or more elements of a finite field F.\n * [RFC 9380 5.2](https://www.rfc-editor.org/rfc/rfc9380#section-5.2).\n * @param msg a byte string containing the message to hash\n * @param count the number of elements of F to output\n * @param options `{DST: string, p: bigint, m: number, k: number, expand: 'xmd' | 'xof', hash: H}`, see above\n * @returns [u_0, ..., u_(count - 1)], a list of field elements.\n */\nexport function hash_to_field(msg, count, options) {\n    validateObject(options, {\n        DST: 'stringOrUint8Array',\n        p: 'bigint',\n        m: 'isSafeInteger',\n        k: 'isSafeInteger',\n        hash: 'hash',\n    });\n    const { p, k, m, hash, expand, DST: _DST } = options;\n    abytes(msg);\n    anum(count);\n    const DST = typeof _DST === 'string' ? utf8ToBytes(_DST) : _DST;\n    const log2p = p.toString(2).length;\n    const L = Math.ceil((log2p + k) / 8); // section 5.1 of ietf draft link above\n    const len_in_bytes = count * m * L;\n    let prb; // pseudo_random_bytes\n    if (expand === 'xmd') {\n        prb = expand_message_xmd(msg, DST, len_in_bytes, hash);\n    }\n    else if (expand === 'xof') {\n        prb = expand_message_xof(msg, DST, len_in_bytes, k, hash);\n    }\n    else if (expand === '_internal_pass') {\n        // for internal tests only\n        prb = msg;\n    }\n    else {\n        throw new Error('expand must be \"xmd\" or \"xof\"');\n    }\n    const u = new Array(count);\n    for (let i = 0; i < count; i++) {\n        const e = new Array(m);\n        for (let j = 0; j < m; j++) {\n            const elm_offset = L * (j + i * m);\n            const tv = prb.subarray(elm_offset, elm_offset + L);\n            e[j] = mod(os2ip(tv), p);\n        }\n        u[i] = e;\n    }\n    return u;\n}\nexport function isogenyMap(field, map) {\n    // Make same order as in spec\n    const coeff = map.map((i) => Array.from(i).reverse());\n    return (x, y) => {\n        const [xn, xd, yn, yd] = coeff.map((val) => val.reduce((acc, i) => field.add(field.mul(acc, x), i)));\n        // 6.6.3\n        // Exceptional cases of iso_map are inputs that cause the denominator of\n        // either rational function to evaluate to zero; such cases MUST return\n        // the identity point on E.\n        const [xd_inv, yd_inv] = FpInvertBatch(field, [xd, yd], true);\n        x = field.mul(xn, xd_inv); // xNum / xDen\n        y = field.mul(y, field.mul(yn, yd_inv)); // y * (yNum / yDev)\n        return { x, y };\n    };\n}\n/** Creates hash-to-curve methods from EC Point and mapToCurve function. */\nexport function createHasher(Point, mapToCurve, defaults) {\n    if (typeof mapToCurve !== 'function')\n        throw new Error('mapToCurve() must be defined');\n    function map(num) {\n        return Point.fromAffine(mapToCurve(num));\n    }\n    function clear(initial) {\n        const P = initial.clearCofactor();\n        if (P.equals(Point.ZERO))\n            return Point.ZERO; // zero will throw in assert\n        P.assertValidity();\n        return P;\n    }\n    return {\n        defaults,\n        // Encodes byte string to elliptic curve.\n        // hash_to_curve from https://www.rfc-editor.org/rfc/rfc9380#section-3\n        hashToCurve(msg, options) {\n            const u = hash_to_field(msg, 2, { ...defaults, DST: defaults.DST, ...options });\n            const u0 = map(u[0]);\n            const u1 = map(u[1]);\n            return clear(u0.add(u1));\n        },\n        // Encodes byte string to elliptic curve.\n        // encode_to_curve from https://www.rfc-editor.org/rfc/rfc9380#section-3\n        encodeToCurve(msg, options) {\n            const u = hash_to_field(msg, 1, { ...defaults, DST: defaults.encodeDST, ...options });\n            return clear(map(u[0]));\n        },\n        // Same as encodeToCurve, but without hash\n        mapToCurve(scalars) {\n            if (!Array.isArray(scalars))\n                throw new Error('expected array of bigints');\n            for (const i of scalars)\n                if (typeof i !== 'bigint')\n                    throw new Error('expected array of bigints');\n            return clear(map(scalars));\n        },\n    };\n}\n//# sourceMappingURL=hash-to-curve.js.map","/**\n * Utils for modular division and finite fields.\n * A finite field over 11 is integer number operations `mod 11`.\n * There is no division: it is replaced by modular multiplicative inverse.\n * @module\n */\n/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\nimport { anumber } from '@noble/hashes/utils';\nimport { bitMask, bytesToNumberBE, bytesToNumberLE, ensureBytes, numberToBytesBE, numberToBytesLE, validateObject, } from \"./utils.js\";\n// prettier-ignore\nconst _0n = BigInt(0), _1n = BigInt(1), _2n = /* @__PURE__ */ BigInt(2), _3n = /* @__PURE__ */ BigInt(3);\n// prettier-ignore\nconst _4n = /* @__PURE__ */ BigInt(4), _5n = /* @__PURE__ */ BigInt(5), _8n = /* @__PURE__ */ BigInt(8);\n// Calculates a modulo b\nexport function mod(a, b) {\n    const result = a % b;\n    return result >= _0n ? result : b + result;\n}\n/**\n * Efficiently raise num to power and do modular division.\n * Unsafe in some contexts: uses ladder, so can expose bigint bits.\n * TODO: remove.\n * @example\n * pow(2n, 6n, 11n) // 64n % 11n == 9n\n */\nexport function pow(num, power, modulo) {\n    return FpPow(Field(modulo), num, power);\n}\n/** Does `x^(2^power)` mod p. `pow2(30, 4)` == `30^(2^4)` */\nexport function pow2(x, power, modulo) {\n    let res = x;\n    while (power-- > _0n) {\n        res *= res;\n        res %= modulo;\n    }\n    return res;\n}\n/**\n * Inverses number over modulo.\n * Implemented using [Euclidean GCD](https://brilliant.org/wiki/extended-euclidean-algorithm/).\n */\nexport function invert(number, modulo) {\n    if (number === _0n)\n        throw new Error('invert: expected non-zero number');\n    if (modulo <= _0n)\n        throw new Error('invert: expected positive modulus, got ' + modulo);\n    // Fermat's little theorem \"CT-like\" version inv(n) = n^(m-2) mod m is 30x slower.\n    let a = mod(number, modulo);\n    let b = modulo;\n    // prettier-ignore\n    let x = _0n, y = _1n, u = _1n, v = _0n;\n    while (a !== _0n) {\n        // JIT applies optimization if those two lines follow each other\n        const q = b / a;\n        const r = b % a;\n        const m = x - u * q;\n        const n = y - v * q;\n        // prettier-ignore\n        b = a, a = r, x = u, y = v, u = m, v = n;\n    }\n    const gcd = b;\n    if (gcd !== _1n)\n        throw new Error('invert: does not exist');\n    return mod(x, modulo);\n}\n// Not all roots are possible! Example which will throw:\n// const NUM =\n// n = 72057594037927816n;\n// Fp = Field(BigInt('0x1a0111ea397fe69a4b1ba7b6434bacd764774b84f38512bf6730d2a0f6b0f6241eabfffeb153ffffb9feffffffffaaab'));\nfunction sqrt3mod4(Fp, n) {\n    const p1div4 = (Fp.ORDER + _1n) / _4n;\n    const root = Fp.pow(n, p1div4);\n    // Throw if root^2 != n\n    if (!Fp.eql(Fp.sqr(root), n))\n        throw new Error('Cannot find square root');\n    return root;\n}\nfunction sqrt5mod8(Fp, n) {\n    const p5div8 = (Fp.ORDER - _5n) / _8n;\n    const n2 = Fp.mul(n, _2n);\n    const v = Fp.pow(n2, p5div8);\n    const nv = Fp.mul(n, v);\n    const i = Fp.mul(Fp.mul(nv, _2n), v);\n    const root = Fp.mul(nv, Fp.sub(i, Fp.ONE));\n    if (!Fp.eql(Fp.sqr(root), n))\n        throw new Error('Cannot find square root');\n    return root;\n}\n// TODO: Commented-out for now. Provide test vectors.\n// Tonelli is too slow for extension fields Fp2.\n// That means we can't use sqrt (c1, c2...) even for initialization constants.\n// if (P % _16n === _9n) return sqrt9mod16;\n// // prettier-ignore\n// function sqrt9mod16<T>(Fp: IField<T>, n: T, p7div16?: bigint) {\n//   if (p7div16 === undefined) p7div16 = (Fp.ORDER + BigInt(7)) / _16n;\n//   const c1 = Fp.sqrt(Fp.neg(Fp.ONE)); //  1. c1 = sqrt(-1) in F, i.e., (c1^2) == -1 in F\n//   const c2 = Fp.sqrt(c1);             //  2. c2 = sqrt(c1) in F, i.e., (c2^2) == c1 in F\n//   const c3 = Fp.sqrt(Fp.neg(c1));     //  3. c3 = sqrt(-c1) in F, i.e., (c3^2) == -c1 in F\n//   const c4 = p7div16;                 //  4. c4 = (q + 7) / 16        # Integer arithmetic\n//   let tv1 = Fp.pow(n, c4);            //  1. tv1 = x^c4\n//   let tv2 = Fp.mul(c1, tv1);          //  2. tv2 = c1 * tv1\n//   const tv3 = Fp.mul(c2, tv1);        //  3. tv3 = c2 * tv1\n//   let tv4 = Fp.mul(c3, tv1);          //  4. tv4 = c3 * tv1\n//   const e1 = Fp.eql(Fp.sqr(tv2), n);  //  5.  e1 = (tv2^2) == x\n//   const e2 = Fp.eql(Fp.sqr(tv3), n);  //  6.  e2 = (tv3^2) == x\n//   tv1 = Fp.cmov(tv1, tv2, e1); //  7. tv1 = CMOV(tv1, tv2, e1)  # Select tv2 if (tv2^2) == x\n//   tv2 = Fp.cmov(tv4, tv3, e2); //  8. tv2 = CMOV(tv4, tv3, e2)  # Select tv3 if (tv3^2) == x\n//   const e3 = Fp.eql(Fp.sqr(tv2), n);  //  9.  e3 = (tv2^2) == x\n//   return Fp.cmov(tv1, tv2, e3); // 10.  z = CMOV(tv1, tv2, e3) # Select the sqrt from tv1 and tv2\n// }\n/**\n * Tonelli-Shanks square root search algorithm.\n * 1. https://eprint.iacr.org/2012/685.pdf (page 12)\n * 2. Square Roots from 1; 24, 51, 10 to Dan Shanks\n * @param P field order\n * @returns function that takes field Fp (created from P) and number n\n */\nexport function tonelliShanks(P) {\n    // Initialization (precomputation).\n    if (P < BigInt(3))\n        throw new Error('sqrt is not defined for small field');\n    // Factor P - 1 = Q * 2^S, where Q is odd\n    let Q = P - _1n;\n    let S = 0;\n    while (Q % _2n === _0n) {\n        Q /= _2n;\n        S++;\n    }\n    // Find the first quadratic non-residue Z >= 2\n    let Z = _2n;\n    const _Fp = Field(P);\n    while (FpLegendre(_Fp, Z) === 1) {\n        // Basic primality test for P. After x iterations, chance of\n        // not finding quadratic non-residue is 2^x, so 2^1000.\n        if (Z++ > 1000)\n            throw new Error('Cannot find square root: probably non-prime P');\n    }\n    // Fast-path; usually done before Z, but we do \"primality test\".\n    if (S === 1)\n        return sqrt3mod4;\n    // Slow-path\n    // TODO: test on Fp2 and others\n    let cc = _Fp.pow(Z, Q); // c = z^Q\n    const Q1div2 = (Q + _1n) / _2n;\n    return function tonelliSlow(Fp, n) {\n        if (Fp.is0(n))\n            return n;\n        // Check if n is a quadratic residue using Legendre symbol\n        if (FpLegendre(Fp, n) !== 1)\n            throw new Error('Cannot find square root');\n        // Initialize variables for the main loop\n        let M = S;\n        let c = Fp.mul(Fp.ONE, cc); // c = z^Q, move cc from field _Fp into field Fp\n        let t = Fp.pow(n, Q); // t = n^Q, first guess at the fudge factor\n        let R = Fp.pow(n, Q1div2); // R = n^((Q+1)/2), first guess at the square root\n        // Main loop\n        // while t != 1\n        while (!Fp.eql(t, Fp.ONE)) {\n            if (Fp.is0(t))\n                return Fp.ZERO; // if t=0 return R=0\n            let i = 1;\n            // Find the smallest i >= 1 such that t^(2^i)  1 (mod P)\n            let t_tmp = Fp.sqr(t); // t^(2^1)\n            while (!Fp.eql(t_tmp, Fp.ONE)) {\n                i++;\n                t_tmp = Fp.sqr(t_tmp); // t^(2^2)...\n                if (i === M)\n                    throw new Error('Cannot find square root');\n            }\n            // Calculate the exponent for b: 2^(M - i - 1)\n            const exponent = _1n << BigInt(M - i - 1); // bigint is important\n            const b = Fp.pow(c, exponent); // b = 2^(M - i - 1)\n            // Update variables\n            M = i;\n            c = Fp.sqr(b); // c = b^2\n            t = Fp.mul(t, c); // t = (t * b^2)\n            R = Fp.mul(R, b); // R = R*b\n        }\n        return R;\n    };\n}\n/**\n * Square root for a finite field. Will try optimized versions first:\n *\n * 1. P  3 (mod 4)\n * 2. P  5 (mod 8)\n * 3. Tonelli-Shanks algorithm\n *\n * Different algorithms can give different roots, it is up to user to decide which one they want.\n * For example there is FpSqrtOdd/FpSqrtEven to choice root based on oddness (used for hash-to-curve).\n */\nexport function FpSqrt(P) {\n    // P  3 (mod 4) => n = n^((P+1)/4)\n    if (P % _4n === _3n)\n        return sqrt3mod4;\n    // P  5 (mod 8) => Atkin algorithm, page 10 of https://eprint.iacr.org/2012/685.pdf\n    if (P % _8n === _5n)\n        return sqrt5mod8;\n    // P  9 (mod 16) not implemented, see above\n    // Tonelli-Shanks algorithm\n    return tonelliShanks(P);\n}\n// Little-endian check for first LE bit (last BE bit);\nexport const isNegativeLE = (num, modulo) => (mod(num, modulo) & _1n) === _1n;\n// prettier-ignore\nconst FIELD_FIELDS = [\n    'create', 'isValid', 'is0', 'neg', 'inv', 'sqrt', 'sqr',\n    'eql', 'add', 'sub', 'mul', 'pow', 'div',\n    'addN', 'subN', 'mulN', 'sqrN'\n];\nexport function validateField(field) {\n    const initial = {\n        ORDER: 'bigint',\n        MASK: 'bigint',\n        BYTES: 'isSafeInteger',\n        BITS: 'isSafeInteger',\n    };\n    const opts = FIELD_FIELDS.reduce((map, val) => {\n        map[val] = 'function';\n        return map;\n    }, initial);\n    return validateObject(field, opts);\n}\n// Generic field functions\n/**\n * Same as `pow` but for Fp: non-constant-time.\n * Unsafe in some contexts: uses ladder, so can expose bigint bits.\n */\nexport function FpPow(Fp, num, power) {\n    if (power < _0n)\n        throw new Error('invalid exponent, negatives unsupported');\n    if (power === _0n)\n        return Fp.ONE;\n    if (power === _1n)\n        return num;\n    let p = Fp.ONE;\n    let d = num;\n    while (power > _0n) {\n        if (power & _1n)\n            p = Fp.mul(p, d);\n        d = Fp.sqr(d);\n        power >>= _1n;\n    }\n    return p;\n}\n/**\n * Efficiently invert an array of Field elements.\n * Exception-free. Will return `undefined` for 0 elements.\n * @param passZero map 0 to 0 (instead of undefined)\n */\nexport function FpInvertBatch(Fp, nums, passZero = false) {\n    const inverted = new Array(nums.length).fill(passZero ? Fp.ZERO : undefined);\n    // Walk from first to last, multiply them by each other MOD p\n    const multipliedAcc = nums.reduce((acc, num, i) => {\n        if (Fp.is0(num))\n            return acc;\n        inverted[i] = acc;\n        return Fp.mul(acc, num);\n    }, Fp.ONE);\n    // Invert last element\n    const invertedAcc = Fp.inv(multipliedAcc);\n    // Walk from last to first, multiply them by inverted each other MOD p\n    nums.reduceRight((acc, num, i) => {\n        if (Fp.is0(num))\n            return acc;\n        inverted[i] = Fp.mul(acc, inverted[i]);\n        return Fp.mul(acc, num);\n    }, invertedAcc);\n    return inverted;\n}\n// TODO: remove\nexport function FpDiv(Fp, lhs, rhs) {\n    return Fp.mul(lhs, typeof rhs === 'bigint' ? invert(rhs, Fp.ORDER) : Fp.inv(rhs));\n}\n/**\n * Legendre symbol.\n * Legendre constant is used to calculate Legendre symbol (a | p)\n * which denotes the value of a^((p-1)/2) (mod p).\n *\n * * (a | p)  1    if a is a square (mod p), quadratic residue\n * * (a | p)  -1   if a is not a square (mod p), quadratic non residue\n * * (a | p)  0    if a  0 (mod p)\n */\nexport function FpLegendre(Fp, n) {\n    // We can use 3rd argument as optional cache of this value\n    // but seems unneeded for now. The operation is very fast.\n    const p1mod2 = (Fp.ORDER - _1n) / _2n;\n    const powered = Fp.pow(n, p1mod2);\n    const yes = Fp.eql(powered, Fp.ONE);\n    const zero = Fp.eql(powered, Fp.ZERO);\n    const no = Fp.eql(powered, Fp.neg(Fp.ONE));\n    if (!yes && !zero && !no)\n        throw new Error('invalid Legendre symbol result');\n    return yes ? 1 : zero ? 0 : -1;\n}\n// This function returns True whenever the value x is a square in the field F.\nexport function FpIsSquare(Fp, n) {\n    const l = FpLegendre(Fp, n);\n    return l === 1;\n}\n// CURVE.n lengths\nexport function nLength(n, nBitLength) {\n    // Bit size, byte size of CURVE.n\n    if (nBitLength !== undefined)\n        anumber(nBitLength);\n    const _nBitLength = nBitLength !== undefined ? nBitLength : n.toString(2).length;\n    const nByteLength = Math.ceil(_nBitLength / 8);\n    return { nBitLength: _nBitLength, nByteLength };\n}\n/**\n * Initializes a finite field over prime.\n * Major performance optimizations:\n * * a) denormalized operations like mulN instead of mul\n * * b) same object shape: never add or remove keys\n * * c) Object.freeze\n * Fragile: always run a benchmark on a change.\n * Security note: operations don't check 'isValid' for all elements for performance reasons,\n * it is caller responsibility to check this.\n * This is low-level code, please make sure you know what you're doing.\n * @param ORDER prime positive bigint\n * @param bitLen how many bits the field consumes\n * @param isLE (def: false) if encoding / decoding should be in little-endian\n * @param redef optional faster redefinitions of sqrt and other methods\n */\nexport function Field(ORDER, bitLen, isLE = false, redef = {}) {\n    if (ORDER <= _0n)\n        throw new Error('invalid field: expected ORDER > 0, got ' + ORDER);\n    const { nBitLength: BITS, nByteLength: BYTES } = nLength(ORDER, bitLen);\n    if (BYTES > 2048)\n        throw new Error('invalid field: expected ORDER of <= 2048 bytes');\n    let sqrtP; // cached sqrtP\n    const f = Object.freeze({\n        ORDER,\n        isLE,\n        BITS,\n        BYTES,\n        MASK: bitMask(BITS),\n        ZERO: _0n,\n        ONE: _1n,\n        create: (num) => mod(num, ORDER),\n        isValid: (num) => {\n            if (typeof num !== 'bigint')\n                throw new Error('invalid field element: expected bigint, got ' + typeof num);\n            return _0n <= num && num < ORDER; // 0 is valid element, but it's not invertible\n        },\n        is0: (num) => num === _0n,\n        isOdd: (num) => (num & _1n) === _1n,\n        neg: (num) => mod(-num, ORDER),\n        eql: (lhs, rhs) => lhs === rhs,\n        sqr: (num) => mod(num * num, ORDER),\n        add: (lhs, rhs) => mod(lhs + rhs, ORDER),\n        sub: (lhs, rhs) => mod(lhs - rhs, ORDER),\n        mul: (lhs, rhs) => mod(lhs * rhs, ORDER),\n        pow: (num, power) => FpPow(f, num, power),\n        div: (lhs, rhs) => mod(lhs * invert(rhs, ORDER), ORDER),\n        // Same as above, but doesn't normalize\n        sqrN: (num) => num * num,\n        addN: (lhs, rhs) => lhs + rhs,\n        subN: (lhs, rhs) => lhs - rhs,\n        mulN: (lhs, rhs) => lhs * rhs,\n        inv: (num) => invert(num, ORDER),\n        sqrt: redef.sqrt ||\n            ((n) => {\n                if (!sqrtP)\n                    sqrtP = FpSqrt(ORDER);\n                return sqrtP(f, n);\n            }),\n        toBytes: (num) => (isLE ? numberToBytesLE(num, BYTES) : numberToBytesBE(num, BYTES)),\n        fromBytes: (bytes) => {\n            if (bytes.length !== BYTES)\n                throw new Error('Field.fromBytes: expected ' + BYTES + ' bytes, got ' + bytes.length);\n            return isLE ? bytesToNumberLE(bytes) : bytesToNumberBE(bytes);\n        },\n        // TODO: we don't need it here, move out to separate fn\n        invertBatch: (lst) => FpInvertBatch(f, lst),\n        // We can't move this out because Fp6, Fp12 implement it\n        // and it's unclear what to return in there.\n        cmov: (a, b, c) => (c ? b : a),\n    });\n    return Object.freeze(f);\n}\nexport function FpSqrtOdd(Fp, elm) {\n    if (!Fp.isOdd)\n        throw new Error(\"Field doesn't have isOdd\");\n    const root = Fp.sqrt(elm);\n    return Fp.isOdd(root) ? root : Fp.neg(root);\n}\nexport function FpSqrtEven(Fp, elm) {\n    if (!Fp.isOdd)\n        throw new Error(\"Field doesn't have isOdd\");\n    const root = Fp.sqrt(elm);\n    return Fp.isOdd(root) ? Fp.neg(root) : root;\n}\n/**\n * \"Constant-time\" private key generation utility.\n * Same as mapKeyToField, but accepts less bytes (40 instead of 48 for 32-byte field).\n * Which makes it slightly more biased, less secure.\n * @deprecated use `mapKeyToField` instead\n */\nexport function hashToPrivateScalar(hash, groupOrder, isLE = false) {\n    hash = ensureBytes('privateHash', hash);\n    const hashLen = hash.length;\n    const minLen = nLength(groupOrder).nByteLength + 8;\n    if (minLen < 24 || hashLen < minLen || hashLen > 1024)\n        throw new Error('hashToPrivateScalar: expected ' + minLen + '-1024 bytes of input, got ' + hashLen);\n    const num = isLE ? bytesToNumberLE(hash) : bytesToNumberBE(hash);\n    return mod(num, groupOrder - _1n) + _1n;\n}\n/**\n * Returns total number of bytes consumed by the field element.\n * For example, 32 bytes for usual 256-bit weierstrass curve.\n * @param fieldOrder number of field elements, usually CURVE.n\n * @returns byte length of field\n */\nexport function getFieldBytesLength(fieldOrder) {\n    if (typeof fieldOrder !== 'bigint')\n        throw new Error('field order must be bigint');\n    const bitLength = fieldOrder.toString(2).length;\n    return Math.ceil(bitLength / 8);\n}\n/**\n * Returns minimal amount of bytes that can be safely reduced\n * by field order.\n * Should be 2^-128 for 128-bit curve such as P256.\n * @param fieldOrder number of field elements, usually CURVE.n\n * @returns byte length of target hash\n */\nexport function getMinHashLength(fieldOrder) {\n    const length = getFieldBytesLength(fieldOrder);\n    return length + Math.ceil(length / 2);\n}\n/**\n * \"Constant-time\" private key generation utility.\n * Can take (n + n/2) or more bytes of uniform input e.g. from CSPRNG or KDF\n * and convert them into private scalar, with the modulo bias being negligible.\n * Needs at least 48 bytes of input for 32-byte private key.\n * https://research.kudelskisecurity.com/2020/07/28/the-definitive-guide-to-modulo-bias-and-how-to-avoid-it/\n * FIPS 186-5, A.2 https://csrc.nist.gov/publications/detail/fips/186/5/final\n * RFC 9380, https://www.rfc-editor.org/rfc/rfc9380#section-5\n * @param hash hash output from SHA3 or a similar function\n * @param groupOrder size of subgroup - (e.g. secp256k1.CURVE.n)\n * @param isLE interpret hash bytes as LE num\n * @returns valid private scalar\n */\nexport function mapHashToField(key, fieldOrder, isLE = false) {\n    const len = key.length;\n    const fieldLen = getFieldBytesLength(fieldOrder);\n    const minLen = getMinHashLength(fieldOrder);\n    // No small numbers: need to understand bias story. No huge numbers: easier to detect JS timings.\n    if (len < 16 || len < minLen || len > 1024)\n        throw new Error('expected ' + minLen + '-1024 bytes of input, got ' + len);\n    const num = isLE ? bytesToNumberLE(key) : bytesToNumberBE(key);\n    // `mod(x, 11)` can sometimes produce 0. `mod(x, 10) + 1` is the same, but no 0\n    const reduced = mod(num, fieldOrder - _1n) + _1n;\n    return isLE ? numberToBytesLE(reduced, fieldLen) : numberToBytesBE(reduced, fieldLen);\n}\n//# sourceMappingURL=modular.js.map","/**\n * Hex, bytes and number utilities.\n * @module\n */\n/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\n// 100 lines of code in the file are duplicated from noble-hashes (utils).\n// This is OK: `abstract` directory does not use noble-hashes.\n// User may opt-in into using different hashing library. This way, noble-hashes\n// won't be included into their bundle.\nconst _0n = /* @__PURE__ */ BigInt(0);\nconst _1n = /* @__PURE__ */ BigInt(1);\nexport function isBytes(a) {\n    return a instanceof Uint8Array || (ArrayBuffer.isView(a) && a.constructor.name === 'Uint8Array');\n}\nexport function abytes(item) {\n    if (!isBytes(item))\n        throw new Error('Uint8Array expected');\n}\nexport function abool(title, value) {\n    if (typeof value !== 'boolean')\n        throw new Error(title + ' boolean expected, got ' + value);\n}\n// Used in weierstrass, der\nexport function numberToHexUnpadded(num) {\n    const hex = num.toString(16);\n    return hex.length & 1 ? '0' + hex : hex;\n}\nexport function hexToNumber(hex) {\n    if (typeof hex !== 'string')\n        throw new Error('hex string expected, got ' + typeof hex);\n    return hex === '' ? _0n : BigInt('0x' + hex); // Big Endian\n}\n// Built-in hex conversion https://caniuse.com/mdn-javascript_builtins_uint8array_fromhex\nconst hasHexBuiltin = \n// @ts-ignore\ntypeof Uint8Array.from([]).toHex === 'function' && typeof Uint8Array.fromHex === 'function';\n// Array where index 0xf0 (240) is mapped to string 'f0'\nconst hexes = /* @__PURE__ */ Array.from({ length: 256 }, (_, i) => i.toString(16).padStart(2, '0'));\n/**\n * Convert byte array to hex string. Uses built-in function, when available.\n * @example bytesToHex(Uint8Array.from([0xca, 0xfe, 0x01, 0x23])) // 'cafe0123'\n */\nexport function bytesToHex(bytes) {\n    abytes(bytes);\n    // @ts-ignore\n    if (hasHexBuiltin)\n        return bytes.toHex();\n    // pre-caching improves the speed 6x\n    let hex = '';\n    for (let i = 0; i < bytes.length; i++) {\n        hex += hexes[bytes[i]];\n    }\n    return hex;\n}\n// We use optimized technique to convert hex string to byte array\nconst asciis = { _0: 48, _9: 57, A: 65, F: 70, a: 97, f: 102 };\nfunction asciiToBase16(ch) {\n    if (ch >= asciis._0 && ch <= asciis._9)\n        return ch - asciis._0; // '2' => 50-48\n    if (ch >= asciis.A && ch <= asciis.F)\n        return ch - (asciis.A - 10); // 'B' => 66-(65-10)\n    if (ch >= asciis.a && ch <= asciis.f)\n        return ch - (asciis.a - 10); // 'b' => 98-(97-10)\n    return;\n}\n/**\n * Convert hex string to byte array. Uses built-in function, when available.\n * @example hexToBytes('cafe0123') // Uint8Array.from([0xca, 0xfe, 0x01, 0x23])\n */\nexport function hexToBytes(hex) {\n    if (typeof hex !== 'string')\n        throw new Error('hex string expected, got ' + typeof hex);\n    // @ts-ignore\n    if (hasHexBuiltin)\n        return Uint8Array.fromHex(hex);\n    const hl = hex.length;\n    const al = hl / 2;\n    if (hl % 2)\n        throw new Error('hex string expected, got unpadded hex of length ' + hl);\n    const array = new Uint8Array(al);\n    for (let ai = 0, hi = 0; ai < al; ai++, hi += 2) {\n        const n1 = asciiToBase16(hex.charCodeAt(hi));\n        const n2 = asciiToBase16(hex.charCodeAt(hi + 1));\n        if (n1 === undefined || n2 === undefined) {\n            const char = hex[hi] + hex[hi + 1];\n            throw new Error('hex string expected, got non-hex character \"' + char + '\" at index ' + hi);\n        }\n        array[ai] = n1 * 16 + n2; // multiply first octet, e.g. 'a3' => 10*16+3 => 160 + 3 => 163\n    }\n    return array;\n}\n// BE: Big Endian, LE: Little Endian\nexport function bytesToNumberBE(bytes) {\n    return hexToNumber(bytesToHex(bytes));\n}\nexport function bytesToNumberLE(bytes) {\n    abytes(bytes);\n    return hexToNumber(bytesToHex(Uint8Array.from(bytes).reverse()));\n}\nexport function numberToBytesBE(n, len) {\n    return hexToBytes(n.toString(16).padStart(len * 2, '0'));\n}\nexport function numberToBytesLE(n, len) {\n    return numberToBytesBE(n, len).reverse();\n}\n// Unpadded, rarely used\nexport function numberToVarBytesBE(n) {\n    return hexToBytes(numberToHexUnpadded(n));\n}\n/**\n * Takes hex string or Uint8Array, converts to Uint8Array.\n * Validates output length.\n * Will throw error for other types.\n * @param title descriptive title for an error e.g. 'private key'\n * @param hex hex string or Uint8Array\n * @param expectedLength optional, will compare to result array's length\n * @returns\n */\nexport function ensureBytes(title, hex, expectedLength) {\n    let res;\n    if (typeof hex === 'string') {\n        try {\n            res = hexToBytes(hex);\n        }\n        catch (e) {\n            throw new Error(title + ' must be hex string or Uint8Array, cause: ' + e);\n        }\n    }\n    else if (isBytes(hex)) {\n        // Uint8Array.from() instead of hash.slice() because node.js Buffer\n        // is instance of Uint8Array, and its slice() creates **mutable** copy\n        res = Uint8Array.from(hex);\n    }\n    else {\n        throw new Error(title + ' must be hex string or Uint8Array');\n    }\n    const len = res.length;\n    if (typeof expectedLength === 'number' && len !== expectedLength)\n        throw new Error(title + ' of length ' + expectedLength + ' expected, got ' + len);\n    return res;\n}\n/**\n * Copies several Uint8Arrays into one.\n */\nexport function concatBytes(...arrays) {\n    let sum = 0;\n    for (let i = 0; i < arrays.length; i++) {\n        const a = arrays[i];\n        abytes(a);\n        sum += a.length;\n    }\n    const res = new Uint8Array(sum);\n    for (let i = 0, pad = 0; i < arrays.length; i++) {\n        const a = arrays[i];\n        res.set(a, pad);\n        pad += a.length;\n    }\n    return res;\n}\n// Compares 2 u8a-s in kinda constant time\nexport function equalBytes(a, b) {\n    if (a.length !== b.length)\n        return false;\n    let diff = 0;\n    for (let i = 0; i < a.length; i++)\n        diff |= a[i] ^ b[i];\n    return diff === 0;\n}\n/**\n * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])\n */\nexport function utf8ToBytes(str) {\n    if (typeof str !== 'string')\n        throw new Error('string expected');\n    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809\n}\n// Is positive bigint\nconst isPosBig = (n) => typeof n === 'bigint' && _0n <= n;\nexport function inRange(n, min, max) {\n    return isPosBig(n) && isPosBig(min) && isPosBig(max) && min <= n && n < max;\n}\n/**\n * Asserts min <= n < max. NOTE: It's < max and not <= max.\n * @example\n * aInRange('x', x, 1n, 256n); // would assume x is in (1n..255n)\n */\nexport function aInRange(title, n, min, max) {\n    // Why min <= n < max and not a (min < n < max) OR b (min <= n <= max)?\n    // consider P=256n, min=0n, max=P\n    // - a for min=0 would require -1:          `inRange('x', x, -1n, P)`\n    // - b would commonly require subtraction:  `inRange('x', x, 0n, P - 1n)`\n    // - our way is the cleanest:               `inRange('x', x, 0n, P)\n    if (!inRange(n, min, max))\n        throw new Error('expected valid ' + title + ': ' + min + ' <= n < ' + max + ', got ' + n);\n}\n// Bit operations\n/**\n * Calculates amount of bits in a bigint.\n * Same as `n.toString(2).length`\n * TODO: merge with nLength in modular\n */\nexport function bitLen(n) {\n    let len;\n    for (len = 0; n > _0n; n >>= _1n, len += 1)\n        ;\n    return len;\n}\n/**\n * Gets single bit at position.\n * NOTE: first bit position is 0 (same as arrays)\n * Same as `!!+Array.from(n.toString(2)).reverse()[pos]`\n */\nexport function bitGet(n, pos) {\n    return (n >> BigInt(pos)) & _1n;\n}\n/**\n * Sets single bit at position.\n */\nexport function bitSet(n, pos, value) {\n    return n | ((value ? _1n : _0n) << BigInt(pos));\n}\n/**\n * Calculate mask for N bits. Not using ** operator with bigints because of old engines.\n * Same as BigInt(`0b${Array(i).fill('1').join('')}`)\n */\nexport const bitMask = (n) => (_1n << BigInt(n)) - _1n;\n// DRBG\nconst u8n = (len) => new Uint8Array(len); // creates Uint8Array\nconst u8fr = (arr) => Uint8Array.from(arr); // another shortcut\n/**\n * Minimal HMAC-DRBG from NIST 800-90 for RFC6979 sigs.\n * @returns function that will call DRBG until 2nd arg returns something meaningful\n * @example\n *   const drbg = createHmacDRBG<Key>(32, 32, hmac);\n *   drbg(seed, bytesToKey); // bytesToKey must return Key or undefined\n */\nexport function createHmacDrbg(hashLen, qByteLen, hmacFn) {\n    if (typeof hashLen !== 'number' || hashLen < 2)\n        throw new Error('hashLen must be a number');\n    if (typeof qByteLen !== 'number' || qByteLen < 2)\n        throw new Error('qByteLen must be a number');\n    if (typeof hmacFn !== 'function')\n        throw new Error('hmacFn must be a function');\n    // Step B, Step C: set hashLen to 8*ceil(hlen/8)\n    let v = u8n(hashLen); // Minimal non-full-spec HMAC-DRBG from NIST 800-90 for RFC6979 sigs.\n    let k = u8n(hashLen); // Steps B and C of RFC6979 3.2: set hashLen, in our case always same\n    let i = 0; // Iterations counter, will throw when over 1000\n    const reset = () => {\n        v.fill(1);\n        k.fill(0);\n        i = 0;\n    };\n    const h = (...b) => hmacFn(k, v, ...b); // hmac(k)(v, ...values)\n    const reseed = (seed = u8n(0)) => {\n        // HMAC-DRBG reseed() function. Steps D-G\n        k = h(u8fr([0x00]), seed); // k = hmac(k || v || 0x00 || seed)\n        v = h(); // v = hmac(k || v)\n        if (seed.length === 0)\n            return;\n        k = h(u8fr([0x01]), seed); // k = hmac(k || v || 0x01 || seed)\n        v = h(); // v = hmac(k || v)\n    };\n    const gen = () => {\n        // HMAC-DRBG generate() function\n        if (i++ >= 1000)\n            throw new Error('drbg: tried 1000 values');\n        let len = 0;\n        const out = [];\n        while (len < qByteLen) {\n            v = h();\n            const sl = v.slice();\n            out.push(sl);\n            len += v.length;\n        }\n        return concatBytes(...out);\n    };\n    const genUntil = (seed, pred) => {\n        reset();\n        reseed(seed); // Steps D-G\n        let res = undefined; // Step H: grind until k is in [1..n-1]\n        while (!(res = pred(gen())))\n            reseed();\n        reset();\n        return res;\n    };\n    return genUntil;\n}\n// Validating curves and fields\nconst validatorFns = {\n    bigint: (val) => typeof val === 'bigint',\n    function: (val) => typeof val === 'function',\n    boolean: (val) => typeof val === 'boolean',\n    string: (val) => typeof val === 'string',\n    stringOrUint8Array: (val) => typeof val === 'string' || isBytes(val),\n    isSafeInteger: (val) => Number.isSafeInteger(val),\n    array: (val) => Array.isArray(val),\n    field: (val, object) => object.Fp.isValid(val),\n    hash: (val) => typeof val === 'function' && Number.isSafeInteger(val.outputLen),\n};\n// type Record<K extends string | number | symbol, T> = { [P in K]: T; }\nexport function validateObject(object, validators, optValidators = {}) {\n    const checkField = (fieldName, type, isOptional) => {\n        const checkVal = validatorFns[type];\n        if (typeof checkVal !== 'function')\n            throw new Error('invalid validator function');\n        const val = object[fieldName];\n        if (isOptional && val === undefined)\n            return;\n        if (!checkVal(val, object)) {\n            throw new Error('param ' + String(fieldName) + ' is invalid. Expected ' + type + ', got ' + val);\n        }\n    };\n    for (const [fieldName, type] of Object.entries(validators))\n        checkField(fieldName, type, false);\n    for (const [fieldName, type] of Object.entries(optValidators))\n        checkField(fieldName, type, true);\n    return object;\n}\n// validate type tests\n// const o: { a: number; b: number; c: number } = { a: 1, b: 5, c: 6 };\n// const z0 = validateObject(o, { a: 'isSafeInteger' }, { c: 'bigint' }); // Ok!\n// // Should fail type-check\n// const z1 = validateObject(o, { a: 'tmp' }, { c: 'zz' });\n// const z2 = validateObject(o, { a: 'isSafeInteger' }, { c: 'zz' });\n// const z3 = validateObject(o, { test: 'boolean', z: 'bug' });\n// const z4 = validateObject(o, { a: 'boolean', z: 'bug' });\n/**\n * throws not implemented error\n */\nexport const notImplemented = () => {\n    throw new Error('not implemented');\n};\n/**\n * Memoizes (caches) computation result.\n * Uses WeakMap: the value is going auto-cleaned by GC after last reference is removed.\n */\nexport function memoized(fn) {\n    const map = new WeakMap();\n    return (arg, ...args) => {\n        const val = map.get(arg);\n        if (val !== undefined)\n            return val;\n        const computed = fn(arg, ...args);\n        map.set(arg, computed);\n        return computed;\n    };\n}\n//# sourceMappingURL=utils.js.map","/**\n * Short Weierstrass curve methods. The formula is: y = x + ax + b.\n *\n * ### Parameters\n *\n * To initialize a weierstrass curve, one needs to pass following params:\n *\n * * a: formula param\n * * b: formula param\n * * Fp: finite field of prime characteristic P; may be complex (Fp2). Arithmetics is done in field\n * * n: order of prime subgroup a.k.a total amount of valid curve points\n * * Gx: Base point (x, y) aka generator point. Gx = x coordinate\n * * Gy: ...y coordinate\n * * h: cofactor, usually 1. h*n = curve group order (n is only subgroup order)\n * * lowS: whether to enable (default) or disable \"low-s\" non-malleable signatures\n *\n * ### Design rationale for types\n *\n * * Interaction between classes from different curves should fail:\n *   `k256.Point.BASE.add(p256.Point.BASE)`\n * * For this purpose we want to use `instanceof` operator, which is fast and works during runtime\n * * Different calls of `curve()` would return different classes -\n *   `curve(params) !== curve(params)`: if somebody decided to monkey-patch their curve,\n *   it won't affect others\n *\n * TypeScript can't infer types for classes created inside a function. Classes is one instance\n * of nominative types in TypeScript and interfaces only check for shape, so it's hard to create\n * unique type for every function call.\n *\n * We can use generic types via some param, like curve opts, but that would:\n *     1. Enable interaction between `curve(params)` and `curve(params)` (curves of same params)\n *     which is hard to debug.\n *     2. Params can be generic and we can't enforce them to be constant value:\n *     if somebody creates curve from non-constant params,\n *     it would be allowed to interact with other curves with non-constant params\n *\n * @todo https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-7.html#unique-symbol\n * @module\n */\n/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\n// prettier-ignore\nimport { pippenger, validateBasic, wNAF } from \"./curve.js\";\n// prettier-ignore\nimport { Field, FpInvertBatch, getMinHashLength, invert, mapHashToField, mod, validateField } from \"./modular.js\";\n// prettier-ignore\nimport { aInRange, abool, bitMask, bytesToHex, bytesToNumberBE, concatBytes, createHmacDrbg, ensureBytes, hexToBytes, inRange, isBytes, memoized, numberToBytesBE, numberToHexUnpadded, validateObject } from \"./utils.js\";\nfunction validateSigVerOpts(opts) {\n    if (opts.lowS !== undefined)\n        abool('lowS', opts.lowS);\n    if (opts.prehash !== undefined)\n        abool('prehash', opts.prehash);\n}\nfunction validatePointOpts(curve) {\n    const opts = validateBasic(curve);\n    validateObject(opts, {\n        a: 'field',\n        b: 'field',\n    }, {\n        allowInfinityPoint: 'boolean',\n        allowedPrivateKeyLengths: 'array',\n        clearCofactor: 'function',\n        fromBytes: 'function',\n        isTorsionFree: 'function',\n        toBytes: 'function',\n        wrapPrivateKey: 'boolean',\n    });\n    const { endo, Fp, a } = opts;\n    if (endo) {\n        if (!Fp.eql(a, Fp.ZERO)) {\n            throw new Error('invalid endo: CURVE.a must be 0');\n        }\n        if (typeof endo !== 'object' ||\n            typeof endo.beta !== 'bigint' ||\n            typeof endo.splitScalar !== 'function') {\n            throw new Error('invalid endo: expected \"beta\": bigint and \"splitScalar\": function');\n        }\n    }\n    return Object.freeze({ ...opts });\n}\nexport class DERErr extends Error {\n    constructor(m = '') {\n        super(m);\n    }\n}\n/**\n * ASN.1 DER encoding utilities. ASN is very complex & fragile. Format:\n *\n *     [0x30 (SEQUENCE), bytelength, 0x02 (INTEGER), intLength, R, 0x02 (INTEGER), intLength, S]\n *\n * Docs: https://letsencrypt.org/docs/a-warm-welcome-to-asn1-and-der/, https://luca.ntop.org/Teaching/Appunti/asn1.html\n */\nexport const DER = {\n    // asn.1 DER encoding utils\n    Err: DERErr,\n    // Basic building block is TLV (Tag-Length-Value)\n    _tlv: {\n        encode: (tag, data) => {\n            const { Err: E } = DER;\n            if (tag < 0 || tag > 256)\n                throw new E('tlv.encode: wrong tag');\n            if (data.length & 1)\n                throw new E('tlv.encode: unpadded data');\n            const dataLen = data.length / 2;\n            const len = numberToHexUnpadded(dataLen);\n            if ((len.length / 2) & 128)\n                throw new E('tlv.encode: long form length too big');\n            // length of length with long form flag\n            const lenLen = dataLen > 127 ? numberToHexUnpadded((len.length / 2) | 128) : '';\n            const t = numberToHexUnpadded(tag);\n            return t + lenLen + len + data;\n        },\n        // v - value, l - left bytes (unparsed)\n        decode(tag, data) {\n            const { Err: E } = DER;\n            let pos = 0;\n            if (tag < 0 || tag > 256)\n                throw new E('tlv.encode: wrong tag');\n            if (data.length < 2 || data[pos++] !== tag)\n                throw new E('tlv.decode: wrong tlv');\n            const first = data[pos++];\n            const isLong = !!(first & 128); // First bit of first length byte is flag for short/long form\n            let length = 0;\n            if (!isLong)\n                length = first;\n            else {\n                // Long form: [longFlag(1bit), lengthLength(7bit), length (BE)]\n                const lenLen = first & 127;\n                if (!lenLen)\n                    throw new E('tlv.decode(long): indefinite length not supported');\n                if (lenLen > 4)\n                    throw new E('tlv.decode(long): byte length is too big'); // this will overflow u32 in js\n                const lengthBytes = data.subarray(pos, pos + lenLen);\n                if (lengthBytes.length !== lenLen)\n                    throw new E('tlv.decode: length bytes not complete');\n                if (lengthBytes[0] === 0)\n                    throw new E('tlv.decode(long): zero leftmost byte');\n                for (const b of lengthBytes)\n                    length = (length << 8) | b;\n                pos += lenLen;\n                if (length < 128)\n                    throw new E('tlv.decode(long): not minimal encoding');\n            }\n            const v = data.subarray(pos, pos + length);\n            if (v.length !== length)\n                throw new E('tlv.decode: wrong value length');\n            return { v, l: data.subarray(pos + length) };\n        },\n    },\n    // https://crypto.stackexchange.com/a/57734 Leftmost bit of first byte is 'negative' flag,\n    // since we always use positive integers here. It must always be empty:\n    // - add zero byte if exists\n    // - if next byte doesn't have a flag, leading zero is not allowed (minimal encoding)\n    _int: {\n        encode(num) {\n            const { Err: E } = DER;\n            if (num < _0n)\n                throw new E('integer: negative integers are not allowed');\n            let hex = numberToHexUnpadded(num);\n            // Pad with zero byte if negative flag is present\n            if (Number.parseInt(hex[0], 16) & 0b1000)\n                hex = '00' + hex;\n            if (hex.length & 1)\n                throw new E('unexpected DER parsing assertion: unpadded hex');\n            return hex;\n        },\n        decode(data) {\n            const { Err: E } = DER;\n            if (data[0] & 128)\n                throw new E('invalid signature integer: negative');\n            if (data[0] === 0x00 && !(data[1] & 128))\n                throw new E('invalid signature integer: unnecessary leading zero');\n            return bytesToNumberBE(data);\n        },\n    },\n    toSig(hex) {\n        // parse DER signature\n        const { Err: E, _int: int, _tlv: tlv } = DER;\n        const data = ensureBytes('signature', hex);\n        const { v: seqBytes, l: seqLeftBytes } = tlv.decode(0x30, data);\n        if (seqLeftBytes.length)\n            throw new E('invalid signature: left bytes after parsing');\n        const { v: rBytes, l: rLeftBytes } = tlv.decode(0x02, seqBytes);\n        const { v: sBytes, l: sLeftBytes } = tlv.decode(0x02, rLeftBytes);\n        if (sLeftBytes.length)\n            throw new E('invalid signature: left bytes after parsing');\n        return { r: int.decode(rBytes), s: int.decode(sBytes) };\n    },\n    hexFromSig(sig) {\n        const { _tlv: tlv, _int: int } = DER;\n        const rs = tlv.encode(0x02, int.encode(sig.r));\n        const ss = tlv.encode(0x02, int.encode(sig.s));\n        const seq = rs + ss;\n        return tlv.encode(0x30, seq);\n    },\n};\nfunction numToSizedHex(num, size) {\n    return bytesToHex(numberToBytesBE(num, size));\n}\n// Be friendly to bad ECMAScript parsers by not using bigint literals\n// prettier-ignore\nconst _0n = BigInt(0), _1n = BigInt(1), _2n = BigInt(2), _3n = BigInt(3), _4n = BigInt(4);\nexport function weierstrassPoints(opts) {\n    const CURVE = validatePointOpts(opts);\n    const { Fp } = CURVE; // All curves has same field / group length as for now, but they can differ\n    const Fn = Field(CURVE.n, CURVE.nBitLength);\n    const toBytes = CURVE.toBytes ||\n        ((_c, point, _isCompressed) => {\n            const a = point.toAffine();\n            return concatBytes(Uint8Array.from([0x04]), Fp.toBytes(a.x), Fp.toBytes(a.y));\n        });\n    const fromBytes = CURVE.fromBytes ||\n        ((bytes) => {\n            // const head = bytes[0];\n            const tail = bytes.subarray(1);\n            // if (head !== 0x04) throw new Error('Only non-compressed encoding is supported');\n            const x = Fp.fromBytes(tail.subarray(0, Fp.BYTES));\n            const y = Fp.fromBytes(tail.subarray(Fp.BYTES, 2 * Fp.BYTES));\n            return { x, y };\n        });\n    /**\n     * y = x + ax + b: Short weierstrass curve formula. Takes x, returns y.\n     * @returns y\n     */\n    function weierstrassEquation(x) {\n        const { a, b } = CURVE;\n        const x2 = Fp.sqr(x); // x * x\n        const x3 = Fp.mul(x2, x); // x * x\n        return Fp.add(Fp.add(x3, Fp.mul(x, a)), b); // x + a * x + b\n    }\n    function isValidXY(x, y) {\n        const left = Fp.sqr(y); // y\n        const right = weierstrassEquation(x); // x + ax + b\n        return Fp.eql(left, right);\n    }\n    // Validate whether the passed curve params are valid.\n    // Test 1: equation y = x + ax + b should work for generator point.\n    if (!isValidXY(CURVE.Gx, CURVE.Gy))\n        throw new Error('bad curve params: generator point');\n    // Test 2: discriminant  part should be non-zero: 4a + 27b != 0.\n    // Guarantees curve is genus-1, smooth (non-singular).\n    const _4a3 = Fp.mul(Fp.pow(CURVE.a, _3n), _4n);\n    const _27b2 = Fp.mul(Fp.sqr(CURVE.b), BigInt(27));\n    if (Fp.is0(Fp.add(_4a3, _27b2)))\n        throw new Error('bad curve params: a or b');\n    // Valid group elements reside in range 1..n-1\n    function isWithinCurveOrder(num) {\n        return inRange(num, _1n, CURVE.n);\n    }\n    // Validates if priv key is valid and converts it to bigint.\n    // Supports options allowedPrivateKeyLengths and wrapPrivateKey.\n    function normPrivateKeyToScalar(key) {\n        const { allowedPrivateKeyLengths: lengths, nByteLength, wrapPrivateKey, n: N } = CURVE;\n        if (lengths && typeof key !== 'bigint') {\n            if (isBytes(key))\n                key = bytesToHex(key);\n            // Normalize to hex string, pad. E.g. P521 would norm 130-132 char hex to 132-char bytes\n            if (typeof key !== 'string' || !lengths.includes(key.length))\n                throw new Error('invalid private key');\n            key = key.padStart(nByteLength * 2, '0');\n        }\n        let num;\n        try {\n            num =\n                typeof key === 'bigint'\n                    ? key\n                    : bytesToNumberBE(ensureBytes('private key', key, nByteLength));\n        }\n        catch (error) {\n            throw new Error('invalid private key, expected hex or ' + nByteLength + ' bytes, got ' + typeof key);\n        }\n        if (wrapPrivateKey)\n            num = mod(num, N); // disabled by default, enabled for BLS\n        aInRange('private key', num, _1n, N); // num in range [1..N-1]\n        return num;\n    }\n    function aprjpoint(other) {\n        if (!(other instanceof Point))\n            throw new Error('ProjectivePoint expected');\n    }\n    // Memoized toAffine / validity check. They are heavy. Points are immutable.\n    // Converts Projective point to affine (x, y) coordinates.\n    // Can accept precomputed Z^-1 - for example, from invertBatch.\n    // (X, Y, Z)  (x=X/Z, y=Y/Z)\n    const toAffineMemo = memoized((p, iz) => {\n        const { px: x, py: y, pz: z } = p;\n        // Fast-path for normalized points\n        if (Fp.eql(z, Fp.ONE))\n            return { x, y };\n        const is0 = p.is0();\n        // If invZ was 0, we return zero point. However we still want to execute\n        // all operations, so we replace invZ with a random number, 1.\n        if (iz == null)\n            iz = is0 ? Fp.ONE : Fp.inv(z);\n        const ax = Fp.mul(x, iz);\n        const ay = Fp.mul(y, iz);\n        const zz = Fp.mul(z, iz);\n        if (is0)\n            return { x: Fp.ZERO, y: Fp.ZERO };\n        if (!Fp.eql(zz, Fp.ONE))\n            throw new Error('invZ was invalid');\n        return { x: ax, y: ay };\n    });\n    // NOTE: on exception this will crash 'cached' and no value will be set.\n    // Otherwise true will be return\n    const assertValidMemo = memoized((p) => {\n        if (p.is0()) {\n            // (0, 1, 0) aka ZERO is invalid in most contexts.\n            // In BLS, ZERO can be serialized, so we allow it.\n            // (0, 0, 0) is invalid representation of ZERO.\n            if (CURVE.allowInfinityPoint && !Fp.is0(p.py))\n                return;\n            throw new Error('bad point: ZERO');\n        }\n        // Some 3rd-party test vectors require different wording between here & `fromCompressedHex`\n        const { x, y } = p.toAffine();\n        // Check if x, y are valid field elements\n        if (!Fp.isValid(x) || !Fp.isValid(y))\n            throw new Error('bad point: x or y not FE');\n        if (!isValidXY(x, y))\n            throw new Error('bad point: equation left != right');\n        if (!p.isTorsionFree())\n            throw new Error('bad point: not in prime-order subgroup');\n        return true;\n    });\n    /**\n     * Projective Point works in 3d / projective (homogeneous) coordinates: (X, Y, Z)  (x=X/Z, y=Y/Z)\n     * Default Point works in 2d / affine coordinates: (x, y)\n     * We're doing calculations in projective, because its operations don't require costly inversion.\n     */\n    class Point {\n        constructor(px, py, pz) {\n            if (px == null || !Fp.isValid(px))\n                throw new Error('x required');\n            if (py == null || !Fp.isValid(py) || Fp.is0(py))\n                throw new Error('y required');\n            if (pz == null || !Fp.isValid(pz))\n                throw new Error('z required');\n            this.px = px;\n            this.py = py;\n            this.pz = pz;\n            Object.freeze(this);\n        }\n        // Does not validate if the point is on-curve.\n        // Use fromHex instead, or call assertValidity() later.\n        static fromAffine(p) {\n            const { x, y } = p || {};\n            if (!p || !Fp.isValid(x) || !Fp.isValid(y))\n                throw new Error('invalid affine point');\n            if (p instanceof Point)\n                throw new Error('projective point not allowed');\n            const is0 = (i) => Fp.eql(i, Fp.ZERO);\n            // fromAffine(x:0, y:0) would produce (x:0, y:0, z:1), but we need (x:0, y:1, z:0)\n            if (is0(x) && is0(y))\n                return Point.ZERO;\n            return new Point(x, y, Fp.ONE);\n        }\n        get x() {\n            return this.toAffine().x;\n        }\n        get y() {\n            return this.toAffine().y;\n        }\n        /**\n         * Takes a bunch of Projective Points but executes only one\n         * inversion on all of them. Inversion is very slow operation,\n         * so this improves performance massively.\n         * Optimization: converts a list of projective points to a list of identical points with Z=1.\n         */\n        static normalizeZ(points) {\n            const toInv = FpInvertBatch(Fp, points.map((p) => p.pz));\n            return points.map((p, i) => p.toAffine(toInv[i])).map(Point.fromAffine);\n        }\n        /**\n         * Converts hash string or Uint8Array to Point.\n         * @param hex short/long ECDSA hex\n         */\n        static fromHex(hex) {\n            const P = Point.fromAffine(fromBytes(ensureBytes('pointHex', hex)));\n            P.assertValidity();\n            return P;\n        }\n        // Multiplies generator point by privateKey.\n        static fromPrivateKey(privateKey) {\n            return Point.BASE.multiply(normPrivateKeyToScalar(privateKey));\n        }\n        // Multiscalar Multiplication\n        static msm(points, scalars) {\n            return pippenger(Point, Fn, points, scalars);\n        }\n        // \"Private method\", don't use it directly\n        _setWindowSize(windowSize) {\n            wnaf.setWindowSize(this, windowSize);\n        }\n        // A point on curve is valid if it conforms to equation.\n        assertValidity() {\n            assertValidMemo(this);\n        }\n        hasEvenY() {\n            const { y } = this.toAffine();\n            if (Fp.isOdd)\n                return !Fp.isOdd(y);\n            throw new Error(\"Field doesn't support isOdd\");\n        }\n        /**\n         * Compare one point to another.\n         */\n        equals(other) {\n            aprjpoint(other);\n            const { px: X1, py: Y1, pz: Z1 } = this;\n            const { px: X2, py: Y2, pz: Z2 } = other;\n            const U1 = Fp.eql(Fp.mul(X1, Z2), Fp.mul(X2, Z1));\n            const U2 = Fp.eql(Fp.mul(Y1, Z2), Fp.mul(Y2, Z1));\n            return U1 && U2;\n        }\n        /**\n         * Flips point to one corresponding to (x, -y) in Affine coordinates.\n         */\n        negate() {\n            return new Point(this.px, Fp.neg(this.py), this.pz);\n        }\n        // Renes-Costello-Batina exception-free doubling formula.\n        // There is 30% faster Jacobian formula, but it is not complete.\n        // https://eprint.iacr.org/2015/1060, algorithm 3\n        // Cost: 8M + 3S + 3*a + 2*b3 + 15add.\n        double() {\n            const { a, b } = CURVE;\n            const b3 = Fp.mul(b, _3n);\n            const { px: X1, py: Y1, pz: Z1 } = this;\n            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore\n            let t0 = Fp.mul(X1, X1); // step 1\n            let t1 = Fp.mul(Y1, Y1);\n            let t2 = Fp.mul(Z1, Z1);\n            let t3 = Fp.mul(X1, Y1);\n            t3 = Fp.add(t3, t3); // step 5\n            Z3 = Fp.mul(X1, Z1);\n            Z3 = Fp.add(Z3, Z3);\n            X3 = Fp.mul(a, Z3);\n            Y3 = Fp.mul(b3, t2);\n            Y3 = Fp.add(X3, Y3); // step 10\n            X3 = Fp.sub(t1, Y3);\n            Y3 = Fp.add(t1, Y3);\n            Y3 = Fp.mul(X3, Y3);\n            X3 = Fp.mul(t3, X3);\n            Z3 = Fp.mul(b3, Z3); // step 15\n            t2 = Fp.mul(a, t2);\n            t3 = Fp.sub(t0, t2);\n            t3 = Fp.mul(a, t3);\n            t3 = Fp.add(t3, Z3);\n            Z3 = Fp.add(t0, t0); // step 20\n            t0 = Fp.add(Z3, t0);\n            t0 = Fp.add(t0, t2);\n            t0 = Fp.mul(t0, t3);\n            Y3 = Fp.add(Y3, t0);\n            t2 = Fp.mul(Y1, Z1); // step 25\n            t2 = Fp.add(t2, t2);\n            t0 = Fp.mul(t2, t3);\n            X3 = Fp.sub(X3, t0);\n            Z3 = Fp.mul(t2, t1);\n            Z3 = Fp.add(Z3, Z3); // step 30\n            Z3 = Fp.add(Z3, Z3);\n            return new Point(X3, Y3, Z3);\n        }\n        // Renes-Costello-Batina exception-free addition formula.\n        // There is 30% faster Jacobian formula, but it is not complete.\n        // https://eprint.iacr.org/2015/1060, algorithm 1\n        // Cost: 12M + 0S + 3*a + 3*b3 + 23add.\n        add(other) {\n            aprjpoint(other);\n            const { px: X1, py: Y1, pz: Z1 } = this;\n            const { px: X2, py: Y2, pz: Z2 } = other;\n            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore\n            const a = CURVE.a;\n            const b3 = Fp.mul(CURVE.b, _3n);\n            let t0 = Fp.mul(X1, X2); // step 1\n            let t1 = Fp.mul(Y1, Y2);\n            let t2 = Fp.mul(Z1, Z2);\n            let t3 = Fp.add(X1, Y1);\n            let t4 = Fp.add(X2, Y2); // step 5\n            t3 = Fp.mul(t3, t4);\n            t4 = Fp.add(t0, t1);\n            t3 = Fp.sub(t3, t4);\n            t4 = Fp.add(X1, Z1);\n            let t5 = Fp.add(X2, Z2); // step 10\n            t4 = Fp.mul(t4, t5);\n            t5 = Fp.add(t0, t2);\n            t4 = Fp.sub(t4, t5);\n            t5 = Fp.add(Y1, Z1);\n            X3 = Fp.add(Y2, Z2); // step 15\n            t5 = Fp.mul(t5, X3);\n            X3 = Fp.add(t1, t2);\n            t5 = Fp.sub(t5, X3);\n            Z3 = Fp.mul(a, t4);\n            X3 = Fp.mul(b3, t2); // step 20\n            Z3 = Fp.add(X3, Z3);\n            X3 = Fp.sub(t1, Z3);\n            Z3 = Fp.add(t1, Z3);\n            Y3 = Fp.mul(X3, Z3);\n            t1 = Fp.add(t0, t0); // step 25\n            t1 = Fp.add(t1, t0);\n            t2 = Fp.mul(a, t2);\n            t4 = Fp.mul(b3, t4);\n            t1 = Fp.add(t1, t2);\n            t2 = Fp.sub(t0, t2); // step 30\n            t2 = Fp.mul(a, t2);\n            t4 = Fp.add(t4, t2);\n            t0 = Fp.mul(t1, t4);\n            Y3 = Fp.add(Y3, t0);\n            t0 = Fp.mul(t5, t4); // step 35\n            X3 = Fp.mul(t3, X3);\n            X3 = Fp.sub(X3, t0);\n            t0 = Fp.mul(t3, t1);\n            Z3 = Fp.mul(t5, Z3);\n            Z3 = Fp.add(Z3, t0); // step 40\n            return new Point(X3, Y3, Z3);\n        }\n        subtract(other) {\n            return this.add(other.negate());\n        }\n        is0() {\n            return this.equals(Point.ZERO);\n        }\n        wNAF(n) {\n            return wnaf.wNAFCached(this, n, Point.normalizeZ);\n        }\n        /**\n         * Non-constant-time multiplication. Uses double-and-add algorithm.\n         * It's faster, but should only be used when you don't care about\n         * an exposed private key e.g. sig verification, which works over *public* keys.\n         */\n        multiplyUnsafe(sc) {\n            const { endo, n: N } = CURVE;\n            aInRange('scalar', sc, _0n, N);\n            const I = Point.ZERO;\n            if (sc === _0n)\n                return I;\n            if (this.is0() || sc === _1n)\n                return this;\n            // Case a: no endomorphism. Case b: has precomputes.\n            if (!endo || wnaf.hasPrecomputes(this))\n                return wnaf.wNAFCachedUnsafe(this, sc, Point.normalizeZ);\n            // Case c: endomorphism\n            /** See docs for {@link EndomorphismOpts} */\n            let { k1neg, k1, k2neg, k2 } = endo.splitScalar(sc);\n            let k1p = I;\n            let k2p = I;\n            let d = this;\n            while (k1 > _0n || k2 > _0n) {\n                if (k1 & _1n)\n                    k1p = k1p.add(d);\n                if (k2 & _1n)\n                    k2p = k2p.add(d);\n                d = d.double();\n                k1 >>= _1n;\n                k2 >>= _1n;\n            }\n            if (k1neg)\n                k1p = k1p.negate();\n            if (k2neg)\n                k2p = k2p.negate();\n            k2p = new Point(Fp.mul(k2p.px, endo.beta), k2p.py, k2p.pz);\n            return k1p.add(k2p);\n        }\n        /**\n         * Constant time multiplication.\n         * Uses wNAF method. Windowed method may be 10% faster,\n         * but takes 2x longer to generate and consumes 2x memory.\n         * Uses precomputes when available.\n         * Uses endomorphism for Koblitz curves.\n         * @param scalar by which the point would be multiplied\n         * @returns New point\n         */\n        multiply(scalar) {\n            const { endo, n: N } = CURVE;\n            aInRange('scalar', scalar, _1n, N);\n            let point, fake; // Fake point is used to const-time mult\n            /** See docs for {@link EndomorphismOpts} */\n            if (endo) {\n                const { k1neg, k1, k2neg, k2 } = endo.splitScalar(scalar);\n                let { p: k1p, f: f1p } = this.wNAF(k1);\n                let { p: k2p, f: f2p } = this.wNAF(k2);\n                k1p = wnaf.constTimeNegate(k1neg, k1p);\n                k2p = wnaf.constTimeNegate(k2neg, k2p);\n                k2p = new Point(Fp.mul(k2p.px, endo.beta), k2p.py, k2p.pz);\n                point = k1p.add(k2p);\n                fake = f1p.add(f2p);\n            }\n            else {\n                const { p, f } = this.wNAF(scalar);\n                point = p;\n                fake = f;\n            }\n            // Normalize `z` for both points, but return only real one\n            return Point.normalizeZ([point, fake])[0];\n        }\n        /**\n         * Efficiently calculate `aP + bQ`. Unsafe, can expose private key, if used incorrectly.\n         * Not using Strauss-Shamir trick: precomputation tables are faster.\n         * The trick could be useful if both P and Q are not G (not in our case).\n         * @returns non-zero affine point\n         */\n        multiplyAndAddUnsafe(Q, a, b) {\n            const G = Point.BASE; // No Strauss-Shamir trick: we have 10% faster G precomputes\n            const mul = (P, a // Select faster multiply() method\n            ) => (a === _0n || a === _1n || !P.equals(G) ? P.multiplyUnsafe(a) : P.multiply(a));\n            const sum = mul(this, a).add(mul(Q, b));\n            return sum.is0() ? undefined : sum;\n        }\n        // Converts Projective point to affine (x, y) coordinates.\n        // Can accept precomputed Z^-1 - for example, from invertBatch.\n        // (x, y, z)  (x=x/z, y=y/z)\n        toAffine(iz) {\n            return toAffineMemo(this, iz);\n        }\n        isTorsionFree() {\n            const { h: cofactor, isTorsionFree } = CURVE;\n            if (cofactor === _1n)\n                return true; // No subgroups, always torsion-free\n            if (isTorsionFree)\n                return isTorsionFree(Point, this);\n            throw new Error('isTorsionFree() has not been declared for the elliptic curve');\n        }\n        clearCofactor() {\n            const { h: cofactor, clearCofactor } = CURVE;\n            if (cofactor === _1n)\n                return this; // Fast-path\n            if (clearCofactor)\n                return clearCofactor(Point, this);\n            return this.multiplyUnsafe(CURVE.h);\n        }\n        toRawBytes(isCompressed = true) {\n            abool('isCompressed', isCompressed);\n            this.assertValidity();\n            return toBytes(Point, this, isCompressed);\n        }\n        toHex(isCompressed = true) {\n            abool('isCompressed', isCompressed);\n            return bytesToHex(this.toRawBytes(isCompressed));\n        }\n    }\n    // base / generator point\n    Point.BASE = new Point(CURVE.Gx, CURVE.Gy, Fp.ONE);\n    // zero / infinity / identity point\n    Point.ZERO = new Point(Fp.ZERO, Fp.ONE, Fp.ZERO); // 0, 1, 0\n    const { endo, nBitLength } = CURVE;\n    const wnaf = wNAF(Point, endo ? Math.ceil(nBitLength / 2) : nBitLength);\n    return {\n        CURVE,\n        ProjectivePoint: Point,\n        normPrivateKeyToScalar,\n        weierstrassEquation,\n        isWithinCurveOrder,\n    };\n}\nfunction validateOpts(curve) {\n    const opts = validateBasic(curve);\n    validateObject(opts, {\n        hash: 'hash',\n        hmac: 'function',\n        randomBytes: 'function',\n    }, {\n        bits2int: 'function',\n        bits2int_modN: 'function',\n        lowS: 'boolean',\n    });\n    return Object.freeze({ lowS: true, ...opts });\n}\n/**\n * Creates short weierstrass curve and ECDSA signature methods for it.\n * @example\n * import { Field } from '@noble/curves/abstract/modular';\n * // Before that, define BigInt-s: a, b, p, n, Gx, Gy\n * const curve = weierstrass({ a, b, Fp: Field(p), n, Gx, Gy, h: 1n })\n */\nexport function weierstrass(curveDef) {\n    const CURVE = validateOpts(curveDef);\n    const { Fp, n: CURVE_ORDER, nByteLength, nBitLength } = CURVE;\n    const compressedLen = Fp.BYTES + 1; // e.g. 33 for 32\n    const uncompressedLen = 2 * Fp.BYTES + 1; // e.g. 65 for 32\n    function modN(a) {\n        return mod(a, CURVE_ORDER);\n    }\n    function invN(a) {\n        return invert(a, CURVE_ORDER);\n    }\n    const { ProjectivePoint: Point, normPrivateKeyToScalar, weierstrassEquation, isWithinCurveOrder, } = weierstrassPoints({\n        ...CURVE,\n        toBytes(_c, point, isCompressed) {\n            const a = point.toAffine();\n            const x = Fp.toBytes(a.x);\n            const cat = concatBytes;\n            abool('isCompressed', isCompressed);\n            if (isCompressed) {\n                return cat(Uint8Array.from([point.hasEvenY() ? 0x02 : 0x03]), x);\n            }\n            else {\n                return cat(Uint8Array.from([0x04]), x, Fp.toBytes(a.y));\n            }\n        },\n        fromBytes(bytes) {\n            const len = bytes.length;\n            const head = bytes[0];\n            const tail = bytes.subarray(1);\n            // this.assertValidity() is done inside of fromHex\n            if (len === compressedLen && (head === 0x02 || head === 0x03)) {\n                const x = bytesToNumberBE(tail);\n                if (!inRange(x, _1n, Fp.ORDER))\n                    throw new Error('Point is not on curve');\n                const y2 = weierstrassEquation(x); // y = x + ax + b\n                let y;\n                try {\n                    y = Fp.sqrt(y2); // y = y ^ (p+1)/4\n                }\n                catch (sqrtError) {\n                    const suffix = sqrtError instanceof Error ? ': ' + sqrtError.message : '';\n                    throw new Error('Point is not on curve' + suffix);\n                }\n                const isYOdd = (y & _1n) === _1n;\n                // ECDSA\n                const isHeadOdd = (head & 1) === 1;\n                if (isHeadOdd !== isYOdd)\n                    y = Fp.neg(y);\n                return { x, y };\n            }\n            else if (len === uncompressedLen && head === 0x04) {\n                const x = Fp.fromBytes(tail.subarray(0, Fp.BYTES));\n                const y = Fp.fromBytes(tail.subarray(Fp.BYTES, 2 * Fp.BYTES));\n                return { x, y };\n            }\n            else {\n                const cl = compressedLen;\n                const ul = uncompressedLen;\n                throw new Error('invalid Point, expected length of ' + cl + ', or uncompressed ' + ul + ', got ' + len);\n            }\n        },\n    });\n    function isBiggerThanHalfOrder(number) {\n        const HALF = CURVE_ORDER >> _1n;\n        return number > HALF;\n    }\n    function normalizeS(s) {\n        return isBiggerThanHalfOrder(s) ? modN(-s) : s;\n    }\n    // slice bytes num\n    const slcNum = (b, from, to) => bytesToNumberBE(b.slice(from, to));\n    /**\n     * ECDSA signature with its (r, s) properties. Supports DER & compact representations.\n     */\n    class Signature {\n        constructor(r, s, recovery) {\n            aInRange('r', r, _1n, CURVE_ORDER); // r in [1..N]\n            aInRange('s', s, _1n, CURVE_ORDER); // s in [1..N]\n            this.r = r;\n            this.s = s;\n            if (recovery != null)\n                this.recovery = recovery;\n            Object.freeze(this);\n        }\n        // pair (bytes of r, bytes of s)\n        static fromCompact(hex) {\n            const l = nByteLength;\n            hex = ensureBytes('compactSignature', hex, l * 2);\n            return new Signature(slcNum(hex, 0, l), slcNum(hex, l, 2 * l));\n        }\n        // DER encoded ECDSA signature\n        // https://bitcoin.stackexchange.com/questions/57644/what-are-the-parts-of-a-bitcoin-transaction-input-script\n        static fromDER(hex) {\n            const { r, s } = DER.toSig(ensureBytes('DER', hex));\n            return new Signature(r, s);\n        }\n        /**\n         * @todo remove\n         * @deprecated\n         */\n        assertValidity() { }\n        addRecoveryBit(recovery) {\n            return new Signature(this.r, this.s, recovery);\n        }\n        recoverPublicKey(msgHash) {\n            const { r, s, recovery: rec } = this;\n            const h = bits2int_modN(ensureBytes('msgHash', msgHash)); // Truncate hash\n            if (rec == null || ![0, 1, 2, 3].includes(rec))\n                throw new Error('recovery id invalid');\n            const radj = rec === 2 || rec === 3 ? r + CURVE.n : r;\n            if (radj >= Fp.ORDER)\n                throw new Error('recovery id 2 or 3 invalid');\n            const prefix = (rec & 1) === 0 ? '02' : '03';\n            const R = Point.fromHex(prefix + numToSizedHex(radj, Fp.BYTES));\n            const ir = invN(radj); // r^-1\n            const u1 = modN(-h * ir); // -hr^-1\n            const u2 = modN(s * ir); // sr^-1\n            const Q = Point.BASE.multiplyAndAddUnsafe(R, u1, u2); // (sr^-1)R-(hr^-1)G = -(hr^-1)G + (sr^-1)\n            if (!Q)\n                throw new Error('point at infinify'); // unsafe is fine: no priv data leaked\n            Q.assertValidity();\n            return Q;\n        }\n        // Signatures should be low-s, to prevent malleability.\n        hasHighS() {\n            return isBiggerThanHalfOrder(this.s);\n        }\n        normalizeS() {\n            return this.hasHighS() ? new Signature(this.r, modN(-this.s), this.recovery) : this;\n        }\n        // DER-encoded\n        toDERRawBytes() {\n            return hexToBytes(this.toDERHex());\n        }\n        toDERHex() {\n            return DER.hexFromSig(this);\n        }\n        // padded bytes of r, then padded bytes of s\n        toCompactRawBytes() {\n            return hexToBytes(this.toCompactHex());\n        }\n        toCompactHex() {\n            const l = nByteLength;\n            return numToSizedHex(this.r, l) + numToSizedHex(this.s, l);\n        }\n    }\n    const utils = {\n        isValidPrivateKey(privateKey) {\n            try {\n                normPrivateKeyToScalar(privateKey);\n                return true;\n            }\n            catch (error) {\n                return false;\n            }\n        },\n        normPrivateKeyToScalar: normPrivateKeyToScalar,\n        /**\n         * Produces cryptographically secure private key from random of size\n         * (groupLen + ceil(groupLen / 2)) with modulo bias being negligible.\n         */\n        randomPrivateKey: () => {\n            const length = getMinHashLength(CURVE.n);\n            return mapHashToField(CURVE.randomBytes(length), CURVE.n);\n        },\n        /**\n         * Creates precompute table for an arbitrary EC point. Makes point \"cached\".\n         * Allows to massively speed-up `point.multiply(scalar)`.\n         * @returns cached point\n         * @example\n         * const fast = utils.precompute(8, ProjectivePoint.fromHex(someonesPubKey));\n         * fast.multiply(privKey); // much faster ECDH now\n         */\n        precompute(windowSize = 8, point = Point.BASE) {\n            point._setWindowSize(windowSize);\n            point.multiply(BigInt(3)); // 3 is arbitrary, just need any number here\n            return point;\n        },\n    };\n    /**\n     * Computes public key for a private key. Checks for validity of the private key.\n     * @param privateKey private key\n     * @param isCompressed whether to return compact (default), or full key\n     * @returns Public key, full when isCompressed=false; short when isCompressed=true\n     */\n    function getPublicKey(privateKey, isCompressed = true) {\n        return Point.fromPrivateKey(privateKey).toRawBytes(isCompressed);\n    }\n    /**\n     * Quick and dirty check for item being public key. Does not validate hex, or being on-curve.\n     */\n    function isProbPub(item) {\n        if (typeof item === 'bigint')\n            return false;\n        if (item instanceof Point)\n            return true;\n        const arr = ensureBytes('key', item);\n        const len = arr.length;\n        const fpl = Fp.BYTES;\n        const compLen = fpl + 1; // e.g. 33 for 32\n        const uncompLen = 2 * fpl + 1; // e.g. 65 for 32\n        if (CURVE.allowedPrivateKeyLengths || nByteLength === compLen) {\n            return undefined;\n        }\n        else {\n            return len === compLen || len === uncompLen;\n        }\n    }\n    /**\n     * ECDH (Elliptic Curve Diffie Hellman).\n     * Computes shared public key from private key and public key.\n     * Checks: 1) private key validity 2) shared key is on-curve.\n     * Does NOT hash the result.\n     * @param privateA private key\n     * @param publicB different public key\n     * @param isCompressed whether to return compact (default), or full key\n     * @returns shared public key\n     */\n    function getSharedSecret(privateA, publicB, isCompressed = true) {\n        if (isProbPub(privateA) === true)\n            throw new Error('first arg must be private key');\n        if (isProbPub(publicB) === false)\n            throw new Error('second arg must be public key');\n        const b = Point.fromHex(publicB); // check for being on-curve\n        return b.multiply(normPrivateKeyToScalar(privateA)).toRawBytes(isCompressed);\n    }\n    // RFC6979: ensure ECDSA msg is X bytes and < N. RFC suggests optional truncating via bits2octets.\n    // FIPS 186-4 4.6 suggests the leftmost min(nBitLen, outLen) bits, which matches bits2int.\n    // bits2int can produce res>N, we can do mod(res, N) since the bitLen is the same.\n    // int2octets can't be used; pads small msgs with 0: unacceptatble for trunc as per RFC vectors\n    const bits2int = CURVE.bits2int ||\n        function (bytes) {\n            // Our custom check \"just in case\", for protection against DoS\n            if (bytes.length > 8192)\n                throw new Error('input is too large');\n            // For curves with nBitLength % 8 !== 0: bits2octets(bits2octets(m)) !== bits2octets(m)\n            // for some cases, since bytes.length * 8 is not actual bitLength.\n            const num = bytesToNumberBE(bytes); // check for == u8 done here\n            const delta = bytes.length * 8 - nBitLength; // truncate to nBitLength leftmost bits\n            return delta > 0 ? num >> BigInt(delta) : num;\n        };\n    const bits2int_modN = CURVE.bits2int_modN ||\n        function (bytes) {\n            return modN(bits2int(bytes)); // can't use bytesToNumberBE here\n        };\n    // NOTE: pads output with zero as per spec\n    const ORDER_MASK = bitMask(nBitLength);\n    /**\n     * Converts to bytes. Checks if num in `[0..ORDER_MASK-1]` e.g.: `[0..2^256-1]`.\n     */\n    function int2octets(num) {\n        aInRange('num < 2^' + nBitLength, num, _0n, ORDER_MASK);\n        // works with order, can have different size than numToField!\n        return numberToBytesBE(num, nByteLength);\n    }\n    // Steps A, D of RFC6979 3.2\n    // Creates RFC6979 seed; converts msg/privKey to numbers.\n    // Used only in sign, not in verify.\n    // NOTE: we cannot assume here that msgHash has same amount of bytes as curve order,\n    // this will be invalid at least for P521. Also it can be bigger for P224 + SHA256\n    function prepSig(msgHash, privateKey, opts = defaultSigOpts) {\n        if (['recovered', 'canonical'].some((k) => k in opts))\n            throw new Error('sign() legacy options not supported');\n        const { hash, randomBytes } = CURVE;\n        let { lowS, prehash, extraEntropy: ent } = opts; // generates low-s sigs by default\n        if (lowS == null)\n            lowS = true; // RFC6979 3.2: we skip step A, because we already provide hash\n        msgHash = ensureBytes('msgHash', msgHash);\n        validateSigVerOpts(opts);\n        if (prehash)\n            msgHash = ensureBytes('prehashed msgHash', hash(msgHash));\n        // We can't later call bits2octets, since nested bits2int is broken for curves\n        // with nBitLength % 8 !== 0. Because of that, we unwrap it here as int2octets call.\n        // const bits2octets = (bits) => int2octets(bits2int_modN(bits))\n        const h1int = bits2int_modN(msgHash);\n        const d = normPrivateKeyToScalar(privateKey); // validate private key, convert to bigint\n        const seedArgs = [int2octets(d), int2octets(h1int)];\n        // extraEntropy. RFC6979 3.6: additional k' (optional).\n        if (ent != null && ent !== false) {\n            // K = HMAC_K(V || 0x00 || int2octets(x) || bits2octets(h1) || k')\n            const e = ent === true ? randomBytes(Fp.BYTES) : ent; // generate random bytes OR pass as-is\n            seedArgs.push(ensureBytes('extraEntropy', e)); // check for being bytes\n        }\n        const seed = concatBytes(...seedArgs); // Step D of RFC6979 3.2\n        const m = h1int; // NOTE: no need to call bits2int second time here, it is inside truncateHash!\n        // Converts signature params into point w r/s, checks result for validity.\n        function k2sig(kBytes) {\n            // RFC 6979 Section 3.2, step 3: k = bits2int(T)\n            const k = bits2int(kBytes); // Cannot use fields methods, since it is group element\n            if (!isWithinCurveOrder(k))\n                return; // Important: all mod() calls here must be done over N\n            const ik = invN(k); // k^-1 mod n\n            const q = Point.BASE.multiply(k).toAffine(); // q = Gk\n            const r = modN(q.x); // r = q.x mod n\n            if (r === _0n)\n                return;\n            // Can use scalar blinding b^-1(bm + bdr) where b  [1,q1] according to\n            // https://tches.iacr.org/index.php/TCHES/article/view/7337/6509. We've decided against it:\n            // a) dependency on CSPRNG b) 15% slowdown c) doesn't really help since bigints are not CT\n            const s = modN(ik * modN(m + r * d)); // Not using blinding here\n            if (s === _0n)\n                return;\n            let recovery = (q.x === r ? 0 : 2) | Number(q.y & _1n); // recovery bit (2 or 3, when q.x > n)\n            let normS = s;\n            if (lowS && isBiggerThanHalfOrder(s)) {\n                normS = normalizeS(s); // if lowS was passed, ensure s is always\n                recovery ^= 1; // // in the bottom half of N\n            }\n            return new Signature(r, normS, recovery); // use normS, not s\n        }\n        return { seed, k2sig };\n    }\n    const defaultSigOpts = { lowS: CURVE.lowS, prehash: false };\n    const defaultVerOpts = { lowS: CURVE.lowS, prehash: false };\n    /**\n     * Signs message hash with a private key.\n     * ```\n     * sign(m, d, k) where\n     *   (x, y) = G  k\n     *   r = x mod n\n     *   s = (m + dr)/k mod n\n     * ```\n     * @param msgHash NOT message. msg needs to be hashed to `msgHash`, or use `prehash`.\n     * @param privKey private key\n     * @param opts lowS for non-malleable sigs. extraEntropy for mixing randomness into k. prehash will hash first arg.\n     * @returns signature with recovery param\n     */\n    function sign(msgHash, privKey, opts = defaultSigOpts) {\n        const { seed, k2sig } = prepSig(msgHash, privKey, opts); // Steps A, D of RFC6979 3.2.\n        const C = CURVE;\n        const drbg = createHmacDrbg(C.hash.outputLen, C.nByteLength, C.hmac);\n        return drbg(seed, k2sig); // Steps B, C, D, E, F, G\n    }\n    // Enable precomputes. Slows down first publicKey computation by 20ms.\n    Point.BASE._setWindowSize(8);\n    // utils.precompute(8, ProjectivePoint.BASE)\n    /**\n     * Verifies a signature against message hash and public key.\n     * Rejects lowS signatures by default: to override,\n     * specify option `{lowS: false}`. Implements section 4.1.4 from https://www.secg.org/sec1-v2.pdf:\n     *\n     * ```\n     * verify(r, s, h, P) where\n     *   U1 = hs^-1 mod n\n     *   U2 = rs^-1 mod n\n     *   R = U1G - U2P\n     *   mod(R.x, n) == r\n     * ```\n     */\n    function verify(signature, msgHash, publicKey, opts = defaultVerOpts) {\n        const sg = signature;\n        msgHash = ensureBytes('msgHash', msgHash);\n        publicKey = ensureBytes('publicKey', publicKey);\n        const { lowS, prehash, format } = opts;\n        // Verify opts, deduce signature format\n        validateSigVerOpts(opts);\n        if ('strict' in opts)\n            throw new Error('options.strict was renamed to lowS');\n        if (format !== undefined && format !== 'compact' && format !== 'der')\n            throw new Error('format must be compact or der');\n        const isHex = typeof sg === 'string' || isBytes(sg);\n        const isObj = !isHex &&\n            !format &&\n            typeof sg === 'object' &&\n            sg !== null &&\n            typeof sg.r === 'bigint' &&\n            typeof sg.s === 'bigint';\n        if (!isHex && !isObj)\n            throw new Error('invalid signature, expected Uint8Array, hex string or Signature instance');\n        let _sig = undefined;\n        let P;\n        try {\n            if (isObj)\n                _sig = new Signature(sg.r, sg.s);\n            if (isHex) {\n                // Signature can be represented in 2 ways: compact (2*nByteLength) & DER (variable-length).\n                // Since DER can also be 2*nByteLength bytes, we check for it first.\n                try {\n                    if (format !== 'compact')\n                        _sig = Signature.fromDER(sg);\n                }\n                catch (derError) {\n                    if (!(derError instanceof DER.Err))\n                        throw derError;\n                }\n                if (!_sig && format !== 'der')\n                    _sig = Signature.fromCompact(sg);\n            }\n            P = Point.fromHex(publicKey);\n        }\n        catch (error) {\n            return false;\n        }\n        if (!_sig)\n            return false;\n        if (lowS && _sig.hasHighS())\n            return false;\n        if (prehash)\n            msgHash = CURVE.hash(msgHash);\n        const { r, s } = _sig;\n        const h = bits2int_modN(msgHash); // Cannot use fields methods, since it is group element\n        const is = invN(s); // s^-1\n        const u1 = modN(h * is); // u1 = hs^-1 mod n\n        const u2 = modN(r * is); // u2 = rs^-1 mod n\n        const R = Point.BASE.multiplyAndAddUnsafe(P, u1, u2)?.toAffine(); // R = u1G + u2P\n        if (!R)\n            return false;\n        const v = modN(R.x);\n        return v === r;\n    }\n    return {\n        CURVE,\n        getPublicKey,\n        getSharedSecret,\n        sign,\n        verify,\n        ProjectivePoint: Point,\n        Signature,\n        utils,\n    };\n}\n/**\n * Implementation of the Shallue and van de Woestijne method for any weierstrass curve.\n * TODO: check if there is a way to merge this with uvRatio in Edwards; move to modular.\n * b = True and y = sqrt(u / v) if (u / v) is square in F, and\n * b = False and y = sqrt(Z * (u / v)) otherwise.\n * @param Fp\n * @param Z\n * @returns\n */\nexport function SWUFpSqrtRatio(Fp, Z) {\n    // Generic implementation\n    const q = Fp.ORDER;\n    let l = _0n;\n    for (let o = q - _1n; o % _2n === _0n; o /= _2n)\n        l += _1n;\n    const c1 = l; // 1. c1, the largest integer such that 2^c1 divides q - 1.\n    // We need 2n ** c1 and 2n ** (c1-1). We can't use **; but we can use <<.\n    // 2n ** c1 == 2n << (c1-1)\n    const _2n_pow_c1_1 = _2n << (c1 - _1n - _1n);\n    const _2n_pow_c1 = _2n_pow_c1_1 * _2n;\n    const c2 = (q - _1n) / _2n_pow_c1; // 2. c2 = (q - 1) / (2^c1)  # Integer arithmetic\n    const c3 = (c2 - _1n) / _2n; // 3. c3 = (c2 - 1) / 2            # Integer arithmetic\n    const c4 = _2n_pow_c1 - _1n; // 4. c4 = 2^c1 - 1                # Integer arithmetic\n    const c5 = _2n_pow_c1_1; // 5. c5 = 2^(c1 - 1)                  # Integer arithmetic\n    const c6 = Fp.pow(Z, c2); // 6. c6 = Z^c2\n    const c7 = Fp.pow(Z, (c2 + _1n) / _2n); // 7. c7 = Z^((c2 + 1) / 2)\n    let sqrtRatio = (u, v) => {\n        let tv1 = c6; // 1. tv1 = c6\n        let tv2 = Fp.pow(v, c4); // 2. tv2 = v^c4\n        let tv3 = Fp.sqr(tv2); // 3. tv3 = tv2^2\n        tv3 = Fp.mul(tv3, v); // 4. tv3 = tv3 * v\n        let tv5 = Fp.mul(u, tv3); // 5. tv5 = u * tv3\n        tv5 = Fp.pow(tv5, c3); // 6. tv5 = tv5^c3\n        tv5 = Fp.mul(tv5, tv2); // 7. tv5 = tv5 * tv2\n        tv2 = Fp.mul(tv5, v); // 8. tv2 = tv5 * v\n        tv3 = Fp.mul(tv5, u); // 9. tv3 = tv5 * u\n        let tv4 = Fp.mul(tv3, tv2); // 10. tv4 = tv3 * tv2\n        tv5 = Fp.pow(tv4, c5); // 11. tv5 = tv4^c5\n        let isQR = Fp.eql(tv5, Fp.ONE); // 12. isQR = tv5 == 1\n        tv2 = Fp.mul(tv3, c7); // 13. tv2 = tv3 * c7\n        tv5 = Fp.mul(tv4, tv1); // 14. tv5 = tv4 * tv1\n        tv3 = Fp.cmov(tv2, tv3, isQR); // 15. tv3 = CMOV(tv2, tv3, isQR)\n        tv4 = Fp.cmov(tv5, tv4, isQR); // 16. tv4 = CMOV(tv5, tv4, isQR)\n        // 17. for i in (c1, c1 - 1, ..., 2):\n        for (let i = c1; i > _1n; i--) {\n            let tv5 = i - _2n; // 18.    tv5 = i - 2\n            tv5 = _2n << (tv5 - _1n); // 19.    tv5 = 2^tv5\n            let tvv5 = Fp.pow(tv4, tv5); // 20.    tv5 = tv4^tv5\n            const e1 = Fp.eql(tvv5, Fp.ONE); // 21.    e1 = tv5 == 1\n            tv2 = Fp.mul(tv3, tv1); // 22.    tv2 = tv3 * tv1\n            tv1 = Fp.mul(tv1, tv1); // 23.    tv1 = tv1 * tv1\n            tvv5 = Fp.mul(tv4, tv1); // 24.    tv5 = tv4 * tv1\n            tv3 = Fp.cmov(tv2, tv3, e1); // 25.    tv3 = CMOV(tv2, tv3, e1)\n            tv4 = Fp.cmov(tvv5, tv4, e1); // 26.    tv4 = CMOV(tv5, tv4, e1)\n        }\n        return { isValid: isQR, value: tv3 };\n    };\n    if (Fp.ORDER % _4n === _3n) {\n        // sqrt_ratio_3mod4(u, v)\n        const c1 = (Fp.ORDER - _3n) / _4n; // 1. c1 = (q - 3) / 4     # Integer arithmetic\n        const c2 = Fp.sqrt(Fp.neg(Z)); // 2. c2 = sqrt(-Z)\n        sqrtRatio = (u, v) => {\n            let tv1 = Fp.sqr(v); // 1. tv1 = v^2\n            const tv2 = Fp.mul(u, v); // 2. tv2 = u * v\n            tv1 = Fp.mul(tv1, tv2); // 3. tv1 = tv1 * tv2\n            let y1 = Fp.pow(tv1, c1); // 4. y1 = tv1^c1\n            y1 = Fp.mul(y1, tv2); // 5. y1 = y1 * tv2\n            const y2 = Fp.mul(y1, c2); // 6. y2 = y1 * c2\n            const tv3 = Fp.mul(Fp.sqr(y1), v); // 7. tv3 = y1^2; 8. tv3 = tv3 * v\n            const isQR = Fp.eql(tv3, u); // 9. isQR = tv3 == u\n            let y = Fp.cmov(y2, y1, isQR); // 10. y = CMOV(y2, y1, isQR)\n            return { isValid: isQR, value: y }; // 11. return (isQR, y) isQR ? y : y*c2\n        };\n    }\n    // No curves uses that\n    // if (Fp.ORDER % _8n === _5n) // sqrt_ratio_5mod8\n    return sqrtRatio;\n}\n/**\n * Simplified Shallue-van de Woestijne-Ulas Method\n * https://www.rfc-editor.org/rfc/rfc9380#section-6.6.2\n */\nexport function mapToCurveSimpleSWU(Fp, opts) {\n    validateField(Fp);\n    if (!Fp.isValid(opts.A) || !Fp.isValid(opts.B) || !Fp.isValid(opts.Z))\n        throw new Error('mapToCurveSimpleSWU: invalid opts');\n    const sqrtRatio = SWUFpSqrtRatio(Fp, opts.Z);\n    if (!Fp.isOdd)\n        throw new Error('Fp.isOdd is not implemented!');\n    // Input: u, an element of F.\n    // Output: (x, y), a point on E.\n    return (u) => {\n        // prettier-ignore\n        let tv1, tv2, tv3, tv4, tv5, tv6, x, y;\n        tv1 = Fp.sqr(u); // 1.  tv1 = u^2\n        tv1 = Fp.mul(tv1, opts.Z); // 2.  tv1 = Z * tv1\n        tv2 = Fp.sqr(tv1); // 3.  tv2 = tv1^2\n        tv2 = Fp.add(tv2, tv1); // 4.  tv2 = tv2 + tv1\n        tv3 = Fp.add(tv2, Fp.ONE); // 5.  tv3 = tv2 + 1\n        tv3 = Fp.mul(tv3, opts.B); // 6.  tv3 = B * tv3\n        tv4 = Fp.cmov(opts.Z, Fp.neg(tv2), !Fp.eql(tv2, Fp.ZERO)); // 7.  tv4 = CMOV(Z, -tv2, tv2 != 0)\n        tv4 = Fp.mul(tv4, opts.A); // 8.  tv4 = A * tv4\n        tv2 = Fp.sqr(tv3); // 9.  tv2 = tv3^2\n        tv6 = Fp.sqr(tv4); // 10. tv6 = tv4^2\n        tv5 = Fp.mul(tv6, opts.A); // 11. tv5 = A * tv6\n        tv2 = Fp.add(tv2, tv5); // 12. tv2 = tv2 + tv5\n        tv2 = Fp.mul(tv2, tv3); // 13. tv2 = tv2 * tv3\n        tv6 = Fp.mul(tv6, tv4); // 14. tv6 = tv6 * tv4\n        tv5 = Fp.mul(tv6, opts.B); // 15. tv5 = B * tv6\n        tv2 = Fp.add(tv2, tv5); // 16. tv2 = tv2 + tv5\n        x = Fp.mul(tv1, tv3); // 17.   x = tv1 * tv3\n        const { isValid, value } = sqrtRatio(tv2, tv6); // 18. (is_gx1_square, y1) = sqrt_ratio(tv2, tv6)\n        y = Fp.mul(tv1, u); // 19.   y = tv1 * u  -> Z * u^3 * y1\n        y = Fp.mul(y, value); // 20.   y = y * y1\n        x = Fp.cmov(x, tv3, isValid); // 21.   x = CMOV(x, tv3, is_gx1_square)\n        y = Fp.cmov(y, value, isValid); // 22.   y = CMOV(y, y1, is_gx1_square)\n        const e1 = Fp.isOdd(u) === Fp.isOdd(y); // 23.  e1 = sgn0(u) == sgn0(y)\n        y = Fp.cmov(Fp.neg(y), y, e1); // 24.   y = CMOV(-y, y, e1)\n        const tv4_inv = FpInvertBatch(Fp, [tv4], true)[0];\n        x = Fp.mul(x, tv4_inv); // 25.   x = x / tv4\n        return { x, y };\n    };\n}\n//# sourceMappingURL=weierstrass.js.map","/**\n * NIST secp256k1. See [pdf](https://www.secg.org/sec2-v2.pdf).\n *\n * Seems to be rigid (not backdoored)\n * [as per discussion](https://bitcointalk.org/index.php?topic=289795.msg3183975#msg3183975).\n *\n * secp256k1 belongs to Koblitz curves: it has efficiently computable endomorphism.\n * Endomorphism uses 2x less RAM, speeds up precomputation by 2x and ECDH / key recovery by 20%.\n * For precomputed wNAF it trades off 1/2 init time & 1/3 ram for 20% perf hit.\n * [See explanation](https://gist.github.com/paulmillr/eb670806793e84df628a7c434a873066).\n * @module\n */\n/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\nimport { sha256 } from '@noble/hashes/sha2';\nimport { randomBytes } from '@noble/hashes/utils';\nimport { createCurve } from \"./_shortw_utils.js\";\nimport { createHasher, isogenyMap } from \"./abstract/hash-to-curve.js\";\nimport { Field, mod, pow2 } from \"./abstract/modular.js\";\nimport { aInRange, bytesToNumberBE, concatBytes, ensureBytes, inRange, numberToBytesBE, } from \"./abstract/utils.js\";\nimport { mapToCurveSimpleSWU } from \"./abstract/weierstrass.js\";\nconst secp256k1P = BigInt('0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f');\nconst secp256k1N = BigInt('0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141');\nconst _0n = BigInt(0);\nconst _1n = BigInt(1);\nconst _2n = BigInt(2);\nconst divNearest = (a, b) => (a + b / _2n) / b;\n/**\n * n = n^((p+1)/4) for fields p = 3 mod 4. We unwrap the loop and multiply bit-by-bit.\n * (P+1n/4n).toString(2) would produce bits [223x 1, 0, 22x 1, 4x 0, 11, 00]\n */\nfunction sqrtMod(y) {\n    const P = secp256k1P;\n    // prettier-ignore\n    const _3n = BigInt(3), _6n = BigInt(6), _11n = BigInt(11), _22n = BigInt(22);\n    // prettier-ignore\n    const _23n = BigInt(23), _44n = BigInt(44), _88n = BigInt(88);\n    const b2 = (y * y * y) % P; // x^3, 11\n    const b3 = (b2 * b2 * y) % P; // x^7\n    const b6 = (pow2(b3, _3n, P) * b3) % P;\n    const b9 = (pow2(b6, _3n, P) * b3) % P;\n    const b11 = (pow2(b9, _2n, P) * b2) % P;\n    const b22 = (pow2(b11, _11n, P) * b11) % P;\n    const b44 = (pow2(b22, _22n, P) * b22) % P;\n    const b88 = (pow2(b44, _44n, P) * b44) % P;\n    const b176 = (pow2(b88, _88n, P) * b88) % P;\n    const b220 = (pow2(b176, _44n, P) * b44) % P;\n    const b223 = (pow2(b220, _3n, P) * b3) % P;\n    const t1 = (pow2(b223, _23n, P) * b22) % P;\n    const t2 = (pow2(t1, _6n, P) * b2) % P;\n    const root = pow2(t2, _2n, P);\n    if (!Fpk1.eql(Fpk1.sqr(root), y))\n        throw new Error('Cannot find square root');\n    return root;\n}\nconst Fpk1 = Field(secp256k1P, undefined, undefined, { sqrt: sqrtMod });\n/**\n * secp256k1 curve, ECDSA and ECDH methods.\n *\n * Field: `2n**256n - 2n**32n - 2n**9n - 2n**8n - 2n**7n - 2n**6n - 2n**4n - 1n`\n *\n * @example\n * ```js\n * import { secp256k1 } from '@noble/curves/secp256k1';\n * const priv = secp256k1.utils.randomPrivateKey();\n * const pub = secp256k1.getPublicKey(priv);\n * const msg = new Uint8Array(32).fill(1); // message hash (not message) in ecdsa\n * const sig = secp256k1.sign(msg, priv); // `{prehash: true}` option is available\n * const isValid = secp256k1.verify(sig, msg, pub) === true;\n * ```\n */\nexport const secp256k1 = createCurve({\n    a: _0n,\n    b: BigInt(7),\n    Fp: Fpk1,\n    n: secp256k1N,\n    Gx: BigInt('55066263022277343669578718895168534326250603453777594175500187360389116729240'),\n    Gy: BigInt('32670510020758816978083085130507043184471273380659243275938904335757337482424'),\n    h: BigInt(1),\n    lowS: true, // Allow only low-S signatures by default in sign() and verify()\n    endo: {\n        // Endomorphism, see above\n        beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),\n        splitScalar: (k) => {\n            const n = secp256k1N;\n            const a1 = BigInt('0x3086d221a7d46bcde86c90e49284eb15');\n            const b1 = -_1n * BigInt('0xe4437ed6010e88286f547fa90abfe4c3');\n            const a2 = BigInt('0x114ca50f7a8e2f3f657c1108d9d44cfd8');\n            const b2 = a1;\n            const POW_2_128 = BigInt('0x100000000000000000000000000000000'); // (2n**128n).toString(16)\n            const c1 = divNearest(b2 * k, n);\n            const c2 = divNearest(-b1 * k, n);\n            let k1 = mod(k - c1 * a1 - c2 * a2, n);\n            let k2 = mod(-c1 * b1 - c2 * b2, n);\n            const k1neg = k1 > POW_2_128;\n            const k2neg = k2 > POW_2_128;\n            if (k1neg)\n                k1 = n - k1;\n            if (k2neg)\n                k2 = n - k2;\n            if (k1 > POW_2_128 || k2 > POW_2_128) {\n                throw new Error('splitScalar: Endomorphism failed, k=' + k);\n            }\n            return { k1neg, k1, k2neg, k2 };\n        },\n    },\n}, sha256);\n// Schnorr signatures are superior to ECDSA from above. Below is Schnorr-specific BIP0340 code.\n// https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki\n/** An object mapping tags to their tagged hash prefix of [SHA256(tag) | SHA256(tag)] */\nconst TAGGED_HASH_PREFIXES = {};\nfunction taggedHash(tag, ...messages) {\n    let tagP = TAGGED_HASH_PREFIXES[tag];\n    if (tagP === undefined) {\n        const tagH = sha256(Uint8Array.from(tag, (c) => c.charCodeAt(0)));\n        tagP = concatBytes(tagH, tagH);\n        TAGGED_HASH_PREFIXES[tag] = tagP;\n    }\n    return sha256(concatBytes(tagP, ...messages));\n}\n// ECDSA compact points are 33-byte. Schnorr is 32: we strip first byte 0x02 or 0x03\nconst pointToBytes = (point) => point.toRawBytes(true).slice(1);\nconst numTo32b = (n) => numberToBytesBE(n, 32);\nconst modP = (x) => mod(x, secp256k1P);\nconst modN = (x) => mod(x, secp256k1N);\nconst Point = /* @__PURE__ */ (() => secp256k1.ProjectivePoint)();\nconst GmulAdd = (Q, a, b) => Point.BASE.multiplyAndAddUnsafe(Q, a, b);\n// Calculate point, scalar and bytes\nfunction schnorrGetExtPubKey(priv) {\n    let d_ = secp256k1.utils.normPrivateKeyToScalar(priv); // same method executed in fromPrivateKey\n    let p = Point.fromPrivateKey(d_); // P = d'G; 0 < d' < n check is done inside\n    const scalar = p.hasEvenY() ? d_ : modN(-d_);\n    return { scalar: scalar, bytes: pointToBytes(p) };\n}\n/**\n * lift_x from BIP340. Convert 32-byte x coordinate to elliptic curve point.\n * @returns valid point checked for being on-curve\n */\nfunction lift_x(x) {\n    aInRange('x', x, _1n, secp256k1P); // Fail if x  p.\n    const xx = modP(x * x);\n    const c = modP(xx * x + BigInt(7)); // Let c = x + 7 mod p.\n    let y = sqrtMod(c); // Let y = c^(p+1)/4 mod p.\n    if (y % _2n !== _0n)\n        y = modP(-y); // Return the unique point P such that x(P) = x and\n    const p = new Point(x, y, _1n); // y(P) = y if y mod 2 = 0 or y(P) = p-y otherwise.\n    p.assertValidity();\n    return p;\n}\nconst num = bytesToNumberBE;\n/**\n * Create tagged hash, convert it to bigint, reduce modulo-n.\n */\nfunction challenge(...args) {\n    return modN(num(taggedHash('BIP0340/challenge', ...args)));\n}\n/**\n * Schnorr public key is just `x` coordinate of Point as per BIP340.\n */\nfunction schnorrGetPublicKey(privateKey) {\n    return schnorrGetExtPubKey(privateKey).bytes; // d'=int(sk). Fail if d'=0 or d'n. Ret bytes(d'G)\n}\n/**\n * Creates Schnorr signature as per BIP340. Verifies itself before returning anything.\n * auxRand is optional and is not the sole source of k generation: bad CSPRNG won't be dangerous.\n */\nfunction schnorrSign(message, privateKey, auxRand = randomBytes(32)) {\n    const m = ensureBytes('message', message);\n    const { bytes: px, scalar: d } = schnorrGetExtPubKey(privateKey); // checks for isWithinCurveOrder\n    const a = ensureBytes('auxRand', auxRand, 32); // Auxiliary random data a: a 32-byte array\n    const t = numTo32b(d ^ num(taggedHash('BIP0340/aux', a))); // Let t be the byte-wise xor of bytes(d) and hash/aux(a)\n    const rand = taggedHash('BIP0340/nonce', t, px, m); // Let rand = hash/nonce(t || bytes(P) || m)\n    const k_ = modN(num(rand)); // Let k' = int(rand) mod n\n    if (k_ === _0n)\n        throw new Error('sign failed: k is zero'); // Fail if k' = 0.\n    const { bytes: rx, scalar: k } = schnorrGetExtPubKey(k_); // Let R = k'G.\n    const e = challenge(rx, px, m); // Let e = int(hash/challenge(bytes(R) || bytes(P) || m)) mod n.\n    const sig = new Uint8Array(64); // Let sig = bytes(R) || bytes((k + ed) mod n).\n    sig.set(rx, 0);\n    sig.set(numTo32b(modN(k + e * d)), 32);\n    // If Verify(bytes(P), m, sig) (see below) returns failure, abort\n    if (!schnorrVerify(sig, m, px))\n        throw new Error('sign: Invalid signature produced');\n    return sig;\n}\n/**\n * Verifies Schnorr signature.\n * Will swallow errors & return false except for initial type validation of arguments.\n */\nfunction schnorrVerify(signature, message, publicKey) {\n    const sig = ensureBytes('signature', signature, 64);\n    const m = ensureBytes('message', message);\n    const pub = ensureBytes('publicKey', publicKey, 32);\n    try {\n        const P = lift_x(num(pub)); // P = lift_x(int(pk)); fail if that fails\n        const r = num(sig.subarray(0, 32)); // Let r = int(sig[0:32]); fail if r  p.\n        if (!inRange(r, _1n, secp256k1P))\n            return false;\n        const s = num(sig.subarray(32, 64)); // Let s = int(sig[32:64]); fail if s  n.\n        if (!inRange(s, _1n, secp256k1N))\n            return false;\n        const e = challenge(numTo32b(r), pointToBytes(P), m); // int(challenge(bytes(r)||bytes(P)||m))%n\n        const R = GmulAdd(P, s, modN(-e)); // R = sG - eP\n        if (!R || !R.hasEvenY() || R.toAffine().x !== r)\n            return false; // -eP == (n-e)P\n        return true; // Fail if is_infinite(R) / not has_even_y(R) / x(R)  r.\n    }\n    catch (error) {\n        return false;\n    }\n}\n/**\n * Schnorr signatures over secp256k1.\n * https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki\n * @example\n * ```js\n * import { schnorr } from '@noble/curves/secp256k1';\n * const priv = schnorr.utils.randomPrivateKey();\n * const pub = schnorr.getPublicKey(priv);\n * const msg = new TextEncoder().encode('hello');\n * const sig = schnorr.sign(msg, priv);\n * const isValid = schnorr.verify(sig, msg, pub);\n * ```\n */\nexport const schnorr = /* @__PURE__ */ (() => ({\n    getPublicKey: schnorrGetPublicKey,\n    sign: schnorrSign,\n    verify: schnorrVerify,\n    utils: {\n        randomPrivateKey: secp256k1.utils.randomPrivateKey,\n        lift_x,\n        pointToBytes,\n        numberToBytesBE,\n        bytesToNumberBE,\n        taggedHash,\n        mod,\n    },\n}))();\nconst isoMap = /* @__PURE__ */ (() => isogenyMap(Fpk1, [\n    // xNum\n    [\n        '0x8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38daaaaa8c7',\n        '0x7d3d4c80bc321d5b9f315cea7fd44c5d595d2fc0bf63b92dfff1044f17c6581',\n        '0x534c328d23f234e6e2a413deca25caece4506144037c40314ecbd0b53d9dd262',\n        '0x8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38daaaaa88c',\n    ],\n    // xDen\n    [\n        '0xd35771193d94918a9ca34ccbb7b640dd86cd409542f8487d9fe6b745781eb49b',\n        '0xedadc6f64383dc1df7c4b2d51b54225406d36b641f5e41bbc52a56612a8c6d14',\n        '0x0000000000000000000000000000000000000000000000000000000000000001', // LAST 1\n    ],\n    // yNum\n    [\n        '0x4bda12f684bda12f684bda12f684bda12f684bda12f684bda12f684b8e38e23c',\n        '0xc75e0c32d5cb7c0fa9d0a54b12a0a6d5647ab046d686da6fdffc90fc201d71a3',\n        '0x29a6194691f91a73715209ef6512e576722830a201be2018a765e85a9ecee931',\n        '0x2f684bda12f684bda12f684bda12f684bda12f684bda12f684bda12f38e38d84',\n    ],\n    // yDen\n    [\n        '0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffff93b',\n        '0x7a06534bb8bdb49fd5e9e6632722c2989467c1bfc8e8d978dfb425d2685c2573',\n        '0x6484aa716545ca2cf3a70c3fa8fe337e0a3d21162f0d6299a7bf8192bfd2a76f',\n        '0x0000000000000000000000000000000000000000000000000000000000000001', // LAST 1\n    ],\n].map((i) => i.map((j) => BigInt(j)))))();\nconst mapSWU = /* @__PURE__ */ (() => mapToCurveSimpleSWU(Fpk1, {\n    A: BigInt('0x3f8731abdd661adca08a5558f0f5d272e953d363cb6f0e5d405447c01a444533'),\n    B: BigInt('1771'),\n    Z: Fpk1.create(BigInt('-11')),\n}))();\n/** Hashing / encoding to secp256k1 points / field. RFC 9380 methods. */\nexport const secp256k1_hasher = /* @__PURE__ */ (() => createHasher(secp256k1.ProjectivePoint, (scalars) => {\n    const { x, y } = mapSWU(Fpk1.create(scalars[0]));\n    return isoMap(x, y);\n}, {\n    DST: 'secp256k1_XMD:SHA-256_SSWU_RO_',\n    encodeDST: 'secp256k1_XMD:SHA-256_SSWU_NU_',\n    p: Fpk1.ORDER,\n    m: 1,\n    k: 128,\n    expand: 'xmd',\n    hash: sha256,\n}))();\nexport const hashToCurve = /* @__PURE__ */ (() => secp256k1_hasher.hashToCurve)();\nexport const encodeToCurve = /* @__PURE__ */ (() => secp256k1_hasher.encodeToCurve)();\n//# sourceMappingURL=secp256k1.js.map","/**\n * Internal Merkle-Damgard hash utils.\n * @module\n */\nimport { Hash, abytes, aexists, aoutput, clean, createView, toBytes } from \"./utils.js\";\n/** Polyfill for Safari 14. https://caniuse.com/mdn-javascript_builtins_dataview_setbiguint64 */\nexport function setBigUint64(view, byteOffset, value, isLE) {\n    if (typeof view.setBigUint64 === 'function')\n        return view.setBigUint64(byteOffset, value, isLE);\n    const _32n = BigInt(32);\n    const _u32_max = BigInt(0xffffffff);\n    const wh = Number((value >> _32n) & _u32_max);\n    const wl = Number(value & _u32_max);\n    const h = isLE ? 4 : 0;\n    const l = isLE ? 0 : 4;\n    view.setUint32(byteOffset + h, wh, isLE);\n    view.setUint32(byteOffset + l, wl, isLE);\n}\n/** Choice: a ? b : c */\nexport function Chi(a, b, c) {\n    return (a & b) ^ (~a & c);\n}\n/** Majority function, true if any two inputs is true. */\nexport function Maj(a, b, c) {\n    return (a & b) ^ (a & c) ^ (b & c);\n}\n/**\n * Merkle-Damgard hash construction base class.\n * Could be used to create MD5, RIPEMD, SHA1, SHA2.\n */\nexport class HashMD extends Hash {\n    constructor(blockLen, outputLen, padOffset, isLE) {\n        super();\n        this.finished = false;\n        this.length = 0;\n        this.pos = 0;\n        this.destroyed = false;\n        this.blockLen = blockLen;\n        this.outputLen = outputLen;\n        this.padOffset = padOffset;\n        this.isLE = isLE;\n        this.buffer = new Uint8Array(blockLen);\n        this.view = createView(this.buffer);\n    }\n    update(data) {\n        aexists(this);\n        data = toBytes(data);\n        abytes(data);\n        const { view, buffer, blockLen } = this;\n        const len = data.length;\n        for (let pos = 0; pos < len;) {\n            const take = Math.min(blockLen - this.pos, len - pos);\n            // Fast path: we have at least one block in input, cast it to view and process\n            if (take === blockLen) {\n                const dataView = createView(data);\n                for (; blockLen <= len - pos; pos += blockLen)\n                    this.process(dataView, pos);\n                continue;\n            }\n            buffer.set(data.subarray(pos, pos + take), this.pos);\n            this.pos += take;\n            pos += take;\n            if (this.pos === blockLen) {\n                this.process(view, 0);\n                this.pos = 0;\n            }\n        }\n        this.length += data.length;\n        this.roundClean();\n        return this;\n    }\n    digestInto(out) {\n        aexists(this);\n        aoutput(out, this);\n        this.finished = true;\n        // Padding\n        // We can avoid allocation of buffer for padding completely if it\n        // was previously not allocated here. But it won't change performance.\n        const { buffer, view, blockLen, isLE } = this;\n        let { pos } = this;\n        // append the bit '1' to the message\n        buffer[pos++] = 0b10000000;\n        clean(this.buffer.subarray(pos));\n        // we have less than padOffset left in buffer, so we cannot put length in\n        // current block, need process it and pad again\n        if (this.padOffset > blockLen - pos) {\n            this.process(view, 0);\n            pos = 0;\n        }\n        // Pad until full block byte with zeros\n        for (let i = pos; i < blockLen; i++)\n            buffer[i] = 0;\n        // Note: sha512 requires length to be 128bit integer, but length in JS will overflow before that\n        // You need to write around 2 exabytes (u64_max / 8 / (1024**6)) for this to happen.\n        // So we just write lowest 64 bits of that value.\n        setBigUint64(view, blockLen - 8, BigInt(this.length * 8), isLE);\n        this.process(view, 0);\n        const oview = createView(out);\n        const len = this.outputLen;\n        // NOTE: we do division by 4 later, which should be fused in single op with modulo by JIT\n        if (len % 4)\n            throw new Error('_sha2: outputLen should be aligned to 32bit');\n        const outLen = len / 4;\n        const state = this.get();\n        if (outLen > state.length)\n            throw new Error('_sha2: outputLen bigger than state');\n        for (let i = 0; i < outLen; i++)\n            oview.setUint32(4 * i, state[i], isLE);\n    }\n    digest() {\n        const { buffer, outputLen } = this;\n        this.digestInto(buffer);\n        const res = buffer.slice(0, outputLen);\n        this.destroy();\n        return res;\n    }\n    _cloneInto(to) {\n        to || (to = new this.constructor());\n        to.set(...this.get());\n        const { blockLen, buffer, length, finished, destroyed, pos } = this;\n        to.destroyed = destroyed;\n        to.finished = finished;\n        to.length = length;\n        to.pos = pos;\n        if (length % blockLen)\n            to.buffer.set(buffer);\n        return to;\n    }\n    clone() {\n        return this._cloneInto();\n    }\n}\n/**\n * Initial SHA-2 state: fractional parts of square roots of first 16 primes 2..53.\n * Check out `test/misc/sha2-gen-iv.js` for recomputation guide.\n */\n/** Initial SHA256 state. Bits 0..32 of frac part of sqrt of primes 2..19 */\nexport const SHA256_IV = /* @__PURE__ */ Uint32Array.from([\n    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19,\n]);\n/** Initial SHA224 state. Bits 32..64 of frac part of sqrt of primes 23..53 */\nexport const SHA224_IV = /* @__PURE__ */ Uint32Array.from([\n    0xc1059ed8, 0x367cd507, 0x3070dd17, 0xf70e5939, 0xffc00b31, 0x68581511, 0x64f98fa7, 0xbefa4fa4,\n]);\n/** Initial SHA384 state. Bits 0..64 of frac part of sqrt of primes 23..53 */\nexport const SHA384_IV = /* @__PURE__ */ Uint32Array.from([\n    0xcbbb9d5d, 0xc1059ed8, 0x629a292a, 0x367cd507, 0x9159015a, 0x3070dd17, 0x152fecd8, 0xf70e5939,\n    0x67332667, 0xffc00b31, 0x8eb44a87, 0x68581511, 0xdb0c2e0d, 0x64f98fa7, 0x47b5481d, 0xbefa4fa4,\n]);\n/** Initial SHA512 state. Bits 0..64 of frac part of sqrt of primes 2..19 */\nexport const SHA512_IV = /* @__PURE__ */ Uint32Array.from([\n    0x6a09e667, 0xf3bcc908, 0xbb67ae85, 0x84caa73b, 0x3c6ef372, 0xfe94f82b, 0xa54ff53a, 0x5f1d36f1,\n    0x510e527f, 0xade682d1, 0x9b05688c, 0x2b3e6c1f, 0x1f83d9ab, 0xfb41bd6b, 0x5be0cd19, 0x137e2179,\n]);\n//# sourceMappingURL=_md.js.map","/**\n * Internal helpers for u64. BigUint64Array is too slow as per 2025, so we implement it using Uint32Array.\n * @todo re-check https://issues.chromium.org/issues/42212588\n * @module\n */\nconst U32_MASK64 = /* @__PURE__ */ BigInt(2 ** 32 - 1);\nconst _32n = /* @__PURE__ */ BigInt(32);\nfunction fromBig(n, le = false) {\n    if (le)\n        return { h: Number(n & U32_MASK64), l: Number((n >> _32n) & U32_MASK64) };\n    return { h: Number((n >> _32n) & U32_MASK64) | 0, l: Number(n & U32_MASK64) | 0 };\n}\nfunction split(lst, le = false) {\n    const len = lst.length;\n    let Ah = new Uint32Array(len);\n    let Al = new Uint32Array(len);\n    for (let i = 0; i < len; i++) {\n        const { h, l } = fromBig(lst[i], le);\n        [Ah[i], Al[i]] = [h, l];\n    }\n    return [Ah, Al];\n}\nconst toBig = (h, l) => (BigInt(h >>> 0) << _32n) | BigInt(l >>> 0);\n// for Shift in [0, 32)\nconst shrSH = (h, _l, s) => h >>> s;\nconst shrSL = (h, l, s) => (h << (32 - s)) | (l >>> s);\n// Right rotate for Shift in [1, 32)\nconst rotrSH = (h, l, s) => (h >>> s) | (l << (32 - s));\nconst rotrSL = (h, l, s) => (h << (32 - s)) | (l >>> s);\n// Right rotate for Shift in (32, 64), NOTE: 32 is special case.\nconst rotrBH = (h, l, s) => (h << (64 - s)) | (l >>> (s - 32));\nconst rotrBL = (h, l, s) => (h >>> (s - 32)) | (l << (64 - s));\n// Right rotate for shift===32 (just swaps l&h)\nconst rotr32H = (_h, l) => l;\nconst rotr32L = (h, _l) => h;\n// Left rotate for Shift in [1, 32)\nconst rotlSH = (h, l, s) => (h << s) | (l >>> (32 - s));\nconst rotlSL = (h, l, s) => (l << s) | (h >>> (32 - s));\n// Left rotate for Shift in (32, 64), NOTE: 32 is special case.\nconst rotlBH = (h, l, s) => (l << (s - 32)) | (h >>> (64 - s));\nconst rotlBL = (h, l, s) => (h << (s - 32)) | (l >>> (64 - s));\n// JS uses 32-bit signed integers for bitwise operations which means we cannot\n// simple take carry out of low bit sum by shift, we need to use division.\nfunction add(Ah, Al, Bh, Bl) {\n    const l = (Al >>> 0) + (Bl >>> 0);\n    return { h: (Ah + Bh + ((l / 2 ** 32) | 0)) | 0, l: l | 0 };\n}\n// Addition with more than 2 elements\nconst add3L = (Al, Bl, Cl) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0);\nconst add3H = (low, Ah, Bh, Ch) => (Ah + Bh + Ch + ((low / 2 ** 32) | 0)) | 0;\nconst add4L = (Al, Bl, Cl, Dl) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0);\nconst add4H = (low, Ah, Bh, Ch, Dh) => (Ah + Bh + Ch + Dh + ((low / 2 ** 32) | 0)) | 0;\nconst add5L = (Al, Bl, Cl, Dl, El) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0) + (El >>> 0);\nconst add5H = (low, Ah, Bh, Ch, Dh, Eh) => (Ah + Bh + Ch + Dh + Eh + ((low / 2 ** 32) | 0)) | 0;\n// prettier-ignore\nexport { add, add3H, add3L, add4H, add4L, add5H, add5L, fromBig, rotlBH, rotlBL, rotlSH, rotlSL, rotr32H, rotr32L, rotrBH, rotrBL, rotrSH, rotrSL, shrSH, shrSL, split, toBig };\n// prettier-ignore\nconst u64 = {\n    fromBig, split, toBig,\n    shrSH, shrSL,\n    rotrSH, rotrSL, rotrBH, rotrBL,\n    rotr32H, rotr32L,\n    rotlSH, rotlSL, rotlBH, rotlBL,\n    add, add3L, add3H, add4L, add4H, add5H, add5L,\n};\nexport default u64;\n//# sourceMappingURL=_u64.js.map","export const crypto = typeof globalThis === 'object' && 'crypto' in globalThis ? globalThis.crypto : undefined;\n//# sourceMappingURL=crypto.js.map","/**\n * HMAC: RFC2104 message authentication code.\n * @module\n */\nimport { abytes, aexists, ahash, clean, Hash, toBytes } from \"./utils.js\";\nexport class HMAC extends Hash {\n    constructor(hash, _key) {\n        super();\n        this.finished = false;\n        this.destroyed = false;\n        ahash(hash);\n        const key = toBytes(_key);\n        this.iHash = hash.create();\n        if (typeof this.iHash.update !== 'function')\n            throw new Error('Expected instance of class which extends utils.Hash');\n        this.blockLen = this.iHash.blockLen;\n        this.outputLen = this.iHash.outputLen;\n        const blockLen = this.blockLen;\n        const pad = new Uint8Array(blockLen);\n        // blockLen can be bigger than outputLen\n        pad.set(key.length > blockLen ? hash.create().update(key).digest() : key);\n        for (let i = 0; i < pad.length; i++)\n            pad[i] ^= 0x36;\n        this.iHash.update(pad);\n        // By doing update (processing of first block) of outer hash here we can re-use it between multiple calls via clone\n        this.oHash = hash.create();\n        // Undo internal XOR && apply outer XOR\n        for (let i = 0; i < pad.length; i++)\n            pad[i] ^= 0x36 ^ 0x5c;\n        this.oHash.update(pad);\n        clean(pad);\n    }\n    update(buf) {\n        aexists(this);\n        this.iHash.update(buf);\n        return this;\n    }\n    digestInto(out) {\n        aexists(this);\n        abytes(out, this.outputLen);\n        this.finished = true;\n        this.iHash.digestInto(out);\n        this.oHash.update(out);\n        this.oHash.digestInto(out);\n        this.destroy();\n    }\n    digest() {\n        const out = new Uint8Array(this.oHash.outputLen);\n        this.digestInto(out);\n        return out;\n    }\n    _cloneInto(to) {\n        // Create new instance without calling constructor since key already in state and we don't know it.\n        to || (to = Object.create(Object.getPrototypeOf(this), {}));\n        const { oHash, iHash, finished, destroyed, blockLen, outputLen } = this;\n        to = to;\n        to.finished = finished;\n        to.destroyed = destroyed;\n        to.blockLen = blockLen;\n        to.outputLen = outputLen;\n        to.oHash = oHash._cloneInto(to.oHash);\n        to.iHash = iHash._cloneInto(to.iHash);\n        return to;\n    }\n    clone() {\n        return this._cloneInto();\n    }\n    destroy() {\n        this.destroyed = true;\n        this.oHash.destroy();\n        this.iHash.destroy();\n    }\n}\n/**\n * HMAC: RFC2104 message authentication code.\n * @param hash - function that would be used e.g. sha256\n * @param key - message key\n * @param message - message data\n * @example\n * import { hmac } from '@noble/hashes/hmac';\n * import { sha256 } from '@noble/hashes/sha2';\n * const mac1 = hmac(sha256, 'key', 'message');\n */\nexport const hmac = (hash, key, message) => new HMAC(hash, key).update(message).digest();\nhmac.create = (hash, key) => new HMAC(hash, key);\n//# sourceMappingURL=hmac.js.map","/**\n\nSHA1 (RFC 3174), MD5 (RFC 1321) and RIPEMD160 (RFC 2286) legacy, weak hash functions.\nDon't use them in a new protocol. What \"weak\" means:\n\n- Collisions can be made with 2^18 effort in MD5, 2^60 in SHA1, 2^80 in RIPEMD160.\n- No practical pre-image attacks (only theoretical, 2^123.4)\n- HMAC seems kinda ok: https://datatracker.ietf.org/doc/html/rfc6151\n * @module\n */\nimport { Chi, HashMD, Maj } from \"./_md.js\";\nimport { clean, createHasher, rotl } from \"./utils.js\";\n/** Initial SHA1 state */\nconst SHA1_IV = /* @__PURE__ */ Uint32Array.from([\n    0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0,\n]);\n// Reusable temporary buffer\nconst SHA1_W = /* @__PURE__ */ new Uint32Array(80);\n/** SHA1 legacy hash class. */\nexport class SHA1 extends HashMD {\n    constructor() {\n        super(64, 20, 8, false);\n        this.A = SHA1_IV[0] | 0;\n        this.B = SHA1_IV[1] | 0;\n        this.C = SHA1_IV[2] | 0;\n        this.D = SHA1_IV[3] | 0;\n        this.E = SHA1_IV[4] | 0;\n    }\n    get() {\n        const { A, B, C, D, E } = this;\n        return [A, B, C, D, E];\n    }\n    set(A, B, C, D, E) {\n        this.A = A | 0;\n        this.B = B | 0;\n        this.C = C | 0;\n        this.D = D | 0;\n        this.E = E | 0;\n    }\n    process(view, offset) {\n        for (let i = 0; i < 16; i++, offset += 4)\n            SHA1_W[i] = view.getUint32(offset, false);\n        for (let i = 16; i < 80; i++)\n            SHA1_W[i] = rotl(SHA1_W[i - 3] ^ SHA1_W[i - 8] ^ SHA1_W[i - 14] ^ SHA1_W[i - 16], 1);\n        // Compression function main loop, 80 rounds\n        let { A, B, C, D, E } = this;\n        for (let i = 0; i < 80; i++) {\n            let F, K;\n            if (i < 20) {\n                F = Chi(B, C, D);\n                K = 0x5a827999;\n            }\n            else if (i < 40) {\n                F = B ^ C ^ D;\n                K = 0x6ed9eba1;\n            }\n            else if (i < 60) {\n                F = Maj(B, C, D);\n                K = 0x8f1bbcdc;\n            }\n            else {\n                F = B ^ C ^ D;\n                K = 0xca62c1d6;\n            }\n            const T = (rotl(A, 5) + F + E + K + SHA1_W[i]) | 0;\n            E = D;\n            D = C;\n            C = rotl(B, 30);\n            B = A;\n            A = T;\n        }\n        // Add the compressed chunk to the current hash value\n        A = (A + this.A) | 0;\n        B = (B + this.B) | 0;\n        C = (C + this.C) | 0;\n        D = (D + this.D) | 0;\n        E = (E + this.E) | 0;\n        this.set(A, B, C, D, E);\n    }\n    roundClean() {\n        clean(SHA1_W);\n    }\n    destroy() {\n        this.set(0, 0, 0, 0, 0);\n        clean(this.buffer);\n    }\n}\n/** SHA1 (RFC 3174) legacy hash function. It was cryptographically broken. */\nexport const sha1 = /* @__PURE__ */ createHasher(() => new SHA1());\n/** Per-round constants */\nconst p32 = /* @__PURE__ */ Math.pow(2, 32);\nconst K = /* @__PURE__ */ Array.from({ length: 64 }, (_, i) => Math.floor(p32 * Math.abs(Math.sin(i + 1))));\n/** md5 initial state: same as sha1, but 4 u32 instead of 5. */\nconst MD5_IV = /* @__PURE__ */ SHA1_IV.slice(0, 4);\n// Reusable temporary buffer\nconst MD5_W = /* @__PURE__ */ new Uint32Array(16);\n/** MD5 legacy hash class. */\nexport class MD5 extends HashMD {\n    constructor() {\n        super(64, 16, 8, true);\n        this.A = MD5_IV[0] | 0;\n        this.B = MD5_IV[1] | 0;\n        this.C = MD5_IV[2] | 0;\n        this.D = MD5_IV[3] | 0;\n    }\n    get() {\n        const { A, B, C, D } = this;\n        return [A, B, C, D];\n    }\n    set(A, B, C, D) {\n        this.A = A | 0;\n        this.B = B | 0;\n        this.C = C | 0;\n        this.D = D | 0;\n    }\n    process(view, offset) {\n        for (let i = 0; i < 16; i++, offset += 4)\n            MD5_W[i] = view.getUint32(offset, true);\n        // Compression function main loop, 64 rounds\n        let { A, B, C, D } = this;\n        for (let i = 0; i < 64; i++) {\n            let F, g, s;\n            if (i < 16) {\n                F = Chi(B, C, D);\n                g = i;\n                s = [7, 12, 17, 22];\n            }\n            else if (i < 32) {\n                F = Chi(D, B, C);\n                g = (5 * i + 1) % 16;\n                s = [5, 9, 14, 20];\n            }\n            else if (i < 48) {\n                F = B ^ C ^ D;\n                g = (3 * i + 5) % 16;\n                s = [4, 11, 16, 23];\n            }\n            else {\n                F = C ^ (B | ~D);\n                g = (7 * i) % 16;\n                s = [6, 10, 15, 21];\n            }\n            F = F + A + K[i] + MD5_W[g];\n            A = D;\n            D = C;\n            C = B;\n            B = B + rotl(F, s[i % 4]);\n        }\n        // Add the compressed chunk to the current hash value\n        A = (A + this.A) | 0;\n        B = (B + this.B) | 0;\n        C = (C + this.C) | 0;\n        D = (D + this.D) | 0;\n        this.set(A, B, C, D);\n    }\n    roundClean() {\n        clean(MD5_W);\n    }\n    destroy() {\n        this.set(0, 0, 0, 0);\n        clean(this.buffer);\n    }\n}\n/**\n * MD5 (RFC 1321) legacy hash function. It was cryptographically broken.\n * MD5 architecture is similar to SHA1, with some differences:\n * - Reduced output length: 16 bytes (128 bit) instead of 20\n * - 64 rounds, instead of 80\n * - Little-endian: could be faster, but will require more code\n * - Non-linear index selection: huge speed-up for unroll\n * - Per round constants: more memory accesses, additional speed-up for unroll\n */\nexport const md5 = /* @__PURE__ */ createHasher(() => new MD5());\n// RIPEMD-160\nconst Rho160 = /* @__PURE__ */ Uint8Array.from([\n    7, 4, 13, 1, 10, 6, 15, 3, 12, 0, 9, 5, 2, 14, 11, 8,\n]);\nconst Id160 = /* @__PURE__ */ (() => Uint8Array.from(new Array(16).fill(0).map((_, i) => i)))();\nconst Pi160 = /* @__PURE__ */ (() => Id160.map((i) => (9 * i + 5) % 16))();\nconst idxLR = /* @__PURE__ */ (() => {\n    const L = [Id160];\n    const R = [Pi160];\n    const res = [L, R];\n    for (let i = 0; i < 4; i++)\n        for (let j of res)\n            j.push(j[i].map((k) => Rho160[k]));\n    return res;\n})();\nconst idxL = /* @__PURE__ */ (() => idxLR[0])();\nconst idxR = /* @__PURE__ */ (() => idxLR[1])();\n// const [idxL, idxR] = idxLR;\nconst shifts160 = /* @__PURE__ */ [\n    [11, 14, 15, 12, 5, 8, 7, 9, 11, 13, 14, 15, 6, 7, 9, 8],\n    [12, 13, 11, 15, 6, 9, 9, 7, 12, 15, 11, 13, 7, 8, 7, 7],\n    [13, 15, 14, 11, 7, 7, 6, 8, 13, 14, 13, 12, 5, 5, 6, 9],\n    [14, 11, 12, 14, 8, 6, 5, 5, 15, 12, 15, 14, 9, 9, 8, 6],\n    [15, 12, 13, 13, 9, 5, 8, 6, 14, 11, 12, 11, 8, 6, 5, 5],\n].map((i) => Uint8Array.from(i));\nconst shiftsL160 = /* @__PURE__ */ idxL.map((idx, i) => idx.map((j) => shifts160[i][j]));\nconst shiftsR160 = /* @__PURE__ */ idxR.map((idx, i) => idx.map((j) => shifts160[i][j]));\nconst Kl160 = /* @__PURE__ */ Uint32Array.from([\n    0x00000000, 0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xa953fd4e,\n]);\nconst Kr160 = /* @__PURE__ */ Uint32Array.from([\n    0x50a28be6, 0x5c4dd124, 0x6d703ef3, 0x7a6d76e9, 0x00000000,\n]);\n// It's called f() in spec.\nfunction ripemd_f(group, x, y, z) {\n    if (group === 0)\n        return x ^ y ^ z;\n    if (group === 1)\n        return (x & y) | (~x & z);\n    if (group === 2)\n        return (x | ~y) ^ z;\n    if (group === 3)\n        return (x & z) | (y & ~z);\n    return x ^ (y | ~z);\n}\n// Reusable temporary buffer\nconst BUF_160 = /* @__PURE__ */ new Uint32Array(16);\nexport class RIPEMD160 extends HashMD {\n    constructor() {\n        super(64, 20, 8, true);\n        this.h0 = 0x67452301 | 0;\n        this.h1 = 0xefcdab89 | 0;\n        this.h2 = 0x98badcfe | 0;\n        this.h3 = 0x10325476 | 0;\n        this.h4 = 0xc3d2e1f0 | 0;\n    }\n    get() {\n        const { h0, h1, h2, h3, h4 } = this;\n        return [h0, h1, h2, h3, h4];\n    }\n    set(h0, h1, h2, h3, h4) {\n        this.h0 = h0 | 0;\n        this.h1 = h1 | 0;\n        this.h2 = h2 | 0;\n        this.h3 = h3 | 0;\n        this.h4 = h4 | 0;\n    }\n    process(view, offset) {\n        for (let i = 0; i < 16; i++, offset += 4)\n            BUF_160[i] = view.getUint32(offset, true);\n        // prettier-ignore\n        let al = this.h0 | 0, ar = al, bl = this.h1 | 0, br = bl, cl = this.h2 | 0, cr = cl, dl = this.h3 | 0, dr = dl, el = this.h4 | 0, er = el;\n        // Instead of iterating 0 to 80, we split it into 5 groups\n        // And use the groups in constants, functions, etc. Much simpler\n        for (let group = 0; group < 5; group++) {\n            const rGroup = 4 - group;\n            const hbl = Kl160[group], hbr = Kr160[group]; // prettier-ignore\n            const rl = idxL[group], rr = idxR[group]; // prettier-ignore\n            const sl = shiftsL160[group], sr = shiftsR160[group]; // prettier-ignore\n            for (let i = 0; i < 16; i++) {\n                const tl = (rotl(al + ripemd_f(group, bl, cl, dl) + BUF_160[rl[i]] + hbl, sl[i]) + el) | 0;\n                al = el, el = dl, dl = rotl(cl, 10) | 0, cl = bl, bl = tl; // prettier-ignore\n            }\n            // 2 loops are 10% faster\n            for (let i = 0; i < 16; i++) {\n                const tr = (rotl(ar + ripemd_f(rGroup, br, cr, dr) + BUF_160[rr[i]] + hbr, sr[i]) + er) | 0;\n                ar = er, er = dr, dr = rotl(cr, 10) | 0, cr = br, br = tr; // prettier-ignore\n            }\n        }\n        // Add the compressed chunk to the current hash value\n        this.set((this.h1 + cl + dr) | 0, (this.h2 + dl + er) | 0, (this.h3 + el + ar) | 0, (this.h4 + al + br) | 0, (this.h0 + bl + cr) | 0);\n    }\n    roundClean() {\n        clean(BUF_160);\n    }\n    destroy() {\n        this.destroyed = true;\n        clean(this.buffer);\n        this.set(0, 0, 0, 0, 0);\n    }\n}\n/**\n * RIPEMD-160 - a legacy hash function from 1990s.\n * * https://homes.esat.kuleuven.be/~bosselae/ripemd160.html\n * * https://homes.esat.kuleuven.be/~bosselae/ripemd160/pdf/AB-9601/AB-9601.pdf\n */\nexport const ripemd160 = /* @__PURE__ */ createHasher(() => new RIPEMD160());\n//# sourceMappingURL=legacy.js.map","/**\n * RIPEMD-160 legacy hash function.\n * https://homes.esat.kuleuven.be/~bosselae/ripemd160.html\n * https://homes.esat.kuleuven.be/~bosselae/ripemd160/pdf/AB-9601/AB-9601.pdf\n * @module\n * @deprecated\n */\nimport { RIPEMD160 as RIPEMD160n, ripemd160 as ripemd160n } from \"./legacy.js\";\n/** @deprecated Use import from `noble/hashes/legacy` module */\nexport const RIPEMD160 = RIPEMD160n;\n/** @deprecated Use import from `noble/hashes/legacy` module */\nexport const ripemd160 = ripemd160n;\n//# sourceMappingURL=ripemd160.js.map","/**\n * SHA2 hash function. A.k.a. sha256, sha384, sha512, sha512_224, sha512_256.\n * SHA256 is the fastest hash implementable in JS, even faster than Blake3.\n * Check out [RFC 4634](https://datatracker.ietf.org/doc/html/rfc4634) and\n * [FIPS 180-4](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf).\n * @module\n */\nimport { Chi, HashMD, Maj, SHA224_IV, SHA256_IV, SHA384_IV, SHA512_IV } from \"./_md.js\";\nimport * as u64 from \"./_u64.js\";\nimport { clean, createHasher, rotr } from \"./utils.js\";\n/**\n * Round constants:\n * First 32 bits of fractional parts of the cube roots of the first 64 primes 2..311)\n */\n// prettier-ignore\nconst SHA256_K = /* @__PURE__ */ Uint32Array.from([\n    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,\n    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,\n    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,\n    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,\n    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,\n    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,\n    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,\n    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2\n]);\n/** Reusable temporary buffer. \"W\" comes straight from spec. */\nconst SHA256_W = /* @__PURE__ */ new Uint32Array(64);\nexport class SHA256 extends HashMD {\n    constructor(outputLen = 32) {\n        super(64, outputLen, 8, false);\n        // We cannot use array here since array allows indexing by variable\n        // which means optimizer/compiler cannot use registers.\n        this.A = SHA256_IV[0] | 0;\n        this.B = SHA256_IV[1] | 0;\n        this.C = SHA256_IV[2] | 0;\n        this.D = SHA256_IV[3] | 0;\n        this.E = SHA256_IV[4] | 0;\n        this.F = SHA256_IV[5] | 0;\n        this.G = SHA256_IV[6] | 0;\n        this.H = SHA256_IV[7] | 0;\n    }\n    get() {\n        const { A, B, C, D, E, F, G, H } = this;\n        return [A, B, C, D, E, F, G, H];\n    }\n    // prettier-ignore\n    set(A, B, C, D, E, F, G, H) {\n        this.A = A | 0;\n        this.B = B | 0;\n        this.C = C | 0;\n        this.D = D | 0;\n        this.E = E | 0;\n        this.F = F | 0;\n        this.G = G | 0;\n        this.H = H | 0;\n    }\n    process(view, offset) {\n        // Extend the first 16 words into the remaining 48 words w[16..63] of the message schedule array\n        for (let i = 0; i < 16; i++, offset += 4)\n            SHA256_W[i] = view.getUint32(offset, false);\n        for (let i = 16; i < 64; i++) {\n            const W15 = SHA256_W[i - 15];\n            const W2 = SHA256_W[i - 2];\n            const s0 = rotr(W15, 7) ^ rotr(W15, 18) ^ (W15 >>> 3);\n            const s1 = rotr(W2, 17) ^ rotr(W2, 19) ^ (W2 >>> 10);\n            SHA256_W[i] = (s1 + SHA256_W[i - 7] + s0 + SHA256_W[i - 16]) | 0;\n        }\n        // Compression function main loop, 64 rounds\n        let { A, B, C, D, E, F, G, H } = this;\n        for (let i = 0; i < 64; i++) {\n            const sigma1 = rotr(E, 6) ^ rotr(E, 11) ^ rotr(E, 25);\n            const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;\n            const sigma0 = rotr(A, 2) ^ rotr(A, 13) ^ rotr(A, 22);\n            const T2 = (sigma0 + Maj(A, B, C)) | 0;\n            H = G;\n            G = F;\n            F = E;\n            E = (D + T1) | 0;\n            D = C;\n            C = B;\n            B = A;\n            A = (T1 + T2) | 0;\n        }\n        // Add the compressed chunk to the current hash value\n        A = (A + this.A) | 0;\n        B = (B + this.B) | 0;\n        C = (C + this.C) | 0;\n        D = (D + this.D) | 0;\n        E = (E + this.E) | 0;\n        F = (F + this.F) | 0;\n        G = (G + this.G) | 0;\n        H = (H + this.H) | 0;\n        this.set(A, B, C, D, E, F, G, H);\n    }\n    roundClean() {\n        clean(SHA256_W);\n    }\n    destroy() {\n        this.set(0, 0, 0, 0, 0, 0, 0, 0);\n        clean(this.buffer);\n    }\n}\nexport class SHA224 extends SHA256 {\n    constructor() {\n        super(28);\n        this.A = SHA224_IV[0] | 0;\n        this.B = SHA224_IV[1] | 0;\n        this.C = SHA224_IV[2] | 0;\n        this.D = SHA224_IV[3] | 0;\n        this.E = SHA224_IV[4] | 0;\n        this.F = SHA224_IV[5] | 0;\n        this.G = SHA224_IV[6] | 0;\n        this.H = SHA224_IV[7] | 0;\n    }\n}\n// SHA2-512 is slower than sha256 in js because u64 operations are slow.\n// Round contants\n// First 32 bits of the fractional parts of the cube roots of the first 80 primes 2..409\n// prettier-ignore\nconst K512 = /* @__PURE__ */ (() => u64.split([\n    '0x428a2f98d728ae22', '0x7137449123ef65cd', '0xb5c0fbcfec4d3b2f', '0xe9b5dba58189dbbc',\n    '0x3956c25bf348b538', '0x59f111f1b605d019', '0x923f82a4af194f9b', '0xab1c5ed5da6d8118',\n    '0xd807aa98a3030242', '0x12835b0145706fbe', '0x243185be4ee4b28c', '0x550c7dc3d5ffb4e2',\n    '0x72be5d74f27b896f', '0x80deb1fe3b1696b1', '0x9bdc06a725c71235', '0xc19bf174cf692694',\n    '0xe49b69c19ef14ad2', '0xefbe4786384f25e3', '0x0fc19dc68b8cd5b5', '0x240ca1cc77ac9c65',\n    '0x2de92c6f592b0275', '0x4a7484aa6ea6e483', '0x5cb0a9dcbd41fbd4', '0x76f988da831153b5',\n    '0x983e5152ee66dfab', '0xa831c66d2db43210', '0xb00327c898fb213f', '0xbf597fc7beef0ee4',\n    '0xc6e00bf33da88fc2', '0xd5a79147930aa725', '0x06ca6351e003826f', '0x142929670a0e6e70',\n    '0x27b70a8546d22ffc', '0x2e1b21385c26c926', '0x4d2c6dfc5ac42aed', '0x53380d139d95b3df',\n    '0x650a73548baf63de', '0x766a0abb3c77b2a8', '0x81c2c92e47edaee6', '0x92722c851482353b',\n    '0xa2bfe8a14cf10364', '0xa81a664bbc423001', '0xc24b8b70d0f89791', '0xc76c51a30654be30',\n    '0xd192e819d6ef5218', '0xd69906245565a910', '0xf40e35855771202a', '0x106aa07032bbd1b8',\n    '0x19a4c116b8d2d0c8', '0x1e376c085141ab53', '0x2748774cdf8eeb99', '0x34b0bcb5e19b48a8',\n    '0x391c0cb3c5c95a63', '0x4ed8aa4ae3418acb', '0x5b9cca4f7763e373', '0x682e6ff3d6b2b8a3',\n    '0x748f82ee5defb2fc', '0x78a5636f43172f60', '0x84c87814a1f0ab72', '0x8cc702081a6439ec',\n    '0x90befffa23631e28', '0xa4506cebde82bde9', '0xbef9a3f7b2c67915', '0xc67178f2e372532b',\n    '0xca273eceea26619c', '0xd186b8c721c0c207', '0xeada7dd6cde0eb1e', '0xf57d4f7fee6ed178',\n    '0x06f067aa72176fba', '0x0a637dc5a2c898a6', '0x113f9804bef90dae', '0x1b710b35131c471b',\n    '0x28db77f523047d84', '0x32caab7b40c72493', '0x3c9ebe0a15c9bebc', '0x431d67c49c100d4c',\n    '0x4cc5d4becb3e42b6', '0x597f299cfc657e2a', '0x5fcb6fab3ad6faec', '0x6c44198c4a475817'\n].map(n => BigInt(n))))();\nconst SHA512_Kh = /* @__PURE__ */ (() => K512[0])();\nconst SHA512_Kl = /* @__PURE__ */ (() => K512[1])();\n// Reusable temporary buffers\nconst SHA512_W_H = /* @__PURE__ */ new Uint32Array(80);\nconst SHA512_W_L = /* @__PURE__ */ new Uint32Array(80);\nexport class SHA512 extends HashMD {\n    constructor(outputLen = 64) {\n        super(128, outputLen, 16, false);\n        // We cannot use array here since array allows indexing by variable\n        // which means optimizer/compiler cannot use registers.\n        // h -- high 32 bits, l -- low 32 bits\n        this.Ah = SHA512_IV[0] | 0;\n        this.Al = SHA512_IV[1] | 0;\n        this.Bh = SHA512_IV[2] | 0;\n        this.Bl = SHA512_IV[3] | 0;\n        this.Ch = SHA512_IV[4] | 0;\n        this.Cl = SHA512_IV[5] | 0;\n        this.Dh = SHA512_IV[6] | 0;\n        this.Dl = SHA512_IV[7] | 0;\n        this.Eh = SHA512_IV[8] | 0;\n        this.El = SHA512_IV[9] | 0;\n        this.Fh = SHA512_IV[10] | 0;\n        this.Fl = SHA512_IV[11] | 0;\n        this.Gh = SHA512_IV[12] | 0;\n        this.Gl = SHA512_IV[13] | 0;\n        this.Hh = SHA512_IV[14] | 0;\n        this.Hl = SHA512_IV[15] | 0;\n    }\n    // prettier-ignore\n    get() {\n        const { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;\n        return [Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl];\n    }\n    // prettier-ignore\n    set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl) {\n        this.Ah = Ah | 0;\n        this.Al = Al | 0;\n        this.Bh = Bh | 0;\n        this.Bl = Bl | 0;\n        this.Ch = Ch | 0;\n        this.Cl = Cl | 0;\n        this.Dh = Dh | 0;\n        this.Dl = Dl | 0;\n        this.Eh = Eh | 0;\n        this.El = El | 0;\n        this.Fh = Fh | 0;\n        this.Fl = Fl | 0;\n        this.Gh = Gh | 0;\n        this.Gl = Gl | 0;\n        this.Hh = Hh | 0;\n        this.Hl = Hl | 0;\n    }\n    process(view, offset) {\n        // Extend the first 16 words into the remaining 64 words w[16..79] of the message schedule array\n        for (let i = 0; i < 16; i++, offset += 4) {\n            SHA512_W_H[i] = view.getUint32(offset);\n            SHA512_W_L[i] = view.getUint32((offset += 4));\n        }\n        for (let i = 16; i < 80; i++) {\n            // s0 := (w[i-15] rightrotate 1) xor (w[i-15] rightrotate 8) xor (w[i-15] rightshift 7)\n            const W15h = SHA512_W_H[i - 15] | 0;\n            const W15l = SHA512_W_L[i - 15] | 0;\n            const s0h = u64.rotrSH(W15h, W15l, 1) ^ u64.rotrSH(W15h, W15l, 8) ^ u64.shrSH(W15h, W15l, 7);\n            const s0l = u64.rotrSL(W15h, W15l, 1) ^ u64.rotrSL(W15h, W15l, 8) ^ u64.shrSL(W15h, W15l, 7);\n            // s1 := (w[i-2] rightrotate 19) xor (w[i-2] rightrotate 61) xor (w[i-2] rightshift 6)\n            const W2h = SHA512_W_H[i - 2] | 0;\n            const W2l = SHA512_W_L[i - 2] | 0;\n            const s1h = u64.rotrSH(W2h, W2l, 19) ^ u64.rotrBH(W2h, W2l, 61) ^ u64.shrSH(W2h, W2l, 6);\n            const s1l = u64.rotrSL(W2h, W2l, 19) ^ u64.rotrBL(W2h, W2l, 61) ^ u64.shrSL(W2h, W2l, 6);\n            // SHA256_W[i] = s0 + s1 + SHA256_W[i - 7] + SHA256_W[i - 16];\n            const SUMl = u64.add4L(s0l, s1l, SHA512_W_L[i - 7], SHA512_W_L[i - 16]);\n            const SUMh = u64.add4H(SUMl, s0h, s1h, SHA512_W_H[i - 7], SHA512_W_H[i - 16]);\n            SHA512_W_H[i] = SUMh | 0;\n            SHA512_W_L[i] = SUMl | 0;\n        }\n        let { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;\n        // Compression function main loop, 80 rounds\n        for (let i = 0; i < 80; i++) {\n            // S1 := (e rightrotate 14) xor (e rightrotate 18) xor (e rightrotate 41)\n            const sigma1h = u64.rotrSH(Eh, El, 14) ^ u64.rotrSH(Eh, El, 18) ^ u64.rotrBH(Eh, El, 41);\n            const sigma1l = u64.rotrSL(Eh, El, 14) ^ u64.rotrSL(Eh, El, 18) ^ u64.rotrBL(Eh, El, 41);\n            //const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;\n            const CHIh = (Eh & Fh) ^ (~Eh & Gh);\n            const CHIl = (El & Fl) ^ (~El & Gl);\n            // T1 = H + sigma1 + Chi(E, F, G) + SHA512_K[i] + SHA512_W[i]\n            // prettier-ignore\n            const T1ll = u64.add5L(Hl, sigma1l, CHIl, SHA512_Kl[i], SHA512_W_L[i]);\n            const T1h = u64.add5H(T1ll, Hh, sigma1h, CHIh, SHA512_Kh[i], SHA512_W_H[i]);\n            const T1l = T1ll | 0;\n            // S0 := (a rightrotate 28) xor (a rightrotate 34) xor (a rightrotate 39)\n            const sigma0h = u64.rotrSH(Ah, Al, 28) ^ u64.rotrBH(Ah, Al, 34) ^ u64.rotrBH(Ah, Al, 39);\n            const sigma0l = u64.rotrSL(Ah, Al, 28) ^ u64.rotrBL(Ah, Al, 34) ^ u64.rotrBL(Ah, Al, 39);\n            const MAJh = (Ah & Bh) ^ (Ah & Ch) ^ (Bh & Ch);\n            const MAJl = (Al & Bl) ^ (Al & Cl) ^ (Bl & Cl);\n            Hh = Gh | 0;\n            Hl = Gl | 0;\n            Gh = Fh | 0;\n            Gl = Fl | 0;\n            Fh = Eh | 0;\n            Fl = El | 0;\n            ({ h: Eh, l: El } = u64.add(Dh | 0, Dl | 0, T1h | 0, T1l | 0));\n            Dh = Ch | 0;\n            Dl = Cl | 0;\n            Ch = Bh | 0;\n            Cl = Bl | 0;\n            Bh = Ah | 0;\n            Bl = Al | 0;\n            const All = u64.add3L(T1l, sigma0l, MAJl);\n            Ah = u64.add3H(All, T1h, sigma0h, MAJh);\n            Al = All | 0;\n        }\n        // Add the compressed chunk to the current hash value\n        ({ h: Ah, l: Al } = u64.add(this.Ah | 0, this.Al | 0, Ah | 0, Al | 0));\n        ({ h: Bh, l: Bl } = u64.add(this.Bh | 0, this.Bl | 0, Bh | 0, Bl | 0));\n        ({ h: Ch, l: Cl } = u64.add(this.Ch | 0, this.Cl | 0, Ch | 0, Cl | 0));\n        ({ h: Dh, l: Dl } = u64.add(this.Dh | 0, this.Dl | 0, Dh | 0, Dl | 0));\n        ({ h: Eh, l: El } = u64.add(this.Eh | 0, this.El | 0, Eh | 0, El | 0));\n        ({ h: Fh, l: Fl } = u64.add(this.Fh | 0, this.Fl | 0, Fh | 0, Fl | 0));\n        ({ h: Gh, l: Gl } = u64.add(this.Gh | 0, this.Gl | 0, Gh | 0, Gl | 0));\n        ({ h: Hh, l: Hl } = u64.add(this.Hh | 0, this.Hl | 0, Hh | 0, Hl | 0));\n        this.set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl);\n    }\n    roundClean() {\n        clean(SHA512_W_H, SHA512_W_L);\n    }\n    destroy() {\n        clean(this.buffer);\n        this.set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    }\n}\nexport class SHA384 extends SHA512 {\n    constructor() {\n        super(48);\n        this.Ah = SHA384_IV[0] | 0;\n        this.Al = SHA384_IV[1] | 0;\n        this.Bh = SHA384_IV[2] | 0;\n        this.Bl = SHA384_IV[3] | 0;\n        this.Ch = SHA384_IV[4] | 0;\n        this.Cl = SHA384_IV[5] | 0;\n        this.Dh = SHA384_IV[6] | 0;\n        this.Dl = SHA384_IV[7] | 0;\n        this.Eh = SHA384_IV[8] | 0;\n        this.El = SHA384_IV[9] | 0;\n        this.Fh = SHA384_IV[10] | 0;\n        this.Fl = SHA384_IV[11] | 0;\n        this.Gh = SHA384_IV[12] | 0;\n        this.Gl = SHA384_IV[13] | 0;\n        this.Hh = SHA384_IV[14] | 0;\n        this.Hl = SHA384_IV[15] | 0;\n    }\n}\n/**\n * Truncated SHA512/256 and SHA512/224.\n * SHA512_IV is XORed with 0xa5a5a5a5a5a5a5a5, then used as \"intermediary\" IV of SHA512/t.\n * Then t hashes string to produce result IV.\n * See `test/misc/sha2-gen-iv.js`.\n */\n/** SHA512/224 IV */\nconst T224_IV = /* @__PURE__ */ Uint32Array.from([\n    0x8c3d37c8, 0x19544da2, 0x73e19966, 0x89dcd4d6, 0x1dfab7ae, 0x32ff9c82, 0x679dd514, 0x582f9fcf,\n    0x0f6d2b69, 0x7bd44da8, 0x77e36f73, 0x04c48942, 0x3f9d85a8, 0x6a1d36c8, 0x1112e6ad, 0x91d692a1,\n]);\n/** SHA512/256 IV */\nconst T256_IV = /* @__PURE__ */ Uint32Array.from([\n    0x22312194, 0xfc2bf72c, 0x9f555fa3, 0xc84c64c2, 0x2393b86b, 0x6f53b151, 0x96387719, 0x5940eabd,\n    0x96283ee2, 0xa88effe3, 0xbe5e1e25, 0x53863992, 0x2b0199fc, 0x2c85b8aa, 0x0eb72ddc, 0x81c52ca2,\n]);\nexport class SHA512_224 extends SHA512 {\n    constructor() {\n        super(28);\n        this.Ah = T224_IV[0] | 0;\n        this.Al = T224_IV[1] | 0;\n        this.Bh = T224_IV[2] | 0;\n        this.Bl = T224_IV[3] | 0;\n        this.Ch = T224_IV[4] | 0;\n        this.Cl = T224_IV[5] | 0;\n        this.Dh = T224_IV[6] | 0;\n        this.Dl = T224_IV[7] | 0;\n        this.Eh = T224_IV[8] | 0;\n        this.El = T224_IV[9] | 0;\n        this.Fh = T224_IV[10] | 0;\n        this.Fl = T224_IV[11] | 0;\n        this.Gh = T224_IV[12] | 0;\n        this.Gl = T224_IV[13] | 0;\n        this.Hh = T224_IV[14] | 0;\n        this.Hl = T224_IV[15] | 0;\n    }\n}\nexport class SHA512_256 extends SHA512 {\n    constructor() {\n        super(32);\n        this.Ah = T256_IV[0] | 0;\n        this.Al = T256_IV[1] | 0;\n        this.Bh = T256_IV[2] | 0;\n        this.Bl = T256_IV[3] | 0;\n        this.Ch = T256_IV[4] | 0;\n        this.Cl = T256_IV[5] | 0;\n        this.Dh = T256_IV[6] | 0;\n        this.Dl = T256_IV[7] | 0;\n        this.Eh = T256_IV[8] | 0;\n        this.El = T256_IV[9] | 0;\n        this.Fh = T256_IV[10] | 0;\n        this.Fl = T256_IV[11] | 0;\n        this.Gh = T256_IV[12] | 0;\n        this.Gl = T256_IV[13] | 0;\n        this.Hh = T256_IV[14] | 0;\n        this.Hl = T256_IV[15] | 0;\n    }\n}\n/**\n * SHA2-256 hash function from RFC 4634.\n *\n * It is the fastest JS hash, even faster than Blake3.\n * To break sha256 using birthday attack, attackers need to try 2^128 hashes.\n * BTC network is doing 2^70 hashes/sec (2^95 hashes/year) as per 2025.\n */\nexport const sha256 = /* @__PURE__ */ createHasher(() => new SHA256());\n/** SHA2-224 hash function from RFC 4634 */\nexport const sha224 = /* @__PURE__ */ createHasher(() => new SHA224());\n/** SHA2-512 hash function from RFC 4634. */\nexport const sha512 = /* @__PURE__ */ createHasher(() => new SHA512());\n/** SHA2-384 hash function from RFC 4634. */\nexport const sha384 = /* @__PURE__ */ createHasher(() => new SHA384());\n/**\n * SHA2-512/256 \"truncated\" hash function, with improved resistance to length extension attacks.\n * See the paper on [truncated SHA512](https://eprint.iacr.org/2010/548.pdf).\n */\nexport const sha512_256 = /* @__PURE__ */ createHasher(() => new SHA512_256());\n/**\n * SHA2-512/224 \"truncated\" hash function, with improved resistance to length extension attacks.\n * See the paper on [truncated SHA512](https://eprint.iacr.org/2010/548.pdf).\n */\nexport const sha512_224 = /* @__PURE__ */ createHasher(() => new SHA512_224());\n//# sourceMappingURL=sha2.js.map","/**\n * SHA2-256 a.k.a. sha256. In JS, it is the fastest hash, even faster than Blake3.\n *\n * To break sha256 using birthday attack, attackers need to try 2^128 hashes.\n * BTC network is doing 2^70 hashes/sec (2^95 hashes/year) as per 2025.\n *\n * Check out [FIPS 180-4](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf).\n * @module\n * @deprecated\n */\nimport { SHA224 as SHA224n, sha224 as sha224n, SHA256 as SHA256n, sha256 as sha256n, } from \"./sha2.js\";\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const SHA256 = SHA256n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const sha256 = sha256n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const SHA224 = SHA224n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const sha224 = sha224n;\n//# sourceMappingURL=sha256.js.map","/**\n * SHA2-512 a.k.a. sha512 and sha384. It is slower than sha256 in js because u64 operations are slow.\n *\n * Check out [RFC 4634](https://datatracker.ietf.org/doc/html/rfc4634) and\n * [the paper on truncated SHA512/256](https://eprint.iacr.org/2010/548.pdf).\n * @module\n * @deprecated\n */\nimport { SHA384 as SHA384n, sha384 as sha384n, sha512_224 as sha512_224n, SHA512_224 as SHA512_224n, sha512_256 as sha512_256n, SHA512_256 as SHA512_256n, SHA512 as SHA512n, sha512 as sha512n, } from \"./sha2.js\";\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const SHA512 = SHA512n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const sha512 = sha512n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const SHA384 = SHA384n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const sha384 = sha384n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const SHA512_224 = SHA512_224n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const sha512_224 = sha512_224n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const SHA512_256 = SHA512_256n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const sha512_256 = sha512_256n;\n//# sourceMappingURL=sha512.js.map","/**\n * Utilities for hex, bytes, CSPRNG.\n * @module\n */\n/*! noble-hashes - MIT License (c) 2022 Paul Miller (paulmillr.com) */\n// We use WebCrypto aka globalThis.crypto, which exists in browsers and node.js 16+.\n// node.js versions earlier than v19 don't declare it in global scope.\n// For node.js, package.json#exports field mapping rewrites import\n// from `crypto` to `cryptoNode`, which imports native module.\n// Makes the utils un-importable in browsers without a bundler.\n// Once node.js 18 is deprecated (2025-04-30), we can just drop the import.\nimport { crypto } from '@noble/hashes/crypto';\n/** Checks if something is Uint8Array. Be careful: nodejs Buffer will return true. */\nexport function isBytes(a) {\n    return a instanceof Uint8Array || (ArrayBuffer.isView(a) && a.constructor.name === 'Uint8Array');\n}\n/** Asserts something is positive integer. */\nexport function anumber(n) {\n    if (!Number.isSafeInteger(n) || n < 0)\n        throw new Error('positive integer expected, got ' + n);\n}\n/** Asserts something is Uint8Array. */\nexport function abytes(b, ...lengths) {\n    if (!isBytes(b))\n        throw new Error('Uint8Array expected');\n    if (lengths.length > 0 && !lengths.includes(b.length))\n        throw new Error('Uint8Array expected of length ' + lengths + ', got length=' + b.length);\n}\n/** Asserts something is hash */\nexport function ahash(h) {\n    if (typeof h !== 'function' || typeof h.create !== 'function')\n        throw new Error('Hash should be wrapped by utils.createHasher');\n    anumber(h.outputLen);\n    anumber(h.blockLen);\n}\n/** Asserts a hash instance has not been destroyed / finished */\nexport function aexists(instance, checkFinished = true) {\n    if (instance.destroyed)\n        throw new Error('Hash instance has been destroyed');\n    if (checkFinished && instance.finished)\n        throw new Error('Hash#digest() has already been called');\n}\n/** Asserts output is properly-sized byte array */\nexport function aoutput(out, instance) {\n    abytes(out);\n    const min = instance.outputLen;\n    if (out.length < min) {\n        throw new Error('digestInto() expects output buffer of length at least ' + min);\n    }\n}\n/** Cast u8 / u16 / u32 to u8. */\nexport function u8(arr) {\n    return new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength);\n}\n/** Cast u8 / u16 / u32 to u32. */\nexport function u32(arr) {\n    return new Uint32Array(arr.buffer, arr.byteOffset, Math.floor(arr.byteLength / 4));\n}\n/** Zeroize a byte array. Warning: JS provides no guarantees. */\nexport function clean(...arrays) {\n    for (let i = 0; i < arrays.length; i++) {\n        arrays[i].fill(0);\n    }\n}\n/** Create DataView of an array for easy byte-level manipulation. */\nexport function createView(arr) {\n    return new DataView(arr.buffer, arr.byteOffset, arr.byteLength);\n}\n/** The rotate right (circular right shift) operation for uint32 */\nexport function rotr(word, shift) {\n    return (word << (32 - shift)) | (word >>> shift);\n}\n/** The rotate left (circular left shift) operation for uint32 */\nexport function rotl(word, shift) {\n    return (word << shift) | ((word >>> (32 - shift)) >>> 0);\n}\n/** Is current platform little-endian? Most are. Big-Endian platform: IBM */\nexport const isLE = /* @__PURE__ */ (() => new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44)();\n/** The byte swap operation for uint32 */\nexport function byteSwap(word) {\n    return (((word << 24) & 0xff000000) |\n        ((word << 8) & 0xff0000) |\n        ((word >>> 8) & 0xff00) |\n        ((word >>> 24) & 0xff));\n}\n/** Conditionally byte swap if on a big-endian platform */\nexport const swap8IfBE = isLE\n    ? (n) => n\n    : (n) => byteSwap(n);\n/** @deprecated */\nexport const byteSwapIfBE = swap8IfBE;\n/** In place byte swap for Uint32Array */\nexport function byteSwap32(arr) {\n    for (let i = 0; i < arr.length; i++) {\n        arr[i] = byteSwap(arr[i]);\n    }\n    return arr;\n}\nexport const swap32IfBE = isLE\n    ? (u) => u\n    : byteSwap32;\n// Built-in hex conversion https://caniuse.com/mdn-javascript_builtins_uint8array_fromhex\nconst hasHexBuiltin = /* @__PURE__ */ (() => \n// @ts-ignore\ntypeof Uint8Array.from([]).toHex === 'function' && typeof Uint8Array.fromHex === 'function')();\n// Array where index 0xf0 (240) is mapped to string 'f0'\nconst hexes = /* @__PURE__ */ Array.from({ length: 256 }, (_, i) => i.toString(16).padStart(2, '0'));\n/**\n * Convert byte array to hex string. Uses built-in function, when available.\n * @example bytesToHex(Uint8Array.from([0xca, 0xfe, 0x01, 0x23])) // 'cafe0123'\n */\nexport function bytesToHex(bytes) {\n    abytes(bytes);\n    // @ts-ignore\n    if (hasHexBuiltin)\n        return bytes.toHex();\n    // pre-caching improves the speed 6x\n    let hex = '';\n    for (let i = 0; i < bytes.length; i++) {\n        hex += hexes[bytes[i]];\n    }\n    return hex;\n}\n// We use optimized technique to convert hex string to byte array\nconst asciis = { _0: 48, _9: 57, A: 65, F: 70, a: 97, f: 102 };\nfunction asciiToBase16(ch) {\n    if (ch >= asciis._0 && ch <= asciis._9)\n        return ch - asciis._0; // '2' => 50-48\n    if (ch >= asciis.A && ch <= asciis.F)\n        return ch - (asciis.A - 10); // 'B' => 66-(65-10)\n    if (ch >= asciis.a && ch <= asciis.f)\n        return ch - (asciis.a - 10); // 'b' => 98-(97-10)\n    return;\n}\n/**\n * Convert hex string to byte array. Uses built-in function, when available.\n * @example hexToBytes('cafe0123') // Uint8Array.from([0xca, 0xfe, 0x01, 0x23])\n */\nexport function hexToBytes(hex) {\n    if (typeof hex !== 'string')\n        throw new Error('hex string expected, got ' + typeof hex);\n    // @ts-ignore\n    if (hasHexBuiltin)\n        return Uint8Array.fromHex(hex);\n    const hl = hex.length;\n    const al = hl / 2;\n    if (hl % 2)\n        throw new Error('hex string expected, got unpadded hex of length ' + hl);\n    const array = new Uint8Array(al);\n    for (let ai = 0, hi = 0; ai < al; ai++, hi += 2) {\n        const n1 = asciiToBase16(hex.charCodeAt(hi));\n        const n2 = asciiToBase16(hex.charCodeAt(hi + 1));\n        if (n1 === undefined || n2 === undefined) {\n            const char = hex[hi] + hex[hi + 1];\n            throw new Error('hex string expected, got non-hex character \"' + char + '\" at index ' + hi);\n        }\n        array[ai] = n1 * 16 + n2; // multiply first octet, e.g. 'a3' => 10*16+3 => 160 + 3 => 163\n    }\n    return array;\n}\n/**\n * There is no setImmediate in browser and setTimeout is slow.\n * Call of async fn will return Promise, which will be fullfiled only on\n * next scheduler queue processing step and this is exactly what we need.\n */\nexport const nextTick = async () => { };\n/** Returns control to thread each 'tick' ms to avoid blocking. */\nexport async function asyncLoop(iters, tick, cb) {\n    let ts = Date.now();\n    for (let i = 0; i < iters; i++) {\n        cb(i);\n        // Date.now() is not monotonic, so in case if clock goes backwards we return return control too\n        const diff = Date.now() - ts;\n        if (diff >= 0 && diff < tick)\n            continue;\n        await nextTick();\n        ts += diff;\n    }\n}\n/**\n * Converts string to bytes using UTF8 encoding.\n * @example utf8ToBytes('abc') // Uint8Array.from([97, 98, 99])\n */\nexport function utf8ToBytes(str) {\n    if (typeof str !== 'string')\n        throw new Error('string expected');\n    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809\n}\n/**\n * Converts bytes to string using UTF8 encoding.\n * @example bytesToUtf8(Uint8Array.from([97, 98, 99])) // 'abc'\n */\nexport function bytesToUtf8(bytes) {\n    return new TextDecoder().decode(bytes);\n}\n/**\n * Normalizes (non-hex) string or Uint8Array to Uint8Array.\n * Warning: when Uint8Array is passed, it would NOT get copied.\n * Keep in mind for future mutable operations.\n */\nexport function toBytes(data) {\n    if (typeof data === 'string')\n        data = utf8ToBytes(data);\n    abytes(data);\n    return data;\n}\n/**\n * Helper for KDFs: consumes uint8array or string.\n * When string is passed, does utf8 decoding, using TextDecoder.\n */\nexport function kdfInputToBytes(data) {\n    if (typeof data === 'string')\n        data = utf8ToBytes(data);\n    abytes(data);\n    return data;\n}\n/** Copies several Uint8Arrays into one. */\nexport function concatBytes(...arrays) {\n    let sum = 0;\n    for (let i = 0; i < arrays.length; i++) {\n        const a = arrays[i];\n        abytes(a);\n        sum += a.length;\n    }\n    const res = new Uint8Array(sum);\n    for (let i = 0, pad = 0; i < arrays.length; i++) {\n        const a = arrays[i];\n        res.set(a, pad);\n        pad += a.length;\n    }\n    return res;\n}\nexport function checkOpts(defaults, opts) {\n    if (opts !== undefined && {}.toString.call(opts) !== '[object Object]')\n        throw new Error('options should be object or undefined');\n    const merged = Object.assign(defaults, opts);\n    return merged;\n}\n/** For runtime check if class implements interface */\nexport class Hash {\n}\n/** Wraps hash function, creating an interface on top of it */\nexport function createHasher(hashCons) {\n    const hashC = (msg) => hashCons().update(toBytes(msg)).digest();\n    const tmp = hashCons();\n    hashC.outputLen = tmp.outputLen;\n    hashC.blockLen = tmp.blockLen;\n    hashC.create = () => hashCons();\n    return hashC;\n}\nexport function createOptHasher(hashCons) {\n    const hashC = (msg, opts) => hashCons(opts).update(toBytes(msg)).digest();\n    const tmp = hashCons({});\n    hashC.outputLen = tmp.outputLen;\n    hashC.blockLen = tmp.blockLen;\n    hashC.create = (opts) => hashCons(opts);\n    return hashC;\n}\nexport function createXOFer(hashCons) {\n    const hashC = (msg, opts) => hashCons(opts).update(toBytes(msg)).digest();\n    const tmp = hashCons({});\n    hashC.outputLen = tmp.outputLen;\n    hashC.blockLen = tmp.blockLen;\n    hashC.create = (opts) => hashCons(opts);\n    return hashC;\n}\nexport const wrapConstructor = createHasher;\nexport const wrapConstructorWithOpts = createOptHasher;\nexport const wrapXOFConstructorWithOpts = createXOFer;\n/** Cryptographically secure PRNG. Uses internal OS-level `crypto.getRandomValues`. */\nexport function randomBytes(bytesLength = 32) {\n    if (crypto && typeof crypto.getRandomValues === 'function') {\n        return crypto.getRandomValues(new Uint8Array(bytesLength));\n    }\n    // Legacy Node.js compatibility\n    if (crypto && typeof crypto.randomBytes === 'function') {\n        return Uint8Array.from(crypto.randomBytes(bytesLength));\n    }\n    throw new Error('crypto.getRandomValues must be defined');\n}\n//# sourceMappingURL=utils.js.map","import { RequestId } from './RequestId.js';\nimport { CborDecoder } from '../cbor/CborDecoder.js';\nimport { CborEncoder } from '../cbor/CborEncoder.js';\nimport { DataHash } from '../hash/DataHash.js';\nimport { Signature } from '../signing/Signature.js';\nimport { SigningService } from '../signing/SigningService.js';\nimport { HexConverter } from '../util/HexConverter.js';\nimport { dedent } from '../util/StringUtils.js';\n/**\n * Represents an Authenticator for signing and verifying transactions.\n */\nexport class Authenticator {\n    algorithm;\n    _publicKey;\n    signature;\n    stateHash;\n    /**\n     * Constructs an Authenticator instance.\n     * @param algorithm The signature algorithm used.\n     * @param _publicKey The public key as a Uint8Array.\n     * @param signature The signature object.\n     * @param stateHash The state hash object.\n     */\n    constructor(algorithm, _publicKey, signature, stateHash) {\n        this.algorithm = algorithm;\n        this._publicKey = _publicKey;\n        this.signature = signature;\n        this.stateHash = stateHash;\n        this._publicKey = new Uint8Array(_publicKey);\n    }\n    /**\n     * Gets a copy of the public key.\n     * @returns The public key as a Uint8Array.\n     */\n    get publicKey() {\n        return new Uint8Array(this._publicKey);\n    }\n    /**\n     * Creates an Authenticator by signing a transaction hash.\n     * @param signingService The signing service to use.\n     * @param transactionHash The transaction hash to sign.\n     * @param stateHash The state hash.\n     * @returns A Promise resolving to an Authenticator instance.\n     */\n    static async create(signingService, transactionHash, stateHash) {\n        return new Authenticator(signingService.algorithm, signingService.publicKey, await signingService.sign(transactionHash), stateHash);\n    }\n    /**\n     * Creates an Authenticator from a JSON object.\n     * @param data The JSON data.\n     * @returns An Authenticator instance.\n     * @throws Error if parsing fails.\n     */\n    static fromJSON(data) {\n        if (!Authenticator.isJSON(data)) {\n            throw new Error('Parsing authenticator dto failed.');\n        }\n        return new Authenticator(data.algorithm, HexConverter.decode(data.publicKey), Signature.fromJSON(data.signature), DataHash.fromJSON(data.stateHash));\n    }\n    /**\n     * Type guard to check if data is IAuthenticatorJson.\n     * @param data The data to check.\n     * @returns True if data is IAuthenticatorJson, false otherwise.\n     */\n    static isJSON(data) {\n        return (typeof data === 'object' &&\n            data !== null &&\n            'publicKey' in data &&\n            typeof data.publicKey === 'string' &&\n            'algorithm' in data &&\n            typeof data.algorithm === 'string' &&\n            'signature' in data &&\n            typeof data.signature === 'string' &&\n            'stateHash' in data &&\n            typeof data.stateHash === 'string');\n    }\n    /**\n     * Decodes an Authenticator from CBOR bytes.\n     * @param bytes The CBOR-encoded bytes.\n     * @returns An Authenticator instance.\n     */\n    static fromCBOR(bytes) {\n        const data = CborDecoder.readArray(bytes);\n        return new Authenticator(CborDecoder.readTextString(data[0]), CborDecoder.readByteString(data[1]), Signature.decode(CborDecoder.readByteString(data[2])), DataHash.fromImprint(CborDecoder.readByteString(data[3])));\n    }\n    /**\n     * Encodes the Authenticator to CBOR format.\n     * @returns The CBOR-encoded bytes.\n     */\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            CborEncoder.encodeTextString(this.algorithm),\n            CborEncoder.encodeByteString(this.publicKey),\n            CborEncoder.encodeByteString(this.signature.encode()),\n            CborEncoder.encodeByteString(this.stateHash.imprint),\n        ]);\n    }\n    /**\n     * Converts the Authenticator to a JSON object.\n     * @returns The Authenticator as IAuthenticatorJson.\n     */\n    toJSON() {\n        return {\n            algorithm: this.algorithm,\n            publicKey: HexConverter.encode(this.publicKey),\n            signature: this.signature.toJSON(),\n            stateHash: this.stateHash.toJSON(),\n        };\n    }\n    /**\n     * Verifies the signature for a given transaction hash.\n     * @param transactionHash The transaction hash to verify.\n     * @returns A Promise resolving to true if valid, false otherwise.\n     */\n    verify(transactionHash) {\n        return SigningService.verifyWithPublicKey(transactionHash, this.signature.bytes, this.publicKey);\n    }\n    /**\n     * Calculates the request ID for this Authenticator.\n     * @returns A Promise resolving to a RequestId.\n     */\n    calculateRequestId() {\n        return RequestId.create(this._publicKey, this.stateHash);\n    }\n    /**\n     * Returns a string representation of the Authenticator.\n     * @returns The string representation.\n     */\n    toString() {\n        return dedent `\n      Authenticator\n        Public Key: ${HexConverter.encode(this._publicKey)}\n        Signature Algorithm: ${this.algorithm}\n        Signature: ${this.signature.toString()}\n        State Hash: ${this.stateHash.toString()}`;\n    }\n}\n","import { Authenticator } from './Authenticator.js';\nimport { LeafValue } from './LeafValue.js';\nimport { CborDecoder } from '../cbor/CborDecoder.js';\nimport { CborEncoder } from '../cbor/CborEncoder.js';\nimport { DataHash } from '../hash/DataHash.js';\nimport { MerkleTreePath } from '../smt/MerkleTreePath.js';\nimport { dedent } from '../util/StringUtils.js';\n/**\n * Status codes for verifying an InclusionProof.\n */\nexport var InclusionProofVerificationStatus;\n(function (InclusionProofVerificationStatus) {\n    InclusionProofVerificationStatus[\"NOT_AUTHENTICATED\"] = \"NOT_AUTHENTICATED\";\n    InclusionProofVerificationStatus[\"PATH_NOT_INCLUDED\"] = \"PATH_NOT_INCLUDED\";\n    InclusionProofVerificationStatus[\"PATH_INVALID\"] = \"PATH_INVALID\";\n    InclusionProofVerificationStatus[\"OK\"] = \"OK\";\n})(InclusionProofVerificationStatus || (InclusionProofVerificationStatus = {}));\n/**\n * Represents a proof of inclusion or non inclusion in a sparse merkle tree.\n */\nexport class InclusionProof {\n    merkleTreePath;\n    authenticator;\n    transactionHash;\n    /**\n     * Constructs an InclusionProof instance.\n     * @param merkleTreePath Sparse merkle tree path.\n     * @param authenticator Authenticator.\n     * @param transactionHash Transaction hash.\n     * @throws Error if authenticator and transactionHash are not both set or both null.\n     */\n    constructor(merkleTreePath, authenticator, transactionHash) {\n        this.merkleTreePath = merkleTreePath;\n        this.authenticator = authenticator;\n        this.transactionHash = transactionHash;\n        if (!this.authenticator != !this.transactionHash) {\n            throw new Error('Authenticator and transaction hash must be both set or both null.');\n        }\n    }\n    /**\n     * Type guard to check if data is IInclusionProofJson.\n     * @param data The data to check.\n     * @returns True if data is IInclusionProofJson, false otherwise.\n     */\n    static isJSON(data) {\n        return typeof data === 'object' && data !== null && 'merkleTreePath' in data;\n    }\n    /**\n     * Creates an InclusionProof from a JSON object.\n     * @param data The JSON data.\n     * @returns An InclusionProof instance.\n     * @throws Error if parsing fails.\n     */\n    static fromJSON(data) {\n        if (!InclusionProof.isJSON(data)) {\n            throw new Error('Parsing inclusion proof json failed.');\n        }\n        return new InclusionProof(MerkleTreePath.fromJSON(data.merkleTreePath), data.authenticator ? Authenticator.fromJSON(data.authenticator) : null, data.transactionHash ? DataHash.fromJSON(data.transactionHash) : null);\n    }\n    /**\n     * Decodes an InclusionProof from CBOR bytes.\n     * @param bytes The CBOR-encoded bytes.\n     * @returns An InclusionProof instance.\n     */\n    static fromCBOR(bytes) {\n        const data = CborDecoder.readArray(bytes);\n        const authenticator = CborDecoder.readOptional(data[1], Authenticator.fromCBOR);\n        const transactionHash = CborDecoder.readOptional(data[2], DataHash.fromCBOR);\n        return new InclusionProof(MerkleTreePath.fromCBOR(data[0]), authenticator, transactionHash);\n    }\n    /**\n     * Converts the InclusionProof to a JSON object.\n     * @returns The InclusionProof as IInclusionProofJson.\n     */\n    toJSON() {\n        return {\n            authenticator: this.authenticator?.toJSON() ?? null,\n            merkleTreePath: this.merkleTreePath.toJSON(),\n            transactionHash: this.transactionHash?.toJSON() ?? null,\n        };\n    }\n    /**\n     * Encodes the InclusionProof to CBOR format.\n     * @returns The CBOR-encoded bytes.\n     */\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            this.merkleTreePath.toCBOR(),\n            this.authenticator?.toCBOR() ?? CborEncoder.encodeNull(),\n            this.transactionHash?.toCBOR() ?? CborEncoder.encodeNull(),\n        ]);\n    }\n    /**\n     * Verifies the inclusion proof for a given request ID.\n     * @param requestId The request ID as a bigint.\n     * @returns A Promise resolving to the verification status.\n     */\n    async verify(requestId) {\n        if (this.authenticator && this.transactionHash) {\n            if (!(await this.authenticator.verify(this.transactionHash))) {\n                return InclusionProofVerificationStatus.NOT_AUTHENTICATED;\n            }\n            const leafValue = await LeafValue.create(this.authenticator, this.transactionHash);\n            if (!leafValue.equals(this.merkleTreePath.steps.at(0)?.branch?.value)) {\n                return InclusionProofVerificationStatus.PATH_NOT_INCLUDED;\n            }\n        }\n        const result = await this.merkleTreePath.verify(requestId);\n        if (!result.isPathValid) {\n            return InclusionProofVerificationStatus.PATH_INVALID;\n        }\n        if (!result.isPathIncluded) {\n            return InclusionProofVerificationStatus.PATH_NOT_INCLUDED;\n        }\n        return InclusionProofVerificationStatus.OK;\n    }\n    /**\n     * Returns a string representation of the InclusionProof.\n     * @returns The string representation.\n     */\n    toString() {\n        return dedent `\n      Inclusion Proof\n        ${this.merkleTreePath.toString()}\n        ${this.authenticator?.toString()}\n        Transaction Hash: ${this.transactionHash?.toString() ?? null}`;\n    }\n}\n","import { DataHasher } from '../hash/DataHasher.js';\nimport { HashAlgorithm } from '../hash/HashAlgorithm.js';\nimport { HexConverter } from '../util/HexConverter.js';\n/**\n * Represents the value of a leaf node in a sparse merkle tree, derived from an authenticator and transaction hash.\n */\nexport class LeafValue {\n    _bytes;\n    /**\n     * Constructs a LeafValue instance.\n     * @param _bytes The bytes representing the leaf value.\n     */\n    constructor(_bytes) {\n        this._bytes = _bytes;\n        this._bytes = new Uint8Array(_bytes);\n    }\n    /**\n     * Gets a copy of the bytes representing the leaf value.\n     * @returns The bytes as a Uint8Array.\n     */\n    get bytes() {\n        return new Uint8Array(this._bytes);\n    }\n    /**\n     * Creates a LeafValue from an authenticator and transaction hash.\n     * @param authenticator The authenticator.\n     * @param transactionHash The transaction hash.\n     * @returns A Promise resolving to a LeafValue instance.\n     */\n    static async create(authenticator, transactionHash) {\n        // TODO: Create cbor object to calculate hash so it would be consistent with everything else?\n        const hash = await new DataHasher(HashAlgorithm.SHA256)\n            .update(authenticator.toCBOR())\n            .update(transactionHash.imprint)\n            .digest();\n        return new LeafValue(hash.imprint);\n    }\n    /**\n     * Checks if the given data is equal to this leaf value.\n     * @param data The data to compare (ArrayBufferView).\n     * @returns True if equal, false otherwise.\n     */\n    equals(data) {\n        if (ArrayBuffer.isView(data)) {\n            return (HexConverter.encode(this.bytes) ===\n                HexConverter.encode(new Uint8Array(data.buffer, data.byteOffset, data.byteLength)));\n        }\n        return false;\n    }\n    /**\n     * Returns a string representation of the LeafValue.\n     * @returns The string representation.\n     */\n    toString() {\n        return `LeafValue[${HexConverter.encode(this.bytes)}]`;\n    }\n}\n","import { DataHash } from '../hash/DataHash.js';\nimport { DataHasher } from '../hash/DataHasher.js';\nimport { HashAlgorithm } from '../hash/HashAlgorithm.js';\nimport { HexConverter } from '../util/HexConverter.js';\n/**\n * Represents a unique request identifier derived from a public key and state hash.\n */\nexport class RequestId {\n    hash;\n    /**\n     * Constructs a RequestId instance.\n     * @param hash The DataHash representing the request ID.\n     */\n    constructor(hash) {\n        this.hash = hash;\n    }\n    /**\n     * Creates a RequestId from a public key and state hash.\n     * @param id The public key as a Uint8Array.\n     * @param stateHash The state hash.\n     * @returns A Promise resolving to a RequestId instance.\n     */\n    static create(id, stateHash) {\n        return RequestId.createFromImprint(id, stateHash.imprint);\n    }\n    /**\n     * Creates a RequestId from a public key and hash imprint.\n     * @param id The public key as a Uint8Array.\n     * @param hashImprint The hash imprint as a Uint8Array.\n     * @returns A Promise resolving to a RequestId instance.\n     */\n    static async createFromImprint(id, hashImprint) {\n        const hash = await new DataHasher(HashAlgorithm.SHA256).update(id).update(hashImprint).digest();\n        return new RequestId(hash);\n    }\n    /**\n     * Decodes a RequestId from CBOR bytes.\n     * @param data The CBOR-encoded bytes.\n     * @returns A RequestId instance.\n     */\n    static fromCBOR(data) {\n        return new RequestId(DataHash.fromCBOR(data));\n    }\n    /**\n     * Creates a RequestId from a JSON string.\n     * @param data The JSON string.\n     * @returns A RequestId instance.\n     */\n    static fromJSON(data) {\n        return new RequestId(DataHash.fromJSON(data));\n    }\n    /**\n     * Converts the RequestId to a bigint.\n     * @returns The bigint representation of the request ID.\n     */\n    toBigInt() {\n        return BigInt(`0x01${HexConverter.encode(this.hash.imprint)}`);\n    }\n    /**\n     * Converts the RequestId to a JSON string.\n     * @returns The JSON string representation.\n     */\n    toJSON() {\n        return this.hash.toJSON();\n    }\n    /**\n     * Encodes the RequestId to CBOR format.\n     * @returns The CBOR-encoded bytes.\n     */\n    toCBOR() {\n        return this.hash.toCBOR();\n    }\n    /**\n     * Checks if this RequestId is equal to another.\n     * @param requestId The RequestId to compare.\n     * @returns True if equal, false otherwise.\n     */\n    equals(requestId) {\n        return this.hash.equals(requestId.hash);\n    }\n    /**\n     * Returns a string representation of the RequestId.\n     * @returns The string representation.\n     */\n    toString() {\n        return `RequestId[${this.hash.toString()}]`;\n    }\n}\n","import { Authenticator } from './Authenticator.js';\nimport { RequestId } from './RequestId.js';\nimport { DataHash } from '../hash/DataHash.js';\n/**\n * Request object sent by the client to the aggregator.\n */\nexport class SubmitCommitmentRequest {\n    requestId;\n    transactionHash;\n    authenticator;\n    receipt;\n    /**\n     * Constructs a SubmitCommitmentRequest instance.\n     * @param requestId The request ID.\n     * @param transactionHash The transaction hash.\n     * @param authenticator The authenticator.\n     * @param receipt Optional flag to request a receipt.\n     */\n    constructor(requestId, transactionHash, authenticator, receipt) {\n        this.requestId = requestId;\n        this.transactionHash = transactionHash;\n        this.authenticator = authenticator;\n        this.receipt = receipt;\n    }\n    /**\n     * Parse a JSON object into a SubmitCommitmentRequest object.\n     * @param data Raw request\n     * @returns SubmitCommitmentRequest object\n     * @throws Error if parsing fails.\n     */\n    static fromJSON(data) {\n        if (!SubmitCommitmentRequest.isJSON(data)) {\n            throw new Error('Parsing submit state transition request failed.');\n        }\n        return new SubmitCommitmentRequest(RequestId.fromJSON(data.requestId), DataHash.fromJSON(data.transactionHash), Authenticator.fromJSON(data.authenticator), data.receipt);\n    }\n    /**\n     * Check if the given data is a valid JSON request object.\n     * @param data Raw request\n     * @returns True if the data is a valid JSON request object\n     */\n    static isJSON(data) {\n        return (typeof data === 'object' &&\n            data !== null &&\n            'authenticator' in data &&\n            typeof data.authenticator === 'object' &&\n            data.authenticator !== null &&\n            'requestId' in data &&\n            typeof data.requestId === 'string' &&\n            'transactionHash' in data &&\n            typeof data.transactionHash === 'string');\n    }\n    /**\n     * Convert the request to a JSON object.\n     * @returns JSON object\n     */\n    toJSON() {\n        return {\n            authenticator: this.authenticator.toJSON(),\n            receipt: this.receipt,\n            requestId: this.requestId.toJSON(),\n            transactionHash: this.transactionHash.toJSON(),\n        };\n    }\n}\n","import { RequestId } from './RequestId.js';\nimport { CborEncoder } from '../cbor/CborEncoder.js';\nimport { DataHash } from '../hash/DataHash.js';\nimport { DataHasher } from '../hash/DataHasher.js';\nimport { HashAlgorithm } from '../hash/HashAlgorithm.js';\nimport { Signature } from '../signing/Signature.js';\nimport { SigningService } from '../signing/SigningService.js';\nimport { HexConverter } from '../util/HexConverter.js';\nimport { dedent } from '../util/StringUtils.js';\n/**\n * Possible results from the aggregator when submitting a commitment.\n */\nexport var SubmitCommitmentStatus;\n(function (SubmitCommitmentStatus) {\n    /** The commitment was accepted and stored. */\n    SubmitCommitmentStatus[\"SUCCESS\"] = \"SUCCESS\";\n    /** Signature verification failed. */\n    SubmitCommitmentStatus[\"AUTHENTICATOR_VERIFICATION_FAILED\"] = \"AUTHENTICATOR_VERIFICATION_FAILED\";\n    /** Request identifier did not match the payload. */\n    SubmitCommitmentStatus[\"REQUEST_ID_MISMATCH\"] = \"REQUEST_ID_MISMATCH\";\n    /** A commitment with the same request id already exists. */\n    SubmitCommitmentStatus[\"REQUEST_ID_EXISTS\"] = \"REQUEST_ID_EXISTS\";\n})(SubmitCommitmentStatus || (SubmitCommitmentStatus = {}));\n/**\n * Request object sent by the client to the aggregator.\n */\nclass Request {\n    service;\n    method;\n    requestId;\n    stateHash;\n    transactionHash;\n    hash;\n    constructor(service, method, requestId, stateHash, transactionHash, hash) {\n        this.service = service;\n        this.method = method;\n        this.requestId = requestId;\n        this.stateHash = stateHash;\n        this.transactionHash = transactionHash;\n        this.hash = hash;\n    }\n    static async create(service, method, requestId, stateHash, transactionHash) {\n        const cborBytes = CborEncoder.encodeArray([\n            CborEncoder.encodeTextString(service),\n            CborEncoder.encodeTextString(method),\n            requestId.toCBOR(),\n            stateHash.toCBOR(),\n            transactionHash.toCBOR(),\n        ]);\n        const hash = await new DataHasher(HashAlgorithm.SHA256).update(cborBytes).digest();\n        return new Request(service, method, requestId, stateHash, transactionHash, hash);\n    }\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            CborEncoder.encodeTextString(this.service),\n            CborEncoder.encodeTextString(this.method),\n            this.requestId.toCBOR(),\n            this.stateHash.toCBOR(),\n            this.transactionHash.toCBOR(),\n        ]);\n    }\n    toJSON() {\n        return {\n            method: this.method,\n            requestId: this.requestId.toJSON(),\n            service: this.service,\n            stateHash: this.stateHash.toJSON(),\n            transactionHash: this.transactionHash.toJSON(),\n        };\n    }\n    toString() {\n        return dedent `\n      Request\n        Service: ${this.service}\n        Method: ${this.method}\n        Request ID: ${this.requestId.toString()}\n        State Hash: ${this.stateHash.toString()}\n        Transaction Hash: ${this.transactionHash.toString()}\n      `;\n    }\n}\n/**\n * Response object returned by the aggregator on commitment submission.\n */\nexport class SubmitCommitmentResponse {\n    status;\n    receipt;\n    constructor(status, receipt) {\n        this.status = status;\n        this.receipt = receipt;\n    }\n    /**\n     * Parse a JSON response object.\n     *\n     * @param data Raw response\n     * @returns Parsed response\n     * @throws Error if the data does not match the expected shape\n     */\n    static async fromJSON(data) {\n        if (!SubmitCommitmentResponse.isJSON(data)) {\n            throw new Error('Parsing submit state transition response failed.');\n        }\n        let receipt;\n        if (data.request && data.algorithm && data.publicKey && data.signature) {\n            const request = await Request.create(data.request.service, data.request.method, RequestId.fromJSON(data.request.requestId), DataHash.fromJSON(data.request.stateHash), DataHash.fromJSON(data.request.transactionHash));\n            receipt = {\n                algorithm: data.algorithm,\n                publicKey: data.publicKey,\n                request,\n                signature: Signature.fromJSON(data.signature),\n            };\n        }\n        return new SubmitCommitmentResponse(data.status, receipt);\n    }\n    /**\n     * Check if the given data is a valid JSON response object.\n     *\n     * @param data Raw response\n     * @returns True if the data is a valid JSON response object\n     */\n    static isJSON(data) {\n        return typeof data === 'object' && data !== null && 'status' in data && typeof data.status === 'string';\n    }\n    /**\n     * Convert the response to a JSON object.\n     *\n     * @returns JSON representation of the response\n     */\n    toJSON() {\n        return {\n            algorithm: this.receipt?.algorithm,\n            publicKey: this.receipt?.publicKey,\n            request: this.receipt?.request.toJSON(),\n            signature: this.receipt?.signature.toJSON(),\n            status: this.status,\n        };\n    }\n    async addSignedReceipt(requestId, stateHash, transactionHash, signingService) {\n        const request = await Request.create('aggregator', // TODO use actual service identifier\n        'submit_commitment', requestId, stateHash, transactionHash);\n        const signature = await signingService.sign(request.hash);\n        this.receipt = {\n            algorithm: signingService.algorithm,\n            publicKey: HexConverter.encode(signingService.publicKey),\n            request,\n            signature,\n        };\n    }\n    /**\n     * Verify the receipt of the commitment.\n     *\n     * @returns True if the receipt is valid, false otherwise\n     */\n    verifyReceipt() {\n        if (!this.receipt) {\n            return Promise.resolve(false);\n        }\n        return SigningService.verifyWithPublicKey(this.receipt.request.hash, this.receipt.signature.bytes, HexConverter.decode(this.receipt.publicKey));\n    }\n}\n","export var BitMask;\n(function (BitMask) {\n    BitMask[BitMask[\"MAJOR_TYPE\"] = 224] = \"MAJOR_TYPE\";\n    BitMask[BitMask[\"ADDITIONAL_INFORMATION\"] = 31] = \"ADDITIONAL_INFORMATION\";\n})(BitMask || (BitMask = {}));\n","import { BitMask } from './BitMask.js';\nimport { CborError } from './CborError.js';\nimport { MajorType } from './MajorType.js';\nimport { HexConverter } from '../util/HexConverter.js';\nexport class CborDecoder {\n    static readOptional(data, reader) {\n        const initialByte = CborDecoder.readByte(data, 0);\n        if (initialByte === 0xf6) {\n            return null;\n        }\n        return reader(data);\n    }\n    static readUnsignedInteger(data) {\n        const majorType = CborDecoder.readByte(data, 0) & BitMask.MAJOR_TYPE;\n        if (majorType != MajorType.UNSIGNED_INTEGER) {\n            throw new CborError('Major type mismatch, expected unsigned integer.');\n        }\n        return CborDecoder.readLength(majorType, data, 0).length;\n    }\n    static readNegativeInteger() {\n        throw new CborError('Not implemented.');\n    }\n    static readByteString(data) {\n        const majorType = CborDecoder.readByte(data, 0) & BitMask.MAJOR_TYPE;\n        if (majorType != MajorType.BYTE_STRING) {\n            throw new CborError('Major type mismatch, expected byte string.');\n        }\n        const { length, position } = CborDecoder.readLength(majorType, data, 0);\n        return CborDecoder.read(data, position, Number(length));\n    }\n    static readTextString(data) {\n        const majorType = CborDecoder.readByte(data, 0) & BitMask.MAJOR_TYPE;\n        if (majorType != MajorType.TEXT_STRING) {\n            throw new CborError('Major type mismatch, expected text string.');\n        }\n        const { length, position } = CborDecoder.readLength(majorType, data, 0);\n        return new TextDecoder().decode(CborDecoder.read(data, position, Number(length)));\n    }\n    static readArray(data) {\n        const majorType = CborDecoder.readByte(data, 0) & BitMask.MAJOR_TYPE;\n        if (majorType != MajorType.ARRAY) {\n            throw new CborError('Major type mismatch, expected array.');\n        }\n        const parsedLength = CborDecoder.readLength(majorType, data, 0);\n        let position = parsedLength.position;\n        const result = [];\n        for (let i = 0; i < parsedLength.length; i++) {\n            const rawCbor = CborDecoder.readRawCbor(data, position);\n            position = rawCbor.position;\n            result.push(rawCbor.data);\n        }\n        return result;\n    }\n    static readMap(data) {\n        const majorType = CborDecoder.readByte(data, 0) & BitMask.MAJOR_TYPE;\n        if (majorType != MajorType.MAP) {\n            throw new CborError('Major type mismatch, expected map.');\n        }\n        const parsedLength = CborDecoder.readLength(majorType, data, 0);\n        let position = parsedLength.position;\n        const result = new Map();\n        for (let i = 0; i < parsedLength.length; i++) {\n            const key = CborDecoder.readRawCbor(data, position);\n            position = key.position;\n            const value = CborDecoder.readRawCbor(data, position);\n            position = value.position;\n            result.set(HexConverter.encode(key.data), value.data);\n        }\n        return result;\n    }\n    static readTag(data) {\n        const majorType = CborDecoder.readByte(data, 0) & BitMask.MAJOR_TYPE;\n        if (majorType != MajorType.TAG) {\n            throw new CborError('Major type mismatch, expected tag.');\n        }\n        const { length: tag, position } = CborDecoder.readLength(majorType, data, 0);\n        return { data: CborDecoder.readRawCbor(data, position).data, tag };\n    }\n    static readBoolean(data) {\n        const byte = CborDecoder.readByte(data, 0);\n        if (byte === 0xf5) {\n            return true;\n        }\n        if (byte === 0xf4) {\n            return false;\n        }\n        throw new CborError('Type mismatch, expected boolean.');\n    }\n    static readLength(majorType, data, offset) {\n        const additionalInformation = CborDecoder.readByte(data, offset) & BitMask.ADDITIONAL_INFORMATION;\n        if (additionalInformation < 24) {\n            return {\n                length: BigInt(additionalInformation),\n                position: offset + 1,\n            };\n        }\n        switch (majorType) {\n            case MajorType.ARRAY:\n            case MajorType.BYTE_STRING:\n            case MajorType.TEXT_STRING:\n                if (additionalInformation == 31) {\n                    throw new CborError('Indefinite length array not supported.');\n                }\n        }\n        if (additionalInformation > 27) {\n            throw new CborError('Encoded item is not well-formed.');\n        }\n        const numberOfLengthBytes = Math.pow(2, additionalInformation - 24);\n        let t = BigInt(0);\n        for (let i = 0; i < numberOfLengthBytes; ++i) {\n            t = (t << 8n) | BigInt(CborDecoder.readByte(data, offset + 1 + i));\n        }\n        return {\n            length: t,\n            position: offset + numberOfLengthBytes + 1,\n        };\n    }\n    static readRawCbor(data, offset) {\n        const majorType = CborDecoder.readByte(data, offset) & BitMask.MAJOR_TYPE;\n        const parsedLength = CborDecoder.readLength(majorType, data, offset);\n        const length = parsedLength.length;\n        let position = parsedLength.position;\n        switch (majorType) {\n            case MajorType.BYTE_STRING:\n            case MajorType.TEXT_STRING:\n                position += Number(length);\n                break;\n            case MajorType.ARRAY:\n                for (let i = 0; i < length; i++) {\n                    position = CborDecoder.readRawCbor(data, position).position;\n                }\n                break;\n            case MajorType.MAP:\n                for (let i = 0; i < length; i++) {\n                    position = CborDecoder.readRawCbor(data, position).position;\n                    position = CborDecoder.readRawCbor(data, position).position;\n                }\n                break;\n            case MajorType.TAG:\n                position = CborDecoder.readRawCbor(data, position).position;\n                break;\n        }\n        return {\n            data: CborDecoder.read(data, offset, position - offset),\n            position,\n        };\n    }\n    static readByte(data, offset) {\n        if (data.length < offset) {\n            throw new CborError('Premature end of data.');\n        }\n        return data[offset] & 0xff;\n    }\n    static read(data, offset, length) {\n        if (data.length < offset + length) {\n            throw new CborError('Premature end of data.');\n        }\n        return data.subarray(offset, offset + length);\n    }\n}\n","import { CborError } from './CborError.js';\nimport { MajorType } from './MajorType.js';\nimport { HexConverter } from '../util/HexConverter.js';\nexport class CborEncoder {\n    static encodeOptional(data, encoder) {\n        if (data == null) {\n            return new Uint8Array([0xf6]);\n        }\n        return encoder(data);\n    }\n    static encodeUnsignedInteger(input) {\n        if (input < 0) {\n            throw new CborError('Only unsigned numbers are allowed.');\n        }\n        if (input < 24) {\n            return new Uint8Array([MajorType.UNSIGNED_INTEGER | Number(input)]);\n        }\n        const bytes = CborEncoder.getUnsignedIntegerAsPaddedBytes(input);\n        return new Uint8Array([\n            MajorType.UNSIGNED_INTEGER | CborEncoder.getAdditionalInformationBits(bytes.length),\n            ...bytes,\n        ]);\n    }\n    static encodeByteString(input) {\n        if (input.length < 24) {\n            return new Uint8Array([MajorType.BYTE_STRING | input.length, ...input]);\n        }\n        const lengthBytes = CborEncoder.getUnsignedIntegerAsPaddedBytes(input.length);\n        return new Uint8Array([\n            MajorType.BYTE_STRING | CborEncoder.getAdditionalInformationBits(lengthBytes.length),\n            ...lengthBytes,\n            ...input,\n        ]);\n    }\n    static encodeTextString(input) {\n        const bytes = new TextEncoder().encode(input);\n        if (bytes.length < 24) {\n            return new Uint8Array([MajorType.TEXT_STRING | bytes.length, ...bytes]);\n        }\n        const lengthBytes = CborEncoder.getUnsignedIntegerAsPaddedBytes(bytes.length);\n        return new Uint8Array([\n            MajorType.TEXT_STRING | CborEncoder.getAdditionalInformationBits(lengthBytes.length),\n            ...lengthBytes,\n            ...bytes,\n        ]);\n    }\n    static encodeArray(input) {\n        const data = new Uint8Array(input.reduce((result, value) => result + value.length, 0));\n        let length = 0;\n        for (const value of input) {\n            data.set(value, length);\n            length += value.length;\n        }\n        if (input.length < 24) {\n            return new Uint8Array([MajorType.ARRAY | input.length, ...data]);\n        }\n        const lengthBytes = CborEncoder.getUnsignedIntegerAsPaddedBytes(input.length);\n        return new Uint8Array([\n            MajorType.ARRAY | CborEncoder.getAdditionalInformationBits(lengthBytes.length),\n            ...lengthBytes,\n            ...data,\n        ]);\n    }\n    static encodeMap(input) {\n        const processedArray = Array.from(input.entries()).map(([key, value]) => [HexConverter.decode(key), value]);\n        processedArray.sort(([a], [b]) => {\n            if (a.length !== b.length) {\n                return a.length - b.length;\n            }\n            for (let i = 0; i < a.length; i++) {\n                if (a[i] !== b[i]) {\n                    return a[i] - b[i];\n                }\n            }\n            return 0;\n        });\n        const dataLength = processedArray.reduce((result, [key, value]) => result + key.length + value.length, 0);\n        const data = new Uint8Array(dataLength);\n        let length = 0;\n        for (const [key, value] of processedArray) {\n            data.set(key, length);\n            length += key.length;\n            data.set(value, length);\n            length += value.length;\n        }\n        if (input.size < 24) {\n            return new Uint8Array([MajorType.MAP | input.size, ...data]);\n        }\n        const lengthBytes = CborEncoder.getUnsignedIntegerAsPaddedBytes(input.size);\n        return new Uint8Array([\n            MajorType.MAP | CborEncoder.getAdditionalInformationBits(lengthBytes.length),\n            ...lengthBytes,\n            ...data,\n        ]);\n    }\n    static encodeTag(tag, input) {\n        if (tag < 24) {\n            return new Uint8Array([MajorType.TAG | Number(tag), ...input]);\n        }\n        const bytes = CborEncoder.getUnsignedIntegerAsPaddedBytes(tag);\n        return new Uint8Array([MajorType.TAG | CborEncoder.getAdditionalInformationBits(bytes.length), ...bytes, ...input]);\n    }\n    static encodeBoolean(data) {\n        if (data) {\n            return new Uint8Array([0xf5]);\n        }\n        return new Uint8Array([0xf4]);\n    }\n    static encodeNull() {\n        return new Uint8Array([0xf6]);\n    }\n    static getAdditionalInformationBits(length) {\n        return 24 + Math.ceil(Math.log2(length));\n    }\n    static getUnsignedIntegerAsPaddedBytes(input) {\n        if (input < 0) {\n            throw new CborError('Only unsigned numbers are allowed.');\n        }\n        let t;\n        const bytes = [];\n        for (t = BigInt(input); t > 0; t = t >> 8n) {\n            bytes.push(Number(t & 255n));\n        }\n        if (bytes.length > 8) {\n            throw new CborError('Number is not unsigned long.');\n        }\n        if (bytes.length === 0) {\n            bytes.push(0);\n        }\n        bytes.reverse();\n        const data = new Uint8Array(Math.pow(2, Math.ceil(Math.log2(bytes.length))));\n        data.set(bytes, data.length - bytes.length);\n        return data;\n    }\n}\n","export class CborError extends Error {\n}\n","export var MajorType;\n(function (MajorType) {\n    MajorType[MajorType[\"UNSIGNED_INTEGER\"] = 0] = \"UNSIGNED_INTEGER\";\n    MajorType[MajorType[\"NEGATIVE_INTEGER\"] = 32] = \"NEGATIVE_INTEGER\";\n    MajorType[MajorType[\"BYTE_STRING\"] = 64] = \"BYTE_STRING\";\n    MajorType[MajorType[\"TEXT_STRING\"] = 96] = \"TEXT_STRING\";\n    MajorType[MajorType[\"ARRAY\"] = 128] = \"ARRAY\";\n    MajorType[MajorType[\"MAP\"] = 160] = \"MAP\";\n    MajorType[MajorType[\"TAG\"] = 192] = \"TAG\";\n    MajorType[MajorType[\"FLOAT_SIMPLE_BREAK\"] = 224] = \"FLOAT_SIMPLE_BREAK\";\n})(MajorType || (MajorType = {}));\n","import { HashAlgorithm } from './HashAlgorithm.js';\nimport { HashError } from './HashError.js';\nimport { CborDecoder } from '../cbor/CborDecoder.js';\nimport { CborEncoder } from '../cbor/CborEncoder.js';\nimport { HexConverter } from '../util/HexConverter.js';\nexport class DataHash {\n    algorithm;\n    _data;\n    _imprint;\n    constructor(algorithm, _data) {\n        this.algorithm = algorithm;\n        this._data = _data;\n        this._data = new Uint8Array(_data);\n        this._imprint = new Uint8Array(_data.length + 2);\n        this._imprint.set([(algorithm & 0xff00) >> 8, algorithm & 0xff]);\n        this._imprint.set(new Uint8Array(_data), 2);\n    }\n    get data() {\n        return new Uint8Array(this._data);\n    }\n    /**\n     * Returns the imprint of the hash, which includes the algorithm identifier and the data.\n     * The first two bytes represent the algorithm, followed by the data bytes.\n     * NB! Do not use this for signing, use `data` instead.\n     */\n    get imprint() {\n        return new Uint8Array(this._imprint);\n    }\n    static fromImprint(imprint) {\n        if (imprint.length < 3) {\n            throw new HashError('Imprint must have 2 bytes of algorithm and at least 1 byte of data.');\n        }\n        const algorithm = (imprint[0] << 8) | imprint[1];\n        return new DataHash(algorithm, imprint.subarray(2));\n    }\n    static fromJSON(data) {\n        return DataHash.fromImprint(HexConverter.decode(data));\n    }\n    static fromCBOR(bytes) {\n        return DataHash.fromImprint(CborDecoder.readByteString(bytes));\n    }\n    toJSON() {\n        return HexConverter.encode(this._imprint);\n    }\n    toCBOR() {\n        return CborEncoder.encodeByteString(this._imprint);\n    }\n    equals(hash) {\n        return HexConverter.encode(this._imprint) === HexConverter.encode(hash._imprint);\n    }\n    toString() {\n        return `[${HashAlgorithm[this.algorithm]}]${HexConverter.encode(this._data)}`;\n    }\n}\n","import { ripemd160 } from '@noble/hashes/ripemd160';\nimport { sha224, sha256 } from '@noble/hashes/sha256';\nimport { sha384, sha512 } from '@noble/hashes/sha512';\nimport { DataHash } from './DataHash.js';\nimport { HashAlgorithm } from './HashAlgorithm.js';\nimport { UnsupportedHashAlgorithmError } from './UnsupportedHashAlgorithmError.js';\nexport const Algorithm = {\n    [HashAlgorithm.RIPEMD160]: ripemd160,\n    [HashAlgorithm.SHA224]: sha224,\n    [HashAlgorithm.SHA256]: sha256,\n    [HashAlgorithm.SHA384]: sha384,\n    [HashAlgorithm.SHA512]: sha512,\n};\n/**\n * Provides synchronous hashing functions\n */\nexport class DataHasher {\n    algorithm;\n    _messageDigest;\n    /**\n     * Create DataHasher instance the hash algorithm\n     * @param {HashAlgorithm} algorithm\n     */\n    constructor(algorithm) {\n        this.algorithm = algorithm;\n        if (!Algorithm[algorithm]) {\n            throw new UnsupportedHashAlgorithmError(algorithm);\n        }\n        this._messageDigest = Algorithm[algorithm].create();\n    }\n    /**\n     * Add data for hashing\n     * @param {Uint8Array} data byte array\n     * @returns {DataHasher}\n     */\n    update(data) {\n        this._messageDigest.update(data);\n        return this;\n    }\n    /**\n     * Hashes the data and returns the DataHash\n     * @returns DataHash\n     */\n    digest() {\n        return Promise.resolve(new DataHash(this.algorithm, this._messageDigest.digest()));\n    }\n}\n","export var HashAlgorithm;\n(function (HashAlgorithm) {\n    HashAlgorithm[HashAlgorithm[\"SHA256\"] = 0] = \"SHA256\";\n    HashAlgorithm[HashAlgorithm[\"SHA224\"] = 1] = \"SHA224\";\n    HashAlgorithm[HashAlgorithm[\"SHA384\"] = 2] = \"SHA384\";\n    HashAlgorithm[HashAlgorithm[\"SHA512\"] = 3] = \"SHA512\";\n    HashAlgorithm[HashAlgorithm[\"RIPEMD160\"] = 4] = \"RIPEMD160\";\n})(HashAlgorithm || (HashAlgorithm = {}));\n","/**\n * Hashing error\n */\nexport class HashError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = 'HashError';\n    }\n}\n","export class UnsupportedHashAlgorithmError extends Error {\n    constructor(algorithm) {\n        super(`Unsupported hash algorithm: ${algorithm}`);\n        this.name = 'UnsupportedHashAlgorithm';\n    }\n}\n","/**\n * JSON-RPC error object.\n */\nexport class JsonRpcDataError {\n    code;\n    message;\n    name = 'JsonRpcError';\n    /**\n     * JSON-RPC error object constructor.\n     * @param {{code: number; message: string}} data Error data.\n     */\n    constructor({ code, message }) {\n        this.code = code;\n        this.message = message;\n    }\n    /**\n     * Error info to string.\n     */\n    toString() {\n        return `{ code: ${this.code}, message: ${this.message} }`;\n    }\n}\n","import { v4 as uuid } from 'uuid';\nimport { JsonRpcDataError } from './JsonRpcDataError.js';\nimport { JsonRpcNetworkError } from './JsonRpcNetworkError.js';\n/**\n * JSON-RPC HTTP service.\n */\nexport class JsonRpcHttpTransport {\n    url;\n    /**\n     * JSON-RPC HTTP service constructor.\n     */\n    constructor(url) {\n        this.url = url;\n    }\n    /**\n     * Send a JSON-RPC request.\n     */\n    async request(method, params) {\n        const response = await fetch(this.url, {\n            body: JSON.stringify({\n                id: uuid(),\n                jsonrpc: '2.0',\n                method,\n                params,\n            }),\n            headers: { 'Content-Type': 'application/json' },\n            method: 'POST',\n        });\n        if (!response.ok) {\n            throw new JsonRpcNetworkError(response.status, await response.text());\n        }\n        const data = (await response.json());\n        if (data.error) {\n            throw new JsonRpcDataError(data.error);\n        }\n        return data.result;\n    }\n}\n","/**\n * JSON-RPC error object.\n */\nexport class JsonRpcNetworkError {\n    status;\n    message;\n    name = 'JsonRpcNetworkError';\n    constructor(status, message) {\n        this.status = status;\n        this.message = message;\n    }\n}\n","import { CborDecoder } from '../cbor/CborDecoder.js';\nimport { CborEncoder } from '../cbor/CborEncoder.js';\nimport { HexConverter } from '../util/HexConverter.js';\nexport class Signature {\n    _bytes;\n    recovery;\n    algorithm = 'secp256k1';\n    constructor(_bytes, recovery) {\n        this._bytes = _bytes;\n        this.recovery = recovery;\n        this._bytes = new Uint8Array(_bytes);\n    }\n    get bytes() {\n        return new Uint8Array(this._bytes);\n    }\n    static fromCBOR(bytes) {\n        return Signature.decode(CborDecoder.readByteString(bytes));\n    }\n    static decode(bytes) {\n        if (bytes.length !== 65) {\n            throw new Error('Signature must contain signature and recovery byte.');\n        }\n        return new Signature(bytes.slice(0, -1), bytes[bytes.length - 1]);\n    }\n    static fromJSON(data) {\n        return Signature.decode(HexConverter.decode(data));\n    }\n    toJSON() {\n        return HexConverter.encode(this.encode());\n    }\n    toCBOR() {\n        return CborEncoder.encodeByteString(this.encode());\n    }\n    encode() {\n        return new Uint8Array([...this._bytes, this.recovery]);\n    }\n    toString() {\n        return `${HexConverter.encode(this.encode())}`;\n    }\n}\n","import { secp256k1 } from '@noble/curves/secp256k1';\nimport { Signature } from './Signature.js';\nimport { DataHasher } from '../hash/DataHasher.js';\nimport { HashAlgorithm } from '../hash/HashAlgorithm.js';\n/**\n * Default signing service.\n * @implements {ISigningService}\n */\nexport class SigningService {\n    privateKey;\n    _publicKey;\n    /**\n     * Signing service constructor.\n     * @param {Uint8Array} privateKey private key bytes.\n     */\n    constructor(privateKey) {\n        this.privateKey = privateKey;\n        this.privateKey = new Uint8Array(privateKey);\n        this._publicKey = secp256k1.getPublicKey(this.privateKey, true);\n    }\n    /**\n     * @see {ISigningService.publicKey}\n     */\n    get publicKey() {\n        return new Uint8Array(this._publicKey);\n    }\n    get algorithm() {\n        return 'secp256k1';\n    }\n    static generatePrivateKey() {\n        return secp256k1.utils.randomPrivateKey();\n    }\n    static async createFromSecret(secret, nonce) {\n        const hasher = new DataHasher(HashAlgorithm.SHA256);\n        hasher.update(secret);\n        if (nonce) {\n            hasher.update(nonce);\n        }\n        const hash = await hasher.digest();\n        return new SigningService(hash.data);\n    }\n    static verifySignatureWithRecoveredPublicKey(hash, signature) {\n        const publicKey = secp256k1.Signature.fromCompact(signature.bytes)\n            .addRecoveryBit(signature.recovery)\n            .recoverPublicKey(hash.data)\n            .toRawBytes();\n        return SigningService.verifyWithPublicKey(hash, signature.bytes, publicKey);\n    }\n    /**\n     * Verify secp256k1 signature hash.\n     * @param {Uint8Array} hash Hash.\n     * @param {Uint8Array} signature Signature.\n     * @param {Uint8Array} publicKey Public key.\n     */\n    static verifyWithPublicKey(hash, signature, publicKey) {\n        return Promise.resolve(secp256k1.verify(signature, hash.data, publicKey, { format: 'compact' }));\n    }\n    /**\n     * Verify secp256k1 signature hash.\n     * @param {Uint8Array} hash Hash.\n     * @param {Uint8Array} signature Signature.\n     */\n    verify(hash, signature) {\n        return SigningService.verifyWithPublicKey(hash, signature.bytes, this._publicKey);\n    }\n    /**\n     * @see {ISigningService.sign} 32-byte hash.\n     */\n    sign(hash) {\n        const signature = secp256k1.sign(hash.data, this.privateKey);\n        return Promise.resolve(new Signature(signature.toCompactRawBytes(), signature.recovery));\n    }\n}\n","import { HexConverter } from '../util/HexConverter.js';\nimport { dedent } from '../util/StringUtils.js';\nexport class LeafBranch {\n    path;\n    _value;\n    sum;\n    hash;\n    constructor(path, _value, sum, hash) {\n        this.path = path;\n        this._value = _value;\n        this.sum = sum;\n        this.hash = hash;\n    }\n    get value() {\n        return new Uint8Array(this._value);\n    }\n    finalize() {\n        return Promise.resolve(this);\n    }\n    toString() {\n        return dedent `\n      Leaf[${this.path.toString(2)}]\n        Hash: ${this.hash.toString()}\n        Value: ${HexConverter.encode(this._value)}\n        Sum: ${this.sum}`;\n    }\n}\n","import { MerkleSumTreePathStep } from './MerkleSumTreePathStep.js';\nimport { CborDecoder } from '../cbor/CborDecoder.js';\nimport { CborEncoder } from '../cbor/CborEncoder.js';\nimport { DataHash } from '../hash/DataHash.js';\nimport { DataHasher } from '../hash/DataHasher.js';\nimport { HashAlgorithm } from '../hash/HashAlgorithm.js';\nimport { PathVerificationResult } from '../smt/PathVerificationResult.js';\nimport { BigintConverter } from '../util/BigintConverter.js';\nimport { dedent } from '../util/StringUtils.js';\nexport class MerkleSumTreePath {\n    root;\n    sum;\n    steps;\n    constructor(root, sum, steps) {\n        this.root = root;\n        this.sum = sum;\n        this.steps = steps;\n    }\n    static fromJSON(data) {\n        if (!MerkleSumTreePath.isJSON(data)) {\n            throw new Error('Parsing merkle tree path json failed.');\n        }\n        return new MerkleSumTreePath(DataHash.fromJSON(data.root), BigInt(data.sum), data.steps.map((step) => MerkleSumTreePathStep.fromJSON(step)));\n    }\n    static isJSON(data) {\n        return (typeof data === 'object' &&\n            data !== null &&\n            'root' in data &&\n            typeof data.root === 'string' &&\n            'steps' in data &&\n            Array.isArray(data.steps));\n    }\n    static fromCBOR(bytes) {\n        const data = CborDecoder.readArray(bytes);\n        return new MerkleSumTreePath(DataHash.fromCBOR(data[0]), BigintConverter.decode(CborDecoder.readByteString(data[1])), CborDecoder.readArray(data[2]).map((step) => MerkleSumTreePathStep.fromCBOR(step)));\n    }\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            this.root.toCBOR(),\n            CborEncoder.encodeArray(this.steps.map((step) => step.toCBOR())),\n        ]);\n    }\n    toJSON() {\n        return {\n            root: this.root.toJSON(),\n            steps: this.steps.map((step) => step.toJSON()),\n            sum: this.sum.toString(),\n        };\n    }\n    async verify(requestId) {\n        let currentPath = 1n;\n        let currentHash = null;\n        let currentSum = this.steps.at(0)?.branch?.sum ?? 0n;\n        for (let i = 0; i < this.steps.length; i++) {\n            const step = this.steps[i];\n            let hash = null;\n            if (step.branch !== null) {\n                const bytes = i === 0 ? step.branch.value : currentHash ? currentHash.imprint : null;\n                hash = await new DataHasher(HashAlgorithm.SHA256)\n                    .update(CborEncoder.encodeArray([\n                    CborEncoder.encodeByteString(BigintConverter.encode(step.path)),\n                    bytes ? CborEncoder.encodeByteString(bytes) : CborEncoder.encodeNull(),\n                    CborEncoder.encodeByteString(BigintConverter.encode(currentSum)),\n                ]))\n                    .digest();\n                const length = BigInt(step.path.toString(2).length - 1);\n                currentPath = (currentPath << length) | (step.path & ((1n << length) - 1n));\n            }\n            const isRight = step.path & 1n;\n            const right = isRight\n                ? hash\n                    ? [hash, currentSum]\n                    : null\n                : step.sibling\n                    ? [step.sibling.hash, step.sibling.sum]\n                    : null;\n            const left = isRight\n                ? step.sibling\n                    ? [step.sibling.hash, step.sibling.sum]\n                    : null\n                : hash\n                    ? [hash, currentSum]\n                    : null;\n            currentHash = await new DataHasher(HashAlgorithm.SHA256)\n                .update(CborEncoder.encodeArray([\n                left\n                    ? CborEncoder.encodeArray([\n                        CborEncoder.encodeByteString(left[0].imprint),\n                        CborEncoder.encodeByteString(BigintConverter.encode(left[1])),\n                    ])\n                    : CborEncoder.encodeNull(),\n                right\n                    ? CborEncoder.encodeArray([\n                        right[0] ? CborEncoder.encodeByteString(right[0].imprint) : CborEncoder.encodeNull(),\n                        CborEncoder.encodeByteString(BigintConverter.encode(right[1])),\n                    ])\n                    : CborEncoder.encodeNull(),\n            ]))\n                .digest();\n            currentSum += step.sibling?.sum ?? 0n;\n        }\n        return new PathVerificationResult(!!currentHash && this.root.equals(currentHash) && currentSum === this.sum, requestId === currentPath);\n    }\n    toString() {\n        return dedent `\n      Merkle Tree Path\n        Root: ${this.root.toString()} \n        Steps: [\n          ${this.steps.map((step) => step?.toString() ?? 'null').join('\\n')}\n        ]`;\n    }\n}\n","import { LeafBranch } from './LeafBranch.js';\nimport { CborDecoder } from '../cbor/CborDecoder.js';\nimport { CborEncoder } from '../cbor/CborEncoder.js';\nimport { DataHash } from '../hash/DataHash.js';\nimport { BigintConverter } from '../util/BigintConverter.js';\nimport { HexConverter } from '../util/HexConverter.js';\nimport { dedent } from '../util/StringUtils.js';\nclass MerkleSumTreePathStepSibling {\n    sum;\n    hash;\n    constructor(sum, hash) {\n        this.sum = sum;\n        this.hash = hash;\n    }\n    static create(sibling) {\n        return new MerkleSumTreePathStepSibling(sibling.sum, sibling.hash);\n    }\n    static isJSON(data) {\n        return Array.isArray(data);\n    }\n    static fromJSON(data) {\n        if (!Array.isArray(data) || data.length !== 2) {\n            throw new Error('Parsing merkle tree path step branch failed.');\n        }\n        return new MerkleSumTreePathStepSibling(BigInt(data[0]), DataHash.fromJSON(data[1]));\n    }\n    static fromCBOR(bytes) {\n        const data = CborDecoder.readArray(bytes);\n        return new MerkleSumTreePathStepSibling(BigintConverter.decode(CborDecoder.readByteString(data[0])), DataHash.fromCBOR(data[1]));\n    }\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            CborEncoder.encodeByteString(BigintConverter.encode(this.sum)),\n            this.hash.toCBOR(),\n        ]);\n    }\n    toJSON() {\n        return [this.sum.toString(), this.hash.toJSON()];\n    }\n    toString() {\n        return `MerkleSumTreePathStepSibling[${this.sum},${this.hash.toString()}]`;\n    }\n}\nclass MerkleSumTreePathStepBranch {\n    sum;\n    _value;\n    constructor(sum, _value) {\n        this.sum = sum;\n        this._value = _value;\n        this._value = _value ? new Uint8Array(_value) : null;\n    }\n    get value() {\n        return this._value ? new Uint8Array(this._value) : null;\n    }\n    static isJSON(data) {\n        return Array.isArray(data);\n    }\n    static fromJSON(data) {\n        if (!Array.isArray(data)) {\n            throw new Error('Parsing merkle tree path step branch failed.');\n        }\n        const sum = data.at(0);\n        const value = data.at(1);\n        return new MerkleSumTreePathStepBranch(BigInt(sum ?? 0n), value ? HexConverter.decode(value) : null);\n    }\n    static fromCBOR(bytes) {\n        const data = CborDecoder.readArray(bytes);\n        return new MerkleSumTreePathStepBranch(BigintConverter.decode(CborDecoder.readByteString(data[0])), CborDecoder.readOptional(data[1], CborDecoder.readByteString));\n    }\n    toCBOR() {\n        return CborEncoder.encodeArray([CborEncoder.encodeOptional(this._value, CborEncoder.encodeByteString)]);\n    }\n    toJSON() {\n        return [this.sum.toString(), this._value ? HexConverter.encode(this._value) : null];\n    }\n    toString() {\n        return `MerkleSumTreePathStepBranch[${this._value ? HexConverter.encode(this._value) : 'null'}]`;\n    }\n}\nexport class MerkleSumTreePathStep {\n    path;\n    sibling;\n    branch;\n    constructor(path, sibling, branch) {\n        this.path = path;\n        this.sibling = sibling;\n        this.branch = branch;\n    }\n    static createWithoutBranch(path, sibling) {\n        return new MerkleSumTreePathStep(path, sibling ? MerkleSumTreePathStepSibling.create(sibling) : null, null);\n    }\n    static create(path, value, sibling) {\n        if (value == null) {\n            return new MerkleSumTreePathStep(path, sibling ? MerkleSumTreePathStepSibling.create(sibling) : null, new MerkleSumTreePathStepBranch(0n, null));\n        }\n        if (value instanceof LeafBranch) {\n            return new MerkleSumTreePathStep(path, sibling ? MerkleSumTreePathStepSibling.create(sibling) : null, new MerkleSumTreePathStepBranch(value.sum, value.value));\n        }\n        return new MerkleSumTreePathStep(path, sibling ? MerkleSumTreePathStepSibling.create(sibling) : null, new MerkleSumTreePathStepBranch(value.sum, value.childrenHash.data));\n    }\n    static isJSON(data) {\n        return (typeof data === 'object' &&\n            data !== null &&\n            'path' in data &&\n            typeof data.path === 'string' &&\n            'sibling' in data &&\n            'branch' in data);\n    }\n    static fromJSON(data) {\n        if (!MerkleSumTreePathStep.isJSON(data)) {\n            throw new Error('Parsing merkle tree path step failed.');\n        }\n        return new MerkleSumTreePathStep(BigInt(data.path), data.sibling != null ? MerkleSumTreePathStepSibling.fromJSON(data.sibling) : null, data.branch != null ? MerkleSumTreePathStepBranch.fromJSON(data.branch) : null);\n    }\n    static fromCBOR(bytes) {\n        const data = CborDecoder.readArray(bytes);\n        return new MerkleSumTreePathStep(BigintConverter.decode(CborDecoder.readByteString(data[0])), CborDecoder.readOptional(data[1], MerkleSumTreePathStepSibling.fromCBOR), CborDecoder.readOptional(data[2], MerkleSumTreePathStepBranch.fromCBOR));\n    }\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            CborEncoder.encodeByteString(BigintConverter.encode(this.path)),\n            this.sibling?.toCBOR() ?? CborEncoder.encodeNull(),\n            this.branch?.toCBOR() ?? CborEncoder.encodeNull(),\n        ]);\n    }\n    toJSON() {\n        return {\n            branch: this.branch?.toJSON() ?? null,\n            path: this.path.toString(),\n            sibling: this.sibling?.toJSON() ?? null,\n        };\n    }\n    toString() {\n        return dedent `\n      Merkle Tree Path Step\n        Path: ${this.path.toString(2)}\n        Branch: ${this.branch?.toString() ?? 'null'}\n        Sibling: ${this.sibling?.toString() ?? 'null'}`;\n    }\n}\n","import { HexConverter } from '../util/HexConverter.js';\nexport class LeafBranch {\n    path;\n    _value;\n    hash;\n    constructor(path, _value, hash) {\n        this.path = path;\n        this._value = _value;\n        this.hash = hash;\n    }\n    get value() {\n        return new Uint8Array(this._value);\n    }\n    finalize() {\n        return Promise.resolve(this);\n    }\n    toString() {\n        return `\n      Leaf[${this.path}]\n        Value: ${HexConverter.encode(this._value)}\n    `;\n    }\n}\n","import { MerkleTreePathStep } from './MerkleTreePathStep.js';\nimport { PathVerificationResult } from './PathVerificationResult.js';\nimport { CborDecoder } from '../cbor/CborDecoder.js';\nimport { CborEncoder } from '../cbor/CborEncoder.js';\nimport { DataHash } from '../hash/DataHash.js';\nimport { DataHasher } from '../hash/DataHasher.js';\nimport { HashAlgorithm } from '../hash/HashAlgorithm.js';\nimport { BigintConverter } from '../util/BigintConverter.js';\nimport { dedent } from '../util/StringUtils.js';\nexport class MerkleTreePath {\n    root;\n    steps;\n    constructor(root, steps) {\n        this.root = root;\n        this.steps = steps;\n    }\n    static fromJSON(data) {\n        if (!MerkleTreePath.isJSON(data)) {\n            throw new Error('Parsing merkle tree path json failed.');\n        }\n        return new MerkleTreePath(DataHash.fromJSON(data.root), data.steps.map((step) => MerkleTreePathStep.fromJSON(step)));\n    }\n    static isJSON(data) {\n        return (typeof data === 'object' &&\n            data !== null &&\n            'root' in data &&\n            typeof data.root === 'string' &&\n            'steps' in data &&\n            Array.isArray(data.steps));\n    }\n    static fromCBOR(bytes) {\n        const data = CborDecoder.readArray(bytes);\n        const steps = CborDecoder.readArray(data[1]);\n        return new MerkleTreePath(DataHash.fromCBOR(data[0]), steps.map((step) => MerkleTreePathStep.fromCBOR(step)));\n    }\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            this.root.toCBOR(),\n            CborEncoder.encodeArray(this.steps.map((step) => step.toCBOR())),\n        ]);\n    }\n    toJSON() {\n        return {\n            root: this.root.toJSON(),\n            steps: this.steps.map((step) => step.toJSON()),\n        };\n    }\n    async verify(requestId) {\n        let currentPath = 1n;\n        let currentHash = null;\n        for (let i = 0; i < this.steps.length; i++) {\n            const step = this.steps[i];\n            let hash;\n            if (step.branch === null) {\n                hash = new Uint8Array(1);\n            }\n            else {\n                const bytes = i === 0 ? step.branch.value : currentHash?.data;\n                const digest = await new DataHasher(HashAlgorithm.SHA256)\n                    .update(BigintConverter.encode(step.path))\n                    .update(bytes ?? new Uint8Array(1))\n                    .digest();\n                hash = digest.data;\n                const length = BigInt(step.path.toString(2).length - 1);\n                currentPath = (currentPath << length) | (step.path & ((1n << length) - 1n));\n            }\n            const siblingHash = step.sibling?.data ?? new Uint8Array(1);\n            const isRight = step.path & 1n;\n            currentHash = await new DataHasher(HashAlgorithm.SHA256)\n                .update(isRight ? siblingHash : hash)\n                .update(isRight ? hash : siblingHash)\n                .digest();\n        }\n        return new PathVerificationResult(!!currentHash && this.root.equals(currentHash), requestId === currentPath);\n    }\n    toString() {\n        return dedent `\n      Merkle Tree Path\n        Root: ${this.root.toString()} \n        Steps: [\n          ${this.steps.map((step) => step?.toString() ?? 'null').join('\\n')}\n        ]`;\n    }\n}\n","import { LeafBranch } from './LeafBranch.js';\nimport { CborDecoder } from '../cbor/CborDecoder.js';\nimport { CborEncoder } from '../cbor/CborEncoder.js';\nimport { DataHash } from '../hash/DataHash.js';\nimport { BigintConverter } from '../util/BigintConverter.js';\nimport { HexConverter } from '../util/HexConverter.js';\nimport { dedent } from '../util/StringUtils.js';\nclass MerkleTreePathStepBranch {\n    _value;\n    constructor(_value) {\n        this._value = _value;\n        this._value = _value ? new Uint8Array(_value) : null;\n    }\n    get value() {\n        return this._value ? new Uint8Array(this._value) : null;\n    }\n    static isJSON(data) {\n        return Array.isArray(data);\n    }\n    static fromJSON(data) {\n        if (!Array.isArray(data)) {\n            throw new Error('Parsing merkle tree path step branch failed.');\n        }\n        const value = data.at(0);\n        return new MerkleTreePathStepBranch(value ? HexConverter.decode(value) : null);\n    }\n    static fromCBOR(bytes) {\n        const data = CborDecoder.readArray(bytes);\n        return new MerkleTreePathStepBranch(CborDecoder.readOptional(data[0], CborDecoder.readByteString));\n    }\n    toCBOR() {\n        return CborEncoder.encodeArray([CborEncoder.encodeOptional(this._value, CborEncoder.encodeByteString)]);\n    }\n    toJSON() {\n        return this._value ? [HexConverter.encode(this._value)] : [];\n    }\n    toString() {\n        return `MerkleTreePathStepBranch[${this._value ? HexConverter.encode(this._value) : 'null'}]`;\n    }\n}\nexport class MerkleTreePathStep {\n    path;\n    sibling;\n    branch;\n    constructor(path, sibling, branch) {\n        this.path = path;\n        this.sibling = sibling;\n        this.branch = branch;\n    }\n    static createWithoutBranch(path, sibling) {\n        return new MerkleTreePathStep(path, sibling?.hash ?? null, null);\n    }\n    static create(path, value, sibling) {\n        if (value == null) {\n            return new MerkleTreePathStep(path, sibling?.hash ?? null, new MerkleTreePathStepBranch(null));\n        }\n        if (value instanceof LeafBranch) {\n            return new MerkleTreePathStep(path, sibling?.hash ?? null, new MerkleTreePathStepBranch(value.value));\n        }\n        return new MerkleTreePathStep(path, sibling?.hash ?? null, new MerkleTreePathStepBranch(value.childrenHash.data));\n    }\n    static isJSON(data) {\n        return (typeof data === 'object' &&\n            data !== null &&\n            'path' in data &&\n            typeof data.path === 'string' &&\n            'sibling' in data &&\n            'branch' in data);\n    }\n    static fromJSON(data) {\n        if (!MerkleTreePathStep.isJSON(data)) {\n            throw new Error('Parsing merkle tree path step failed.');\n        }\n        return new MerkleTreePathStep(BigInt(data.path), data.sibling == null ? null : DataHash.fromJSON(data.sibling), data.branch != null ? MerkleTreePathStepBranch.fromJSON(data.branch) : null);\n    }\n    static fromCBOR(bytes) {\n        const data = CborDecoder.readArray(bytes);\n        return new MerkleTreePathStep(BigintConverter.decode(CborDecoder.readByteString(data[0])), CborDecoder.readOptional(data[1], DataHash.fromCBOR), CborDecoder.readOptional(data[2], MerkleTreePathStepBranch.fromCBOR));\n    }\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            CborEncoder.encodeByteString(BigintConverter.encode(this.path)),\n            this.sibling?.toCBOR() ?? CborEncoder.encodeNull(),\n            this.branch?.toCBOR() ?? CborEncoder.encodeNull(),\n        ]);\n    }\n    toJSON() {\n        return {\n            branch: this.branch?.toJSON() ?? null,\n            path: this.path.toString(),\n            sibling: this.sibling?.toJSON() ?? null,\n        };\n    }\n    toString() {\n        return dedent `\n      Merkle Tree Path Step\n        Path: ${this.path.toString(2)}\n        Branch: ${this.branch?.toString() ?? 'null'}\n        Sibling: ${this.sibling?.toString() ?? 'null'}`;\n    }\n}\n","export class PathVerificationResult {\n    isPathValid;\n    isPathIncluded;\n    result;\n    constructor(isPathValid, isPathIncluded) {\n        this.isPathValid = isPathValid;\n        this.isPathIncluded = isPathIncluded;\n        this.result = isPathValid && isPathIncluded;\n    }\n}\n","export class BigintConverter {\n    /**\n     * Convert bytes to unsigned long\n     * @param {Uint8Array} data byte array\n     * @param {Number} offset read offset\n     * @param {Number} length read length\n     * @returns {bigint} long value\n     */\n    static decode(data, offset, length) {\n        offset = offset ?? 0;\n        length = length ?? data.length;\n        if (offset < 0 || length < 0 || offset + length > data.length) {\n            throw new Error('Index out of bounds');\n        }\n        let t = 0n;\n        for (let i = 0; i < length; ++i) {\n            t = (t << 8n) | BigInt(data[offset + i] & 0xff);\n        }\n        return t;\n    }\n    /**\n     * Convert long to byte array\n     * @param {bigint} value long value\n     * @returns {Uint8Array} Array byte array\n     */\n    static encode(value) {\n        const result = [];\n        for (let t = value; t > 0n; t >>= 8n) {\n            result.unshift(Number(t & 0xffn));\n        }\n        return new Uint8Array(result);\n    }\n}\n","import { bytesToHex, hexToBytes } from '@noble/hashes/utils';\nexport class HexConverter {\n    /**\n     * Convert byte array to hex\n     * @param {Uint8Array} data byte array\n     * @returns string hex string\n     */\n    static encode(data) {\n        return bytesToHex(data);\n    }\n    /**\n     * Convert hex string to bytes\n     * @param value hex string\n     * @returns {Uint8Array} byte array\n     */\n    static decode(value) {\n        return hexToBytes(value);\n    }\n}\n","/**\n * String dedent function, calculates distance which has to be removed from second line string\n * @param {TemplateStringsArray} strings - Template strings array\n * @param {unknown[]} data - Data to be inserted\n * @returns {string} - Dedented string\n */\nexport function dedent(strings, ...data) {\n    if (strings.length === 0) {\n        return '';\n    }\n    let rows = strings[0].split('\\n');\n    if (rows.shift()?.length !== 0) {\n        throw new Error('First line must be empty');\n    }\n    const whiteSpacesFromEdge = rows[0].length - rows[0].trimStart().length;\n    const result = [];\n    for (let j = 0; j < strings.length; j++) {\n        result.push(`${result.pop() || ''}${rows[0].slice(Math.min(rows[0].length - rows[0].trim().length, whiteSpacesFromEdge))}`);\n        for (let i = 1; i < rows.length; i++) {\n            result.push(rows[i].slice(whiteSpacesFromEdge));\n        }\n        const lastElement = result.pop();\n        const whiteSpaces = lastElement.length - lastElement.trimStart().length;\n        const dataRows = j < data.length ? String(data[j]).split('\\n') : [''];\n        result.push(`${lastElement}${dataRows[0]}`);\n        for (let i = 1; i < dataRows.length; i++) {\n            result.push(`${' '.repeat(whiteSpaces)}${dataRows[i]}`);\n        }\n        rows = j + 1 < strings.length ? strings[j + 1].split('\\n') : [];\n    }\n    return result.join('\\n');\n}\n","export {};\n//# sourceMappingURL=ISerializable.js.map","import { Authenticator } from '@unicitylabs/commons/lib/api/Authenticator.js';\nimport { RequestId } from '@unicitylabs/commons/lib/api/RequestId.js';\nimport { SubmitCommitmentStatus } from '@unicitylabs/commons/lib/api/SubmitCommitmentResponse.js';\nimport { StateTransitionClient } from './StateTransitionClient.js';\nimport { Commitment } from './transaction/Commitment.js';\nimport { OfflineCommitment } from './transaction/OfflineCommitment.js';\nimport { waitInclusionProof } from './utils/InclusionProofUtils.js';\n/**\n * High level client implementing the token state transition workflow.\n */\nexport class OfflineStateTransitionClient extends StateTransitionClient {\n    /**\n     * Create an offline commitment for a transaction (does not post it to the aggregator).\n     *\n     * @param transactionData\n     * @param signingService\n     */\n    async createOfflineCommitment(transactionData, signingService) {\n        if (!(await transactionData.sourceState.unlockPredicate.isOwner(signingService.publicKey))) {\n            throw new Error('Failed to unlock token');\n        }\n        const requestId = await RequestId.create(signingService.publicKey, transactionData.sourceState.hash);\n        const authenticator = await Authenticator.create(signingService, transactionData.hash, transactionData.sourceState.hash);\n        return new OfflineCommitment(requestId, transactionData, authenticator);\n    }\n    /**\n     * Submit an offline transaction commitment to the aggregator.\n     *\n     * @param requestId\n     * @param transactionData\n     * @param authenticator\n     */\n    async submitOfflineTransaction({ requestId, transactionData, authenticator, }) {\n        const result = await this.client.submitTransaction(requestId, transactionData.hash, authenticator, false);\n        if (result.status !== SubmitCommitmentStatus.SUCCESS) {\n            throw new Error(`Could not submit transaction: ${result.status}`);\n        }\n        const commitment = new Commitment(requestId, transactionData, authenticator);\n        return await this.createTransaction(commitment, await waitInclusionProof(this, commitment));\n    }\n}\n//# sourceMappingURL=OfflineStateTransitionClient.js.map","import { Authenticator } from '@unicitylabs/commons/lib/api/Authenticator.js';\nimport { InclusionProofVerificationStatus } from '@unicitylabs/commons/lib/api/InclusionProof.js';\nimport { RequestId } from '@unicitylabs/commons/lib/api/RequestId.js';\nimport { SubmitCommitmentStatus } from '@unicitylabs/commons/lib/api/SubmitCommitmentResponse.js';\nimport { HashAlgorithm } from '@unicitylabs/commons/lib/hash/HashAlgorithm.js';\nimport { SigningService } from '@unicitylabs/commons/lib/signing/SigningService.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { DirectAddress } from './address/DirectAddress.js';\nimport { Token } from './token/Token.js';\nimport { Commitment } from './transaction/Commitment.js';\nimport { Transaction } from './transaction/Transaction.js';\n// I_AM_UNIVERSAL_MINTER_FOR_ string bytes\n/**\n * Secret prefix for the signing used internally when minting tokens.\n */\nexport const MINTER_SECRET = HexConverter.decode('495f414d5f554e4956455253414c5f4d494e5445525f464f525f');\n/**\n * High level client implementing the token state transition workflow.\n */\nexport class StateTransitionClient {\n    client;\n    /**\n     * @param client Implementation used to talk to an aggregator\n     */\n    constructor(client) {\n        this.client = client;\n    }\n    /**\n     * Create and submit a mint transaction for a new token.\n     * @param transactionData Mint transaction data containing token information and address.\n     * @returns Commitment containing the transaction data and authenticator\n     * @throws Error when the aggregator rejects the transaction\n     *\n     * @example\n     * ```ts\n     * const commitment = await client.submitMintTransaction(\n     *   await MintTransactionData.create(\n     *     TokenId.create(crypto.getRandomValues(new Uint8Array(32))),\n     *     TokenType.create(crypto.getRandomValues(new Uint8Array(32))),\n     *     new Uint8Array(),\n     *     null,\n     *     await DirectAddress.create(mintTokenData.predicate.reference),\n     *     crypto.getRandomValues(new Uint8Array(32)),\n     *     null,\n     *     null\n     *   )\n     * );\n     * ```\n     */\n    async submitMintTransaction(transactionData) {\n        return this.sendTransaction(transactionData, await SigningService.createFromSecret(MINTER_SECRET, transactionData.tokenId.bytes));\n    }\n    /**\n     * Submit a state transition for an existing token.\n     *\n     * @param transactionData Data describing the transition\n     * @param signingService   Signing service for the current owner\n     * @returns Commitment ready for inclusion proof retrieval\n     * @throws Error if ownership verification fails or aggregator rejects\n     *\n     * @example\n     * ```ts\n     * const commitment = await client.submitTransaction(data, signingService);\n     * ```\n     */\n    async submitTransaction(transactionData, signingService) {\n        if (!(await transactionData.sourceState.unlockPredicate.isOwner(signingService.publicKey))) {\n            throw new Error('Failed to unlock token');\n        }\n        return this.sendTransaction(transactionData, signingService);\n    }\n    /**\n     * Build a {@link Transaction} object once an inclusion proof is obtained.\n     *\n     * @param param0       Commitment returned from submit* methods\n     * @param inclusionProof Proof of inclusion from the aggregator\n     * @returns Constructed transaction object\n     * @throws Error if the inclusion proof is invalid\n     *\n     * @example\n     * ```ts\n     * const tx = await client.createTransaction(commitment, inclusionProof);\n     * ```\n     */\n    async createTransaction({ requestId, transactionData }, inclusionProof) {\n        const status = await inclusionProof.verify(requestId.toBigInt());\n        if (status != InclusionProofVerificationStatus.OK) {\n            throw new Error('Inclusion proof verification failed.');\n        }\n        if (!inclusionProof.authenticator || !HashAlgorithm[inclusionProof.authenticator.stateHash.algorithm]) {\n            throw new Error('Invalid inclusion proof hash algorithm.');\n        }\n        if (!inclusionProof.transactionHash?.equals(transactionData.hash)) {\n            throw new Error('Payload hash mismatch');\n        }\n        return new Transaction(transactionData, inclusionProof);\n    }\n    /**\n     * Finalise a transaction and produce the next token state.\n     *\n     * @param token           Token being transitioned\n     * @param state           New state after the transition\n     * @param transaction     Transaction proving the state change\n     * @param nametagTokens   Optional name tag tokens associated with the transfer\n     * @returns Updated token instance\n     * @throws Error if validation checks fail\n     *\n     * @example\n     * ```ts\n     * const updated = await client.finishTransaction(token, state, tx);\n     * ```\n     */\n    async finishTransaction(token, state, transaction, nametagTokens = []) {\n        if (!(await transaction.data.sourceState.unlockPredicate.verify(transaction))) {\n            throw new Error('Predicate verification failed');\n        }\n        // TODO: Move address processing to a separate method\n        // TODO: Resolve proxy address\n        const expectedAddress = await DirectAddress.create(state.unlockPredicate.reference);\n        if (expectedAddress.toJSON() !== transaction.data.recipient) {\n            throw new Error('Recipient address mismatch');\n        }\n        const transactions = [...token.transactions, transaction];\n        if (!(await transaction.containsData(state.data))) {\n            throw new Error('State data is not part of transaction.');\n        }\n        return new Token(state, token.genesis, transactions, nametagTokens);\n    }\n    /**\n     * Query the ledger to see if the token's current state has been spent.\n     *\n     * @param token     Token to check\n     * @param publicKey Public key of the owner\n     * @returns Verification status reported by the aggregator\n     *\n     * @example\n     * ```ts\n     * const status = await client.getTokenStatus(token, ownerPublicKey);\n     * ```\n     */\n    async getTokenStatus(token, publicKey) {\n        const requestId = await RequestId.create(publicKey, token.state.hash);\n        const inclusionProof = await this.client.getInclusionProof(requestId);\n        // TODO: Check ownership?\n        return inclusionProof.verify(requestId.toBigInt());\n    }\n    /**\n     * Convenience helper to retrieve the inclusion proof for a commitment.\n     *\n     * @example\n     * ```ts\n     * const proof = await client.getInclusionProof(commitment);\n     * ```\n     */\n    getInclusionProof(commitment) {\n        return this.client.getInclusionProof(commitment.requestId);\n    }\n    async sendTransaction(transactionData, signingService) {\n        const requestId = await RequestId.create(signingService.publicKey, transactionData.sourceState.hash);\n        const authenticator = await Authenticator.create(signingService, transactionData.hash, transactionData.sourceState.hash);\n        const result = await this.client.submitTransaction(requestId, transactionData.hash, authenticator);\n        if (result.status !== SubmitCommitmentStatus.SUCCESS) {\n            throw new Error(`Could not submit transaction: ${result.status}`);\n        }\n        return new Commitment(requestId, transactionData, authenticator);\n    }\n}\n//# sourceMappingURL=StateTransitionClient.js.map","/**\n * Enum representing different address schemes.\n */\nexport var AddressScheme;\n(function (AddressScheme) {\n    /** Direct address pointing to a predicate reference. */\n    AddressScheme[\"DIRECT\"] = \"DIRECT\";\n    /** Address pointing to a proxy object such as a name tag. */\n    AddressScheme[\"PROXY\"] = \"PROXY\";\n})(AddressScheme || (AddressScheme = {}));\n//# sourceMappingURL=AddressScheme.js.map","import { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { DataHash } from '@unicitylabs/commons/lib/hash/DataHash.js';\nimport { DataHasher } from '@unicitylabs/commons/lib/hash/DataHasher.js';\nimport { HashAlgorithm } from '@unicitylabs/commons/lib/hash/HashAlgorithm.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { AddressScheme } from './AddressScheme.js';\n/**\n * Address that directly references a predicate.\n *\n * This address type is used to point to a specific predicate by its reference hash.\n * It includes a checksum to help detect mistyped addresses.\n */\nexport class DirectAddress {\n    data;\n    checksum;\n    /**\n     * Create a new {@link DirectAddress} instance.\n     *\n     * @param data     Reference to the predicate this address points to\n     * @param checksum 4-byte checksum to detect mistyped addresses\n     */\n    constructor(data, checksum) {\n        this.data = data;\n        this.checksum = checksum;\n        this.checksum = new Uint8Array(checksum.slice(0, 4));\n    }\n    /**\n     * @inheritDoc\n     */\n    get scheme() {\n        return AddressScheme.DIRECT;\n    }\n    /**\n     * Build a direct address from a predicate reference.\n     *\n     * @param predicateReference The predicate reference to encode\n     * @returns Newly created address instance\n     */\n    static async create(predicateReference) {\n        const checksum = await new DataHasher(HashAlgorithm.SHA256).update(predicateReference.toCBOR()).digest();\n        return new DirectAddress(predicateReference, checksum.data.slice(0, 4));\n    }\n    /**\n     * Create new DirectAddress from string.\n     * @param data Address as string.\n     */\n    static async fromJSON(data) {\n        const [scheme, uri] = data.split('://');\n        if (scheme !== AddressScheme.DIRECT) {\n            throw new Error(`Invalid address scheme: expected ${AddressScheme.DIRECT}, got ${scheme}`);\n        }\n        const checksum = uri.slice(-8);\n        const address = await DirectAddress.create(DataHash.fromCBOR(HexConverter.decode(uri.slice(0, -8))));\n        if (HexConverter.encode(address.checksum) !== checksum) {\n            throw new Error(`Invalid checksum for DirectAddress: expected ${checksum}, got ${HexConverter.encode(address.checksum)}`);\n        }\n        return address;\n    }\n    /**\n     * Convert the address into its canonical string form.\n     */\n    toJSON() {\n        return this.toString();\n    }\n    /**\n     * Encode the address as a CBOR text string.\n     */\n    toCBOR() {\n        return CborEncoder.encodeTextString(this.toString());\n    }\n    /** Convert instance to readable string */\n    toString() {\n        return `${this.scheme}://${HexConverter.encode(this.data.toCBOR())}${HexConverter.encode(this.checksum)}`;\n    }\n}\n//# sourceMappingURL=DirectAddress.js.map","export {};\n//# sourceMappingURL=IAddress.js.map","import { InclusionProof } from '@unicitylabs/commons/lib/api/InclusionProof.js';\nimport { SubmitCommitmentRequest } from '@unicitylabs/commons/lib/api/SubmitCommitmentRequest.js';\nimport { SubmitCommitmentResponse } from '@unicitylabs/commons/lib/api/SubmitCommitmentResponse.js';\nimport { JsonRpcHttpTransport } from '@unicitylabs/commons/lib/json-rpc/JsonRpcHttpTransport.js';\n/**\n * Client implementation for communicating with an aggregator via JSON-RPC.\n */\nexport class AggregatorClient {\n    transport;\n    /**\n     * Create a new client pointing to the given aggregator URL.\n     *\n     * @param url Base URL of the aggregator JSON-RPC endpoint\n     */\n    constructor(url) {\n        this.transport = new JsonRpcHttpTransport(url);\n    }\n    /**\n     * @inheritDoc\n     */\n    async submitTransaction(requestId, transactionHash, authenticator, receipt = false) {\n        const request = new SubmitCommitmentRequest(requestId, transactionHash, authenticator, receipt);\n        const response = await this.transport.request('submit_commitment', request.toJSON());\n        return SubmitCommitmentResponse.fromJSON(response);\n    }\n    /**\n     * @inheritDoc\n     */\n    async getInclusionProof(requestId, blockNum) {\n        const data = { blockNum: blockNum?.toString(), requestId: requestId.toJSON() };\n        return InclusionProof.fromJSON(await this.transport.request('get_inclusion_proof', data));\n    }\n    /**\n     * Fetch a proof that the given request has not been deleted from the ledger.\n     *\n     * @param requestId Request identifier\n     */\n    getNoDeletionProof(requestId) {\n        const data = { requestId: requestId.toJSON() };\n        return this.transport.request('get_no_deletion_proof', data);\n    }\n    async getBlockHeight() {\n        const response = await this.transport.request('get_block_height', {});\n        if (response &&\n            typeof response === 'object' &&\n            'blockNumber' in response &&\n            (typeof response.blockNumber === 'string' ||\n                typeof response.blockNumber === 'number' ||\n                typeof response.blockNumber === 'bigint')) {\n            return BigInt(response.blockNumber);\n        }\n        throw new Error('Invalid response format for block height');\n    }\n}\n//# sourceMappingURL=AggregatorClient.js.map","export {};\n//# sourceMappingURL=IAggregatorClient.js.map","// Address exports\nexport * from './address/AddressScheme.js';\nexport * from './address/DirectAddress.js';\nexport * from './address/IAddress.js';\n// API exports\nexport * from './api/AggregatorClient.js';\nexport * from './api/IAggregatorClient.js';\n// Predicate exports\nexport * from './predicate/BurnPredicate.js';\nexport * from './predicate/DefaultPredicate.js';\nexport * from './predicate/IPredicate.js';\nexport * from './predicate/IPredicateFactory.js';\nexport * from './predicate/MaskedPredicate.js';\nexport * from './predicate/PredicateJsonFactory.js';\nexport * from './predicate/PredicateType.js';\nexport * from './predicate/UnmaskedPredicate.js';\n// Token exports\nexport * from './token/NameTagToken.js';\nexport * from './token/NameTagTokenData.js';\nexport * from './token/Token.js';\nexport * from './token/TokenFactory.js';\nexport * from './token/TokenId.js';\nexport * from './token/TokenState.js';\nexport * from './token/TokenType.js';\n// Fungible token exports\nexport * from './token/fungible/TokenCoinData.js';\nexport * from './token/fungible/CoinId.js';\n// Transaction exports\nexport * from './transaction/Commitment.js';\nexport * from './transaction/MintTransactionData.js';\nexport * from './transaction/Transaction.js';\nexport * from './transaction/TransactionData.js';\n// Core exports\nexport * from './ISerializable.js';\nexport * from './StateTransitionClient.js';\n//# sourceMappingURL=index.js.map","import { CborDecoder } from '@unicitylabs/commons/lib/cbor/CborDecoder.js';\nimport { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { DataHash } from '@unicitylabs/commons/lib/hash/DataHash.js';\nimport { DataHasher } from '@unicitylabs/commons/lib/hash/DataHasher.js';\nimport { HashAlgorithm } from '@unicitylabs/commons/lib/hash/HashAlgorithm.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { dedent } from '@unicitylabs/commons/lib/util/StringUtils.js';\nimport { PredicateType } from './PredicateType.js';\nconst TYPE = PredicateType.BURN;\n/**\n * Predicate representing a permanently burned token.\n */\nexport class BurnPredicate {\n    reference;\n    hash;\n    _nonce;\n    reason;\n    type = TYPE;\n    /**\n     * @param reference  Reference hash identifying the predicate\n     * @param hash       Unique hash of the predicate and token\n     * @param _nonce     Nonce used to ensure uniqueness\n     * @param reason     Reason for the burn\n     */\n    constructor(reference, hash, _nonce, reason) {\n        this.reference = reference;\n        this.hash = hash;\n        this._nonce = _nonce;\n        this.reason = reason;\n    }\n    /** @inheritDoc */\n    get nonce() {\n        return new Uint8Array(this._nonce);\n    }\n    /**\n     * Create a new burn predicate.\n     * @param tokenId Token ID for which the predicate is valid.\n     * @param tokenType Type of the token.\n     * @param nonce Nonce providing uniqueness for the predicate.\n     * @param burnReason Burn reason for committing to the new tokens and coins being created after the burn.\n     */\n    static async create(tokenId, tokenType, nonce, burnReason) {\n        const reference = await BurnPredicate.calculateReference(tokenType, burnReason);\n        const hash = await BurnPredicate.calculateHash(reference, tokenId, nonce);\n        return new BurnPredicate(reference, hash, nonce, burnReason);\n    }\n    /**\n     * Create a burn predicate from JSON data.\n     * @param tokenId Token ID for which the predicate is valid.\n     * @param tokenType Type of the token.\n     * @param data JSON data representing the burn predicate.\n     */\n    static fromJSON(tokenId, tokenType, data) {\n        if (!BurnPredicate.isJSON(data)) {\n            throw new Error('Invalid burn predicate json');\n        }\n        return BurnPredicate.create(tokenId, tokenType, HexConverter.decode(data.nonce), DataHash.fromJSON(data.reason));\n    }\n    static fromCBOR(tokenId, tokenType, bytes) {\n        const data = CborDecoder.readArray(bytes);\n        const type = CborDecoder.readTextString(data[0]);\n        if (type !== PredicateType.BURN) {\n            throw new Error(`Invalid predicate type: expected ${PredicateType.BURN}, got ${type}`);\n        }\n        return BurnPredicate.create(tokenId, tokenType, CborDecoder.readByteString(data[1]), DataHash.fromCBOR(data[2]));\n    }\n    /**\n     * Calculate the reference hash for a burn predicate.\n     * @param tokenType Type of the token for which the predicate is valid.\n     * @param burnReason Reason for the burn\n     */\n    static calculateReference(tokenType, burnReason) {\n        return new DataHasher(HashAlgorithm.SHA256)\n            .update(CborEncoder.encodeArray([CborEncoder.encodeTextString(TYPE), tokenType.toCBOR(), burnReason.toCBOR()]))\n            .digest();\n    }\n    /**\n     * Check if the provided data is a valid JSON representation of a burn predicate.\n     * @param data Data to validate.\n     */\n    static isJSON(data) {\n        return (typeof data === 'object' &&\n            data !== null &&\n            'type' in data &&\n            data.type === PredicateType.BURN &&\n            'nonce' in data &&\n            typeof data.nonce === 'string' &&\n            'reason' in data &&\n            typeof data.reason === 'string');\n    }\n    /**\n     * Compute the predicate hash for a specific token and nonce.\n     * @param reference Reference hash of the predicate.\n     * @param tokenId Token ID for which the predicate is valid.\n     * @param nonce Nonce providing uniqueness for the predicate.\n     * @private\n     */\n    static calculateHash(reference, tokenId, nonce) {\n        return new DataHasher(HashAlgorithm.SHA256)\n            .update(CborEncoder.encodeArray([reference.toCBOR(), tokenId.toCBOR(), CborEncoder.encodeByteString(nonce)]))\n            .digest();\n    }\n    /** @inheritDoc */\n    toJSON() {\n        return {\n            nonce: HexConverter.encode(this._nonce),\n            reason: this.reason.toJSON(),\n            type: this.type,\n        };\n    }\n    /** @inheritDoc */\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            CborEncoder.encodeTextString(this.type),\n            CborEncoder.encodeByteString(this._nonce),\n            this.reason.toCBOR(),\n        ]);\n    }\n    /** @inheritDoc */\n    verify() {\n        return Promise.resolve(false);\n    }\n    /** Convert instance to readable string */\n    toString() {\n        return dedent `\n          Predicate[${this.type}]:\n            Hash: ${this.hash.toString()}`;\n    }\n    /** @inheritDoc */\n    isOwner() {\n        return Promise.resolve(false);\n    }\n}\n//# sourceMappingURL=BurnPredicate.js.map","import { InclusionProofVerificationStatus } from '@unicitylabs/commons/lib/api/InclusionProof.js';\nimport { RequestId } from '@unicitylabs/commons/lib/api/RequestId.js';\nimport { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { HashAlgorithm } from '@unicitylabs/commons/lib/hash/HashAlgorithm.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { dedent } from '@unicitylabs/commons/lib/util/StringUtils.js';\n/**\n * Base predicate containing common verification logic for key-based predicates.\n */\nexport class DefaultPredicate {\n    type;\n    _publicKey;\n    algorithm;\n    hashAlgorithm;\n    _nonce;\n    reference;\n    hash;\n    /**\n     * @param type          Predicate type value\n     * @param _publicKey    Public key able to sign transactions\n     * @param algorithm     Signing algorithm name\n     * @param hashAlgorithm Hash algorithm used for hashing operations\n     * @param _nonce        Nonce providing uniqueness\n     * @param reference     Reference hash of the predicate\n     * @param hash          Hash of the predicate with a specific token\n     */\n    constructor(type, _publicKey, algorithm, hashAlgorithm, _nonce, reference, hash) {\n        this.type = type;\n        this._publicKey = _publicKey;\n        this.algorithm = algorithm;\n        this.hashAlgorithm = hashAlgorithm;\n        this._nonce = _nonce;\n        this.reference = reference;\n        this.hash = hash;\n        this._publicKey = new Uint8Array(_publicKey);\n        this._nonce = new Uint8Array(_nonce);\n    }\n    /** Public key associated with the predicate. */\n    get publicKey() {\n        return this._publicKey;\n    }\n    /**\n     * @inheritDoc\n     */\n    get nonce() {\n        return this._nonce;\n    }\n    /**\n     * Check if the provided data is a valid JSON representation of a key based predicate.\n     * @param data Data to validate.\n     */\n    static isJSON(data) {\n        return (typeof data === 'object' &&\n            data !== null &&\n            'publicKey' in data &&\n            typeof data.publicKey === 'string' &&\n            'algorithm' in data &&\n            typeof data.algorithm === 'string' &&\n            'hashAlgorithm' in data &&\n            !!HashAlgorithm[data.hashAlgorithm] &&\n            'nonce' in data &&\n            typeof data.nonce === 'string');\n    }\n    /**\n     * @inheritDoc\n     */\n    toJSON() {\n        return {\n            algorithm: this.algorithm,\n            hashAlgorithm: this.hashAlgorithm,\n            nonce: HexConverter.encode(this.nonce),\n            publicKey: HexConverter.encode(this.publicKey),\n            type: this.type,\n        };\n    }\n    /**\n     * @inheritDoc\n     */\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            CborEncoder.encodeTextString(this.type),\n            CborEncoder.encodeByteString(this.publicKey),\n            CborEncoder.encodeTextString(this.algorithm),\n            CborEncoder.encodeTextString(HashAlgorithm[this.hashAlgorithm]),\n            CborEncoder.encodeByteString(this.nonce),\n        ]);\n    }\n    /**\n     * @inheritDoc\n     */\n    async verify(transaction) {\n        if (!transaction.inclusionProof.authenticator || !transaction.inclusionProof.transactionHash) {\n            return false;\n        }\n        // Verify if input state and public key are correct.\n        if (HexConverter.encode(transaction.inclusionProof.authenticator.publicKey) !== HexConverter.encode(this.publicKey) ||\n            !transaction.inclusionProof.authenticator.stateHash.equals(transaction.data.sourceState.hash)) {\n            return false; // input mismatch\n        }\n        // Verify if transaction data is valid.\n        if (!(await transaction.inclusionProof.authenticator.verify(transaction.data.hash))) {\n            return false;\n        }\n        // Verify inclusion proof path.\n        const requestId = await RequestId.create(this.publicKey, transaction.data.sourceState.hash);\n        const status = await transaction.inclusionProof.verify(requestId.toBigInt());\n        return status === InclusionProofVerificationStatus.OK;\n    }\n    /** Convert instance to readable string */\n    toString() {\n        return dedent `\n          Predicate[${this.type}]:\n            PublicKey: ${HexConverter.encode(this.publicKey)}\n            Algorithm: ${this.algorithm}\n            Hash Algorithm: ${HashAlgorithm[this.hashAlgorithm]}\n            Nonce: ${HexConverter.encode(this.nonce)}\n            Hash: ${this.hash.toString()}`;\n    }\n    /**\n     * @inheritDoc\n     */\n    isOwner(publicKey) {\n        return Promise.resolve(HexConverter.encode(publicKey) === HexConverter.encode(this.publicKey));\n    }\n}\n//# sourceMappingURL=DefaultPredicate.js.map","export {};\n//# sourceMappingURL=IPredicate.js.map","export {};\n//# sourceMappingURL=IPredicateFactory.js.map","import { CborDecoder } from '@unicitylabs/commons/lib/cbor/CborDecoder.js';\nimport { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { DataHasher } from '@unicitylabs/commons/lib/hash/DataHasher.js';\nimport { HashAlgorithm } from '@unicitylabs/commons/lib/hash/HashAlgorithm.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { DefaultPredicate } from './DefaultPredicate.js';\nimport { PredicateType } from './PredicateType.js';\nconst TYPE = PredicateType.MASKED;\n/**\n * Predicate for masked address transaction.\n */\nexport class MaskedPredicate extends DefaultPredicate {\n    /**\n     * @param publicKey     Owner public key\n     * @param algorithm     Transaction signing algorithm\n     * @param hashAlgorithm Transaction hash algorithm\n     * @param nonce         Nonce used in the predicate\n     * @param reference     Predicate reference\n     * @param hash          Predicate hash\n     */\n    constructor(publicKey, algorithm, hashAlgorithm, nonce, reference, hash) {\n        super(TYPE, publicKey, algorithm, hashAlgorithm, nonce, reference, hash);\n    }\n    /**\n     * Create a new masked predicate for the given owner.\n     * @param tokenId token ID.\n     * @param tokenType token type.\n     * @param signingService Token owner's signing service.\n     * @param hashAlgorithm Hash algorithm used to hash transaction.\n     * @param nonce Nonce value used during creation, providing uniqueness.\n     */\n    static create(tokenId, tokenType, signingService, hashAlgorithm, nonce) {\n        return MaskedPredicate.createFromPublicKey(tokenId, tokenType, signingService.algorithm, signingService.publicKey, hashAlgorithm, nonce);\n    }\n    static async createFromPublicKey(tokenId, tokenType, signingAlgorithm, publicKey, hashAlgorithm, nonce) {\n        const reference = await MaskedPredicate.calculateReference(tokenType, signingAlgorithm, publicKey, hashAlgorithm, nonce);\n        const hash = await MaskedPredicate.calculateHash(reference, tokenId);\n        return new MaskedPredicate(publicKey, signingAlgorithm, hashAlgorithm, nonce, reference, hash);\n    }\n    /**\n     * Create a masked predicate from JSON data.\n     * @param tokenId Token ID.\n     * @param tokenType Token type.\n     * @param data JSON data representing the masked predicate.\n     */\n    static fromJSON(tokenId, tokenType, data) {\n        if (!DefaultPredicate.isJSON(data) || data.type !== TYPE) {\n            throw new Error('Invalid masked predicate json.');\n        }\n        return MaskedPredicate.createFromPublicKey(tokenId, tokenType, data.algorithm, HexConverter.decode(data.publicKey), data.hashAlgorithm, HexConverter.decode(data.nonce));\n    }\n    static fromCBOR(tokenId, tokenType, bytes) {\n        const data = CborDecoder.readArray(bytes);\n        const type = CborDecoder.readTextString(data[0]);\n        if (type !== PredicateType.MASKED) {\n            throw new Error(`Invalid predicate type: expected ${PredicateType.MASKED}, got ${type}`);\n        }\n        const hashAlgorithm = CborDecoder.readTextString(data[3]);\n        if (!HashAlgorithm[hashAlgorithm]) {\n            throw new Error(`Invalid hash algorithm: ${hashAlgorithm}`);\n        }\n        return MaskedPredicate.createFromPublicKey(tokenId, tokenType, CborDecoder.readTextString(data[2]), CborDecoder.readByteString(data[1]), hashAlgorithm, CborDecoder.readByteString(data[4]));\n    }\n    /**\n     * Compute the predicate reference.\n     * @param tokenType token type.\n     * @param algorithm Signing algorithm.\n     * @param publicKey Owner's public key.\n     * @param hashAlgorithm Hash algorithm used for signing.\n     * @param nonce Nonce providing uniqueness for the predicate.\n     */\n    static calculateReference(tokenType, algorithm, publicKey, hashAlgorithm, nonce) {\n        return new DataHasher(HashAlgorithm.SHA256)\n            .update(CborEncoder.encodeArray([\n            CborEncoder.encodeTextString(TYPE),\n            tokenType.toCBOR(),\n            CborEncoder.encodeTextString(algorithm),\n            CborEncoder.encodeTextString(HashAlgorithm[hashAlgorithm]),\n            CborEncoder.encodeByteString(publicKey),\n            CborEncoder.encodeByteString(nonce),\n        ]))\n            .digest();\n    }\n    /**\n     * Compute the predicate hash for a specific token and nonce.\n     * @param reference Reference hash of the predicate.\n     * @param tokenId Token ID.\n     * @private\n     */\n    static calculateHash(reference, tokenId) {\n        return new DataHasher(HashAlgorithm.SHA256)\n            .update(CborEncoder.encodeArray([reference.toCBOR(), tokenId.toCBOR()]))\n            .digest();\n    }\n}\n//# sourceMappingURL=MaskedPredicate.js.map","import { BurnPredicate } from './BurnPredicate.js';\nimport { MaskedPredicate } from './MaskedPredicate.js';\nimport { PredicateType } from './PredicateType.js';\nimport { UnmaskedPredicate } from './UnmaskedPredicate.js';\n/**\n * Default implementation of {@link IPredicateFactory}.\n */\nexport class PredicateJsonFactory {\n    /**\n     * @inheritDoc\n     */\n    create(tokenId, tokenType, data) {\n        switch (data.type) {\n            case PredicateType.BURN:\n                return BurnPredicate.fromJSON(tokenId, tokenType, data);\n            case PredicateType.MASKED:\n                return MaskedPredicate.fromJSON(tokenId, tokenType, data);\n            case PredicateType.UNMASKED:\n                return UnmaskedPredicate.fromJSON(tokenId, tokenType, data);\n            default:\n                throw new Error(`Unknown predicate type: ${data.type}`);\n        }\n    }\n}\n//# sourceMappingURL=PredicateJsonFactory.js.map","/**\n * Enum representing different types of predicates.\n */\nexport var PredicateType;\n(function (PredicateType) {\n    /** Predicate for masked address */\n    PredicateType[\"MASKED\"] = \"MASKED\";\n    /** Predicate for public address */\n    PredicateType[\"UNMASKED\"] = \"UNMASKED\";\n    /** Special predicate burning the token */\n    PredicateType[\"BURN\"] = \"BURN\";\n})(PredicateType || (PredicateType = {}));\n//# sourceMappingURL=PredicateType.js.map","import { CborDecoder } from '@unicitylabs/commons/lib/cbor/CborDecoder.js';\nimport { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { DataHasher } from '@unicitylabs/commons/lib/hash/DataHasher.js';\nimport { HashAlgorithm } from '@unicitylabs/commons/lib/hash/HashAlgorithm.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { DefaultPredicate } from './DefaultPredicate.js';\nimport { PredicateType } from './PredicateType.js';\nconst TYPE = PredicateType.UNMASKED;\n/**\n * Predicate for public address transaction.\n */\nexport class UnmaskedPredicate extends DefaultPredicate {\n    /**\n     * @param publicKey     Owner public key.\n     * @param algorithm     Transaction signing algorithm\n     * @param hashAlgorithm Transaction hash algorithm\n     * @param nonce         Nonce used in the predicate\n     * @param reference     Predicate reference\n     * @param hash          Predicate hash\n     */\n    constructor(publicKey, algorithm, hashAlgorithm, nonce, reference, hash) {\n        super(TYPE, publicKey, algorithm, hashAlgorithm, nonce, reference, hash);\n    }\n    /**\n     * Create a new unmasked predicate for the given owner.\n     * @param tokenId Token ID\n     * @param tokenType Token type\n     * @param signingService Token owner's signing service\n     * @param hashAlgorithm Hash algorithm used to hash transaction\n     * @param salt Transaction salt\n     */\n    static async create(tokenId, tokenType, signingService, hashAlgorithm, salt) {\n        const saltHash = await new DataHasher(HashAlgorithm.SHA256).update(salt).digest();\n        const nonce = await signingService.sign(saltHash);\n        return UnmaskedPredicate.createFromPublicKey(tokenId, tokenType, signingService.algorithm, signingService.publicKey, hashAlgorithm, nonce.bytes);\n    }\n    static async createFromPublicKey(tokenId, tokenType, signingAlgorithm, publicKey, hashAlgorithm, nonce) {\n        const reference = await UnmaskedPredicate.calculateReference(tokenType, signingAlgorithm, publicKey, hashAlgorithm);\n        const hash = await UnmaskedPredicate.calculateHash(reference, tokenId, nonce);\n        return new UnmaskedPredicate(publicKey, signingAlgorithm, hashAlgorithm, nonce, reference, hash);\n    }\n    /**\n     * Create a masked predicate from JSON data.\n     * @param tokenId Token ID.\n     * @param tokenType Token type.\n     * @param data JSON data representing the masked predicate.\n     */\n    static fromJSON(tokenId, tokenType, data) {\n        if (!DefaultPredicate.isJSON(data) || data.type !== TYPE) {\n            throw new Error('Invalid unmasked predicate json.');\n        }\n        return UnmaskedPredicate.createFromPublicKey(tokenId, tokenType, data.algorithm, HexConverter.decode(data.publicKey), data.hashAlgorithm, HexConverter.decode(data.nonce));\n    }\n    static fromCBOR(tokenId, tokenType, bytes) {\n        const data = CborDecoder.readArray(bytes);\n        const type = CborDecoder.readTextString(data[0]);\n        if (type !== PredicateType.UNMASKED) {\n            throw new Error(`Invalid predicate type: expected ${PredicateType.UNMASKED}, got ${type}`);\n        }\n        const hashAlgorithm = CborDecoder.readTextString(data[3]);\n        if (!HashAlgorithm[hashAlgorithm]) {\n            throw new Error(`Invalid hash algorithm: ${hashAlgorithm}`);\n        }\n        return UnmaskedPredicate.createFromPublicKey(tokenId, tokenType, CborDecoder.readTextString(data[2]), CborDecoder.readByteString(data[1]), hashAlgorithm, CborDecoder.readByteString(data[4]));\n    }\n    /**\n     * Calculate the predicate reference.\n     * @param tokenType Token type\n     * @param algorithm Signing algorithm\n     * @param publicKey Owner public key\n     * @param hashAlgorithm Hash algorithm used to hash transaction\n     */\n    static calculateReference(tokenType, algorithm, publicKey, hashAlgorithm) {\n        return new DataHasher(HashAlgorithm.SHA256)\n            .update(CborEncoder.encodeArray([\n            CborEncoder.encodeTextString(TYPE),\n            tokenType.toCBOR(),\n            CborEncoder.encodeTextString(algorithm),\n            CborEncoder.encodeTextString(HashAlgorithm[hashAlgorithm]),\n            CborEncoder.encodeByteString(publicKey),\n        ]))\n            .digest();\n    }\n    /**\n     * Calculate the predicate hash.\n     * @param reference Reference of the predicate\n     * @param tokenId Token ID\n     * @param nonce Nonce used in the predicate\n     * @private\n     */\n    static calculateHash(reference, tokenId, nonce) {\n        return new DataHasher(HashAlgorithm.SHA256)\n            .update(CborEncoder.encodeArray([reference.toCBOR(), tokenId.toCBOR(), CborEncoder.encodeByteString(nonce)]))\n            .digest();\n    }\n}\n//# sourceMappingURL=UnmaskedPredicate.js.map","import { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { Token, TOKEN_VERSION } from '../../token/Token.js';\nimport { TokenState } from '../../token/TokenState.js';\nimport { MintTransactionJsonDeserializer } from '../transaction/MintTransactionJsonDeserializer.js';\nimport { TransactionJsonDeserializer } from '../transaction/TransactionJsonDeserializer.js';\nexport class TokenJsonDeserializer {\n    predicateFactory;\n    mintTransactionDeserializer;\n    transactionDeserializer;\n    constructor(predicateFactory) {\n        this.predicateFactory = predicateFactory;\n        this.mintTransactionDeserializer = new MintTransactionJsonDeserializer(this);\n        this.transactionDeserializer = new TransactionJsonDeserializer(predicateFactory);\n    }\n    async deserialize(data) {\n        const tokenVersion = data.version;\n        if (tokenVersion !== TOKEN_VERSION) {\n            throw new Error(`Cannot parse token. Version mismatch: ${tokenVersion} !== ${TOKEN_VERSION}`);\n        }\n        const mintTransaction = await this.mintTransactionDeserializer.deserialize(data.genesis);\n        const transactions = [];\n        for (const transaction of data.transactions) {\n            transactions.push(await this.transactionDeserializer.deserialize(mintTransaction.data.tokenId, mintTransaction.data.tokenType, transaction));\n        }\n        // TODO: Add nametag tokens\n        return new Token(await TokenState.create(await this.predicateFactory.create(mintTransaction.data.tokenId, mintTransaction.data.tokenType, data.state.unlockPredicate), data.state.data ? HexConverter.decode(data.state.data) : null), mintTransaction, transactions, [], tokenVersion);\n    }\n}\n//# sourceMappingURL=TokenJsonDeserializer.js.map","import { InclusionProof } from '@unicitylabs/commons/lib/api/InclusionProof.js';\nimport { DataHash } from '@unicitylabs/commons/lib/hash/DataHash.js';\nimport { MerkleSumTreePath } from '@unicitylabs/commons/lib/smst/MerkleSumTreePath.js';\nimport { MerkleTreePath } from '@unicitylabs/commons/lib/smt/MerkleTreePath.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { SplitMintReason } from '../../token/fungible/SplitMintReason.js';\nimport { SplitMintReasonProof } from '../../token/fungible/SplitMintReasonProof.js';\nimport { TokenCoinData } from '../../token/fungible/TokenCoinData.js';\nimport { TokenId } from '../../token/TokenId.js';\nimport { TokenType } from '../../token/TokenType.js';\nimport { MintReasonType } from '../../transaction/MintReasonType.js';\nimport { MintTransactionData, } from '../../transaction/MintTransactionData.js';\nimport { Transaction } from '../../transaction/Transaction.js';\nexport class MintTransactionJsonDeserializer {\n    tokenDeserializer;\n    constructor(tokenDeserializer) {\n        this.tokenDeserializer = tokenDeserializer;\n    }\n    async deserialize({ data, inclusionProof, }) {\n        return new Transaction(await MintTransactionData.create(TokenId.create(HexConverter.decode(data.tokenId)), TokenType.create(HexConverter.decode(data.tokenType)), HexConverter.decode(data.tokenData), data.coins ? TokenCoinData.fromJSON(data.coins) : null, data.recipient, HexConverter.decode(data.salt), data.dataHash ? DataHash.fromJSON(data.dataHash) : null, data.reason ? await this.createMintReason(data.reason) : null), InclusionProof.fromJSON(inclusionProof));\n    }\n    createMintReason(data) {\n        switch (data.type) {\n            case MintReasonType.TOKEN_SPLIT:\n                return this.createSplitMintReason(data);\n            default:\n                throw new Error(`Unsupported mint reason type: ${data.type}`);\n        }\n    }\n    async createSplitMintReason(data) {\n        const proofs = new Map();\n        for (const [coinId, proof] of data.proofs) {\n            proofs.set(BigInt(coinId), new SplitMintReasonProof(MerkleTreePath.fromJSON(proof.aggregationPath), MerkleSumTreePath.fromJSON(proof.coinTreePath)));\n        }\n        return new SplitMintReason(await this.tokenDeserializer.deserialize(data.token), proofs);\n    }\n}\n//# sourceMappingURL=MintTransactionJsonDeserializer.js.map","import { InclusionProof } from '@unicitylabs/commons/lib/api/InclusionProof.js';\nimport { DataHash } from '@unicitylabs/commons/lib/hash/DataHash.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { TokenState } from '../../token/TokenState.js';\nimport { Transaction } from '../../transaction/Transaction.js';\nimport { TransactionData } from '../../transaction/TransactionData.js';\nexport class TransactionJsonDeserializer {\n    predicateFactory;\n    constructor(predicateFactory) {\n        this.predicateFactory = predicateFactory;\n    }\n    async deserialize(tokenId, tokenType, { data, inclusionProof }) {\n        return new Transaction(await TransactionData.create(await TokenState.create(await this.predicateFactory.create(tokenId, tokenType, data.sourceState.unlockPredicate), data.sourceState.data ? HexConverter.decode(data.sourceState.data) : null), data.recipient, HexConverter.decode(data.salt), data.dataHash ? DataHash.fromJSON(data.dataHash) : null, data.message ? HexConverter.decode(data.message) : null, []), InclusionProof.fromJSON(inclusionProof));\n    }\n}\n//# sourceMappingURL=TransactionJsonDeserializer.js.map","export {};\n//# sourceMappingURL=NameTagToken.js.map","/**\n * Placeholder data type for name tag tokens.\n */\nexport class NameTagTokenData {\n    /**\n     * Decode a name tag payload. Currently returns an empty instance.\n     */\n    static decode() {\n        return Promise.resolve(new NameTagTokenData());\n    }\n    /** @throws Always throws - not implemented. */\n    toJSON() {\n        throw new Error('toJSON method is not implemented.');\n    }\n    /** @throws Always throws - not implemented. */\n    toCBOR() {\n        throw new Error('toCBOR method is not implemented.');\n    }\n}\n//# sourceMappingURL=NameTagTokenData.js.map","import { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { dedent } from '@unicitylabs/commons/lib/util/StringUtils.js';\n/** Current serialization version for tokens. */\nexport const TOKEN_VERSION = '2.0';\n/**\n * In-memory representation of a token including its transaction history.\n */\nexport class Token {\n    state;\n    genesis;\n    _transactions;\n    _nametagTokens;\n    version;\n    /**\n     * Create a new token instance.\n     * @param state Current state of the token including state data and unlock predicate\n     * @param genesis Mint transaction that created this token\n     * @param _transactions History of transactions\n     * @param _nametagTokens List of nametag tokens associated with this token\n     * @param version Serialization version of the token, defaults to {@link TOKEN_VERSION}\n     */\n    constructor(state, genesis, _transactions = [], _nametagTokens = [], version = TOKEN_VERSION) {\n        this.state = state;\n        this.genesis = genesis;\n        this._transactions = _transactions;\n        this._nametagTokens = _nametagTokens;\n        this.version = version;\n        this._nametagTokens = _nametagTokens.slice();\n        this._transactions = _transactions.slice();\n    }\n    get id() {\n        return this.genesis.data.tokenId;\n    }\n    get type() {\n        return this.genesis.data.tokenType;\n    }\n    /**\n     * Token immutable data.\n     */\n    get data() {\n        return this.genesis.data.tokenData;\n    }\n    get coins() {\n        return this.genesis.data.coinData;\n    }\n    /** Nametag tokens associated with this token. */\n    get nametagTokens() {\n        return this._nametagTokens.slice();\n    }\n    /** History of all transactions starting with the mint transaction. */\n    get transactions() {\n        return this._transactions.slice();\n    }\n    /** Serialize this token to JSON. */\n    toJSON() {\n        return {\n            genesis: this.genesis.toJSON(),\n            nametagTokens: [],\n            state: this.state.toJSON(),\n            transactions: this.transactions.map((transaction) => transaction.toJSON()),\n            version: this.version,\n        };\n    }\n    /** Serialize this token to CBOR. */\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            CborEncoder.encodeTextString(this.version),\n            this.genesis.toCBOR(),\n            CborEncoder.encodeArray(this.transactions.map((transaction) => transaction.toCBOR())),\n            this.state.toCBOR(),\n            CborEncoder.encodeArray(this.nametagTokens.map((token) => token.toCBOR())),\n        ]);\n    }\n    /** Convert instance to readable string */\n    toString() {\n        return dedent `\n        Token[${this.version}]:\n          Id: ${this.id.toString()}\n          Type: ${this.type.toString()}\n          Data: \n            ${this.data.toString()}\n          Coins:\n            ${this.coins?.toString() ?? null}\n          State:\n            ${this.state.toString()}\n          Transactions: [\n            ${this.transactions.map((transition) => transition.toString()).join('\\n')}\n          ]\n          Nametag Tokens: [ \n            ${this.nametagTokens.map((token) => token.toString()).join('\\n')}\n          ]\n      `;\n    }\n}\n//# sourceMappingURL=Token.js.map","import { InclusionProofVerificationStatus } from '@unicitylabs/commons/lib/api/InclusionProof.js';\nimport { RequestId } from '@unicitylabs/commons/lib/api/RequestId.js';\nimport { DataHash } from '@unicitylabs/commons/lib/hash/DataHash.js';\nimport { SigningService } from '@unicitylabs/commons/lib/signing/SigningService.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { DirectAddress } from '../address/DirectAddress.js';\nimport { MINTER_SECRET } from '../StateTransitionClient.js';\nimport { PredicateType } from '../predicate/PredicateType.js';\nimport { SplitMintReason } from './fungible/SplitMintReason.js';\n/**\n * Utility for constructing tokens from their serialized form.\n */\nexport class TokenFactory {\n    deserializer;\n    /**\n     * @param deserializer token deserializer to use for parsing tokens from CBOR or JSON\n     */\n    constructor(deserializer) {\n        this.deserializer = deserializer;\n    }\n    /**\n     * Deserialize a token from JSON.\n     *\n     * @param data       Token JSON representation\n     */\n    async create(data) {\n        const token = await this.deserializer.deserialize(data);\n        if (!(await this.verifyMintTransaction(token.genesis))) {\n            throw new Error('Mint transaction verification failed.');\n        }\n        let previousTransaction = token.genesis;\n        for (const transaction of token.transactions) {\n            // TODO: Move address processing to a separate method\n            const expectedRecipient = await DirectAddress.create(transaction.data.sourceState.unlockPredicate.reference);\n            if (expectedRecipient.toJSON() !== previousTransaction.data.recipient) {\n                throw new Error('Recipient address mismatch');\n            }\n            if (!(await previousTransaction.containsData(transaction.data.sourceState.data))) {\n                throw new Error('State data is not part of transaction.');\n            }\n            if (!(await transaction.data.sourceState.unlockPredicate.verify(transaction))) {\n                throw new Error('Predicate verification failed');\n            }\n            previousTransaction = transaction;\n        }\n        if (!(await previousTransaction.containsData(token.state.data))) {\n            throw new Error('State data is not part of transaction.');\n        }\n        const expectedRecipient = await DirectAddress.create(token.state.unlockPredicate.reference);\n        if (expectedRecipient.toJSON() !== previousTransaction.data.recipient) {\n            throw new Error('Recipient address mismatch');\n        }\n        return token;\n    }\n    /**\n     * Verify a mint transaction integrity and validate against public key.\n     * @param transaction Mint transaction\n     * @private\n     */\n    async verifyMintTransaction(transaction) {\n        if (!transaction.inclusionProof.authenticator || !transaction.inclusionProof.transactionHash) {\n            return false;\n        }\n        const signingService = await SigningService.createFromSecret(MINTER_SECRET, transaction.data.tokenId.bytes);\n        if (HexConverter.encode(transaction.inclusionProof.authenticator.publicKey) !==\n            HexConverter.encode(signingService.publicKey) ||\n            !transaction.inclusionProof.authenticator.stateHash.equals(transaction.data.sourceState.hash)) {\n            return false; // input mismatch\n        }\n        // Verify if transaction data is valid.\n        if (!(await transaction.inclusionProof.authenticator.verify(transaction.data.hash))) {\n            return false;\n        }\n        const reason = transaction.data.reason;\n        if (reason instanceof SplitMintReason) {\n            if (transaction.data.coinData == null) {\n                return false;\n            }\n            if (reason.token.state.unlockPredicate.type != PredicateType.BURN) {\n                return false;\n            }\n            if (transaction.data.coinData.size !== reason.proofs.size) {\n                return false;\n            }\n            for (const [coinId, proof] of reason.proofs) {\n                const aggregationPathResult = await proof.aggregationPath.verify(coinId);\n                if (!aggregationPathResult.result) {\n                    return false;\n                }\n                const coinPathResult = await proof.coinTreePath.verify(transaction.data.tokenId.toBigInt());\n                if (!coinPathResult.result) {\n                    return false;\n                }\n                const aggregationPathLeaf = proof.aggregationPath.steps.at(0)?.branch?.value;\n                if (!aggregationPathLeaf || !proof.coinTreePath.root.equals(DataHash.fromImprint(aggregationPathLeaf))) {\n                    return false;\n                }\n                const sumPathLeaf = proof.coinTreePath.steps.at(0)?.branch?.sum;\n                if (transaction.data.coinData?.getByKey(coinId) !== sumPathLeaf) {\n                    return false;\n                }\n                const predicate = reason.token.state.unlockPredicate;\n                if (!proof.aggregationPath.root.equals(predicate.reason)) {\n                    return false;\n                }\n            }\n        }\n        // Verify inclusion proof path.\n        const requestId = await RequestId.create(signingService.publicKey, transaction.data.sourceState.hash);\n        const status = await transaction.inclusionProof.verify(requestId.toBigInt());\n        return status === InclusionProofVerificationStatus.OK;\n    }\n}\n//# sourceMappingURL=TokenFactory.js.map","import { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\n/**\n * Globally unique identifier of a token.\n */\nexport class TokenId {\n    _bytes;\n    /**\n     * @param _bytes Byte representation of the identifier\n     */\n    constructor(_bytes) {\n        this._bytes = _bytes;\n        this._bytes = new Uint8Array(_bytes);\n    }\n    get bytes() {\n        return new Uint8Array(this._bytes);\n    }\n    /** Factory method to wrap a raw identifier. */\n    static create(id) {\n        return new TokenId(id);\n    }\n    /** Encode as a hex string for JSON. */\n    toJSON() {\n        return HexConverter.encode(this._bytes);\n    }\n    /** CBOR serialisation. */\n    toCBOR() {\n        return CborEncoder.encodeByteString(this._bytes);\n    }\n    /** Convert instance to readable string */\n    toString() {\n        return `TokenId[${HexConverter.encode(this._bytes)}]`;\n    }\n    /**\n     * Converts the TokenId to a BigInt representation.\n     */\n    toBigInt() {\n        return BigInt(`0x01${HexConverter.encode(this.toCBOR())}`);\n    }\n}\n//# sourceMappingURL=TokenId.js.map","import { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { DataHasher } from '@unicitylabs/commons/lib/hash/DataHasher.js';\nimport { HashAlgorithm } from '@unicitylabs/commons/lib/hash/HashAlgorithm.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { dedent } from '@unicitylabs/commons/lib/util/StringUtils.js';\n/**\n * Represents a snapshot of token ownership and associated data.\n */\nexport class TokenState {\n    unlockPredicate;\n    _data;\n    hash;\n    /**\n     * @param unlockPredicate Predicate controlling future transfers\n     * @param _data           Optional encrypted state data\n     * @param hash            Hash of predicate and data\n     */\n    constructor(unlockPredicate, _data, hash) {\n        this.unlockPredicate = unlockPredicate;\n        this._data = _data;\n        this.hash = hash;\n        this._data = _data ? new Uint8Array(_data) : null;\n    }\n    /** Copy of the stored state data. */\n    get data() {\n        return this._data ? new Uint8Array(this._data) : null;\n    }\n    /** Hash algorithm used for the state hash. */\n    get hashAlgorithm() {\n        return this.hash.algorithm;\n    }\n    /**\n     * Compute a new token state from predicate and optional data.\n     */\n    static async create(unlockPredicate, data) {\n        return new TokenState(unlockPredicate, data, await new DataHasher(HashAlgorithm.SHA256)\n            .update(CborEncoder.encodeArray([\n            unlockPredicate.hash.toCBOR(),\n            CborEncoder.encodeOptional(data, CborEncoder.encodeByteString),\n        ]))\n            .digest());\n    }\n    /** Serialize the state to JSON. */\n    toJSON() {\n        return {\n            data: this._data ? HexConverter.encode(this._data) : null,\n            unlockPredicate: this.unlockPredicate.toJSON(),\n        };\n    }\n    /** Encode the state as CBOR. */\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            this.unlockPredicate.toCBOR(),\n            CborEncoder.encodeOptional(this._data, CborEncoder.encodeByteString),\n        ]);\n    }\n    /** Convert instance to readable string */\n    toString() {\n        return dedent `\n        TokenState:\n          ${this.unlockPredicate.toString()}\n          Data: ${this._data ? HexConverter.encode(this._data) : null}\n          Hash: ${this.hash.toString()}`;\n    }\n}\n//# sourceMappingURL=TokenState.js.map","import { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\n/** Unique identifier describing the type/category of a token. */\nexport class TokenType {\n    _bytes;\n    /**\n     * @param _bytes Byte representation of the token type\n     */\n    constructor(_bytes) {\n        this._bytes = _bytes;\n        this._bytes = new Uint8Array(_bytes);\n    }\n    get bytes() {\n        return new Uint8Array(this._bytes);\n    }\n    /** Create an instance from raw bytes. */\n    static create(id) {\n        return new TokenType(id);\n    }\n    /** Hex representation for JSON serialization. */\n    toJSON() {\n        return HexConverter.encode(this._bytes);\n    }\n    /** CBOR serialization. */\n    toCBOR() {\n        return CborEncoder.encodeByteString(this._bytes);\n    }\n    /** Convert instance to readable string */\n    toString() {\n        return `TokenType[${HexConverter.encode(this._bytes)}]`;\n    }\n}\n//# sourceMappingURL=TokenType.js.map","import { CborDecoder } from '@unicitylabs/commons/lib/cbor/CborDecoder.js';\nimport { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\n/** Identifier for a fungible coin type. */\nexport class CoinId {\n    data;\n    /**\n     * @param data Raw byte representation\n     */\n    constructor(data) {\n        this.data = data;\n        this.data = new Uint8Array(data);\n    }\n    /**\n     * Creates a new CoinId from raw bytes.\n     * @param data Raw byte representation\n     */\n    static fromJSON(data) {\n        return new CoinId(HexConverter.decode(data));\n    }\n    /**\n     * Creates a CoinId from a byte array encoded in CBOR.\n     * @param data\n     */\n    static fromCBOR(data) {\n        return new CoinId(CborDecoder.readByteString(data));\n    }\n    /**\n     * Creates a CoinId from a bigint.\n     * @param value bigint represantation of coin id\n     */\n    static fromBigInt(value) {\n        return CoinId.fromCBOR(HexConverter.decode(value.toString(16).slice(1)));\n    }\n    /** Hex string representation. */\n    toJSON() {\n        return HexConverter.encode(this.data);\n    }\n    /** CBOR serialization. */\n    toCBOR() {\n        return CborEncoder.encodeByteString(this.data);\n    }\n    /**\n     * Converts the CoinId to a BigInt representation.\n     */\n    toBigInt() {\n        return BigInt(`0x01${HexConverter.encode(this.toCBOR())}`);\n    }\n}\n//# sourceMappingURL=CoinId.js.map","import { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { BigintConverter } from '@unicitylabs/commons/lib/util/BigintConverter.js';\nimport { MintReasonType } from '../../transaction/MintReasonType.js';\nexport class SplitMintReason {\n    token;\n    _proofs;\n    constructor(token, _proofs) {\n        this.token = token;\n        this._proofs = _proofs;\n        this._proofs = new Map(_proofs);\n    }\n    get proofs() {\n        return new Map(this._proofs);\n    }\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            this.token.toCBOR(),\n            CborEncoder.encodeArray(Array.from(this._proofs.entries()).map(([coinId, proof]) => CborEncoder.encodeArray([CborEncoder.encodeByteString(BigintConverter.encode(coinId)), proof.toCBOR()]))),\n        ]);\n    }\n    toJSON() {\n        return {\n            proofs: Array.from(this._proofs).map(([coinId, proof]) => [coinId.toString(), proof.toJSON()]),\n            token: this.token.toJSON(),\n            type: MintReasonType.TOKEN_SPLIT,\n        };\n    }\n}\n//# sourceMappingURL=SplitMintReason.js.map","import { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nexport class SplitMintReasonProof {\n    aggregationPath;\n    coinTreePath;\n    constructor(aggregationPath, coinTreePath) {\n        this.aggregationPath = aggregationPath;\n        this.coinTreePath = coinTreePath;\n    }\n    toJSON() {\n        return {\n            aggregationPath: this.aggregationPath.toJSON(),\n            coinTreePath: this.coinTreePath.toJSON(),\n        };\n    }\n    toCBOR() {\n        return CborEncoder.encodeArray([this.aggregationPath.toCBOR(), this.coinTreePath.toCBOR()]);\n    }\n}\n//# sourceMappingURL=SplitMintReasonProof.js.map","import { CborDecoder } from '@unicitylabs/commons/lib/cbor/CborDecoder.js';\nimport { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { BigintConverter } from '@unicitylabs/commons/lib/util/BigintConverter.js';\nimport { dedent } from '@unicitylabs/commons/lib/util/StringUtils.js';\nimport { CoinId } from './CoinId.js';\n/**\n * Container for fungible coin balances attached to a token.\n */\nexport class TokenCoinData {\n    _coins;\n    /**\n     * @param coins Array of coin id and balance pairs\n     */\n    constructor(coins) {\n        this._coins = new Map(coins);\n    }\n    /** Get total number of different coins */\n    get size() {\n        return this._coins.size;\n    }\n    get coins() {\n        return new Map(Array.from(this._coins.entries()).map(([key, value]) => [CoinId.fromBigInt(key), value]));\n    }\n    static create(coins) {\n        return new TokenCoinData(coins.map(([key, value]) => [key.toBigInt(), value]));\n    }\n    /** Create a coin data object from CBOR. */\n    static fromCBOR(data) {\n        const coins = [];\n        const entries = CborDecoder.readArray(data);\n        for (const item of entries) {\n            const [key, value] = CborDecoder.readArray(item);\n            coins.push([\n                BigintConverter.decode(CborDecoder.readByteString(key)),\n                BigintConverter.decode(CborDecoder.readByteString(value)),\n            ]);\n        }\n        return new TokenCoinData(coins);\n    }\n    /** Parse from a JSON representation. */\n    static fromJSON(data) {\n        if (!Array.isArray(data)) {\n            throw new Error('Invalid coin data JSON format');\n        }\n        const coins = [];\n        // Helper function to safely parse values that might have been corrupted by JSON.stringify()\n        const parseValue = (v) => {\n            if (typeof v === 'bigint')\n                return v;\n            if (typeof v === 'string' || typeof v === 'number')\n                return BigInt(v);\n            if (v === null) {\n                throw new Error(`Cannot convert null to BigInt. This indicates a JSON serialization issue with BigInt values.`);\n            }\n            if (typeof v === 'object') {\n                throw new Error(`Cannot convert object to BigInt. This indicates a JSON serialization issue with BigInt values. Received: ${JSON.stringify(v)}`);\n            }\n            throw new Error(`Unsupported type for BigInt conversion: ${typeof v}. Expected string, number, or bigint.`);\n        };\n        for (const [key, value] of data) {\n            coins.push([parseValue(key), parseValue(value)]);\n        }\n        return new TokenCoinData(coins);\n    }\n    /** Get the balance of a specific coin. */\n    get(coinId) {\n        return this._coins.get(coinId.toBigInt());\n    }\n    /** Get the balance of a coin by its internal map key. */\n    getByKey(coinId) {\n        return this._coins.get(coinId);\n    }\n    /** @inheritDoc */\n    toCBOR() {\n        return CborEncoder.encodeArray(Array.from(this._coins.entries()).map(([key, value]) => CborEncoder.encodeArray([\n            CborEncoder.encodeByteString(BigintConverter.encode(key)),\n            CborEncoder.encodeByteString(BigintConverter.encode(value)),\n        ])));\n    }\n    /** @inheritDoc */\n    toJSON() {\n        return Array.from(this._coins.entries()).map(([key, value]) => [key.toString(), value.toString()]);\n    }\n    /** Convert instance to readable string */\n    toString() {\n        return dedent `\n      FungibleTokenData\n        ${Array.from(this._coins.entries())\n            .map(([key, value]) => `${key}: ${value}`)\n            .join('\\n')}`;\n    }\n}\n//# sourceMappingURL=TokenCoinData.js.map","/**\n * Result returned when submitting a transaction to the aggregator.\n */\nexport class Commitment {\n    requestId;\n    transactionData;\n    authenticator;\n    _brand = 'Commitment';\n    /**\n     * @param requestId       Request identifier used for submission\n     * @param transactionData Submitted transaction data\n     * @param authenticator   Signature over the payload\n     */\n    constructor(requestId, transactionData, authenticator) {\n        this.requestId = requestId;\n        this.transactionData = transactionData;\n        this.authenticator = authenticator;\n    }\n}\n//# sourceMappingURL=Commitment.js.map","export var MintReasonType;\n(function (MintReasonType) {\n    MintReasonType[\"TOKEN_SPLIT\"] = \"TOKEN_SPLIT\";\n})(MintReasonType || (MintReasonType = {}));\n//# sourceMappingURL=MintReasonType.js.map","import { RequestId } from '@unicitylabs/commons/lib/api/RequestId.js';\nimport { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { DataHasher } from '@unicitylabs/commons/lib/hash/DataHasher.js';\nimport { HashAlgorithm } from '@unicitylabs/commons/lib/hash/HashAlgorithm.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { dedent } from '@unicitylabs/commons/lib/util/StringUtils.js';\n// TOKENID string SHA-256 hash\n/**\n * Constant suffix used when deriving the mint initial state.\n */\nconst MINT_SUFFIX = HexConverter.decode('9e82002c144d7c5796c50f6db50a0c7bbd7f717ae3af6c6c71a3e9eba3022730');\n/**\n * Data object describing a token mint operation.\n */\nexport class MintTransactionData {\n    hash;\n    tokenId;\n    tokenType;\n    _tokenData;\n    coinData;\n    sourceState;\n    recipient;\n    _salt;\n    dataHash;\n    reason;\n    /**\n     * @param hash        Hash of the encoded transaction\n     * @param tokenId     Token identifier\n     * @param tokenType   Token type identifier\n     * @param _tokenData  Immutable token data used for the mint\n     * @param coinData    Fungible coin data, or null if none\n     * @param sourceState Pseudo input state used for the mint\n     * @param recipient   Address of the first owner\n     * @param _salt       Random salt used to derive predicates\n     * @param dataHash    Optional metadata hash\n     * @param reason      Optional reason object\n     */\n    constructor(hash, tokenId, tokenType, _tokenData, coinData, sourceState, recipient, _salt, dataHash, reason) {\n        this.hash = hash;\n        this.tokenId = tokenId;\n        this.tokenType = tokenType;\n        this._tokenData = _tokenData;\n        this.coinData = coinData;\n        this.sourceState = sourceState;\n        this.recipient = recipient;\n        this._salt = _salt;\n        this.dataHash = dataHash;\n        this.reason = reason;\n        this._tokenData = new Uint8Array(_tokenData);\n        this._salt = new Uint8Array(_salt);\n    }\n    /** Immutable token data used for the mint. */\n    get tokenData() {\n        return new Uint8Array(this._tokenData);\n    }\n    /** Salt used during predicate creation. */\n    get salt() {\n        return new Uint8Array(this._salt);\n    }\n    /** Hash algorithm of the transaction hash. */\n    get hashAlgorithm() {\n        return this.hash.algorithm;\n    }\n    /**\n     * Create a new mint transaction data object.\n     * @param tokenId Token identifier\n     * @param tokenType Token type identifier\n     * @param tokenData Token data object\n     * @param coinData Fungible coin data, or null if none\n     * @param recipient Address of the first token owner\n     * @param salt User selected salt\n     * @param dataHash Hash pointing to next state data\n     * @param reason Reason object attached to the mint\n     */\n    static async create(tokenId, tokenType, tokenData, coinData, recipient, salt, dataHash, reason) {\n        const sourceState = await RequestId.createFromImprint(tokenId.bytes, MINT_SUFFIX);\n        const tokenDataHash = await new DataHasher(HashAlgorithm.SHA256).update(tokenData).digest();\n        return new MintTransactionData(await new DataHasher(HashAlgorithm.SHA256)\n            .update(CborEncoder.encodeArray([\n            tokenId.toCBOR(),\n            tokenType.toCBOR(),\n            tokenDataHash.toCBOR(),\n            dataHash?.toCBOR() ?? CborEncoder.encodeNull(),\n            coinData?.toCBOR() ?? CborEncoder.encodeNull(),\n            CborEncoder.encodeTextString(recipient),\n            CborEncoder.encodeByteString(salt),\n            reason?.toCBOR() ?? CborEncoder.encodeNull(),\n        ]))\n            .digest(), tokenId, tokenType, tokenData, coinData, sourceState, recipient, salt, dataHash, reason);\n    }\n    /** Serialize this object to JSON object. */\n    toJSON() {\n        return {\n            coins: this.coinData?.toJSON() ?? null,\n            dataHash: this.dataHash?.toJSON() ?? null,\n            reason: this.reason?.toJSON() ?? null,\n            recipient: this.recipient,\n            salt: HexConverter.encode(this._salt),\n            tokenData: HexConverter.encode(this._tokenData),\n            tokenId: this.tokenId.toJSON(),\n            tokenType: this.tokenType.toJSON(),\n        };\n    }\n    /** Serialize this object to CBOR. */\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            this.tokenId.toCBOR(),\n            this.tokenType.toCBOR(),\n            CborEncoder.encodeByteString(this._tokenData),\n            this.coinData?.toCBOR() ?? CborEncoder.encodeNull(),\n            CborEncoder.encodeTextString(this.recipient),\n            CborEncoder.encodeByteString(this._salt),\n            this.dataHash?.toCBOR() ?? CborEncoder.encodeNull(),\n            this.reason?.toCBOR() ?? CborEncoder.encodeNull(),\n        ]);\n    }\n    /** Convert instance to readable string */\n    toString() {\n        return dedent `\n      MintTransactionData:\n        Token ID: ${this.tokenId.toString()}\n        Token Type: ${this.tokenType.toString()}\n        Token Data: ${HexConverter.encode(this._tokenData)}\n        Coins: ${this.coinData?.toString() ?? null}\n        Recipient: ${this.recipient}\n        Salt: ${HexConverter.encode(this.salt)}\n        Data: ${this.dataHash?.toString() ?? null}\n        Reason: ${this.reason?.toString() ?? null}\n        Hash: ${this.hash.toString()}`;\n    }\n}\n//# sourceMappingURL=MintTransactionData.js.map","/**\n * Result returned when submitting a transaction to the aggregator.\n */\nexport class OfflineCommitment {\n    requestId;\n    transactionData;\n    authenticator;\n    _brand = 'OfflineCommitment';\n    /**\n     * @param requestId       Request identifier used for submission\n     * @param transactionData Submitted transaction data\n     * @param authenticator   Signature over the payload\n     */\n    constructor(requestId, transactionData, authenticator) {\n        this.requestId = requestId;\n        this.transactionData = transactionData;\n        this.authenticator = authenticator;\n    }\n}\n//# sourceMappingURL=OfflineCommitment.js.map","import { Authenticator } from '@unicitylabs/commons/lib/api/Authenticator.js';\nimport { RequestId } from '@unicitylabs/commons/lib/api/RequestId.js';\nimport { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { DataHash } from '@unicitylabs/commons/lib/hash/DataHash.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { OfflineCommitment } from './OfflineCommitment.js';\nimport { TransactionData } from './TransactionData.js';\nimport { PredicateJsonFactory } from '../predicate/PredicateJsonFactory.js';\nimport { TokenJsonDeserializer } from '../serializer/token/TokenJsonDeserializer.js';\nimport { TokenFactory } from '../token/TokenFactory.js';\nimport { TokenState } from '../token/TokenState.js';\nimport { JsonUtils } from '../utils/JsonUtils.js';\n/**\n * Represents a transaction with its commitment for offline processing.\n */\nexport class OfflineTransaction {\n    commitment;\n    token;\n    /**\n     * @param commitment  The commitment for the transaction\n     * @param token\n     */\n    constructor(commitment, token) {\n        this.commitment = commitment;\n        this.token = token;\n    }\n    /**\n     * Create OfflineTransaction from JSON data.\n     * This properly deserializes all components using the necessary factories.\n     * @param data JSON data\n     */\n    static async fromJSON(data) {\n        if (!OfflineTransaction.isJSON(data)) {\n            throw new Error('Invalid offline transaction JSON format');\n        }\n        // Initialize the necessary factories\n        const predicateFactory = new PredicateJsonFactory();\n        const tokenFactory = new TokenFactory(new TokenJsonDeserializer(predicateFactory));\n        // Deserialize the token from JSON\n        const token = await tokenFactory.create(data.token);\n        // Reconstruct the commitment components\n        const requestId = RequestId.fromJSON(data.commitment.requestId);\n        const authenticator = Authenticator.fromJSON(data.commitment.authenticator);\n        // Reconstruct the transaction data\n        const txData = data.commitment.transactionData;\n        const transactionData = await TransactionData.create(await TokenState.create(await predicateFactory.create(token.id, token.type, txData.sourceState.unlockPredicate), txData.sourceState.data ? HexConverter.decode(txData.sourceState.data) : null), txData.recipient, HexConverter.decode(txData.salt), txData.dataHash ? DataHash.fromJSON(txData.dataHash) : null, txData.message ? HexConverter.decode(txData.message) : null, []);\n        // Create the OfflineCommitment\n        const offlineCommitment = new OfflineCommitment(requestId, transactionData, authenticator);\n        return new OfflineTransaction(offlineCommitment, token);\n    }\n    /**\n     * Create OfflineTransaction from JSON string.\n     * This method can handle JSON strings that were created with toJSONString().\n     *\n     * @param jsonString JSON string representation\n     * @returns Promise<OfflineTransaction>\n     */\n    static fromJSONString(jsonString) {\n        const parsed = JsonUtils.parse(jsonString);\n        return OfflineTransaction.fromJSON(parsed);\n    }\n    /**\n     * Type guard to check if data is valid OfflineTransaction JSON.\n     * @param data Data to validate\n     */\n    static isJSON(data) {\n        return (typeof data === 'object' &&\n            data !== null &&\n            'commitment' in data &&\n            'token' in data &&\n            typeof data.commitment === 'object' &&\n            typeof data.token === 'object');\n    }\n    /** Serialize to CBOR format */\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            CborEncoder.encodeArray([\n                this.commitment.requestId.toCBOR(),\n                this.commitment.transactionData.toCBOR(),\n                this.commitment.authenticator.toCBOR(),\n            ]),\n            this.token.toCBOR(),\n        ]);\n    }\n    /** Serialize to JSON format */\n    toJSON() {\n        return {\n            commitment: {\n                authenticator: this.commitment.authenticator.toJSON(),\n                requestId: this.commitment.requestId.toJSON(),\n                transactionData: this.commitment.transactionData.toJSON(),\n            },\n            token: this.token.toJSON(),\n        };\n    }\n    /**\n     * Serialize to JSON string with BigInt support.\n     * This method handles potential BigInt values that might exist in the object graph\n     * and converts them to strings to prevent JSON serialization errors.\n     *\n     * Use this method when you need to serialize for actual transfer (e.g., NFC, file, etc.).\n     *\n     * @param space Optional spacing for formatting\n     * @returns JSON string with BigInt values safely converted\n     */\n    toJSONString(space) {\n        return JsonUtils.safeStringify(this, space);\n    }\n}\n//# sourceMappingURL=OfflineTransaction.js.map","import { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { DataHasher } from '@unicitylabs/commons/lib/hash/DataHasher.js';\nimport { dedent } from '@unicitylabs/commons/lib/util/StringUtils.js';\n/**\n * A transaction along with its verified inclusion proof.\n */\nexport class Transaction {\n    data;\n    inclusionProof;\n    /**\n     * @param data           Transaction data payload\n     * @param inclusionProof Proof of inclusion in the ledger\n     */\n    constructor(data, inclusionProof) {\n        this.data = data;\n        this.inclusionProof = inclusionProof;\n    }\n    /** Serialize transaction and proof to JSON. */\n    toJSON() {\n        return {\n            data: this.data.toJSON(),\n            inclusionProof: this.inclusionProof.toJSON(),\n        };\n    }\n    /** Serialize transaction and proof to CBOR. */\n    toCBOR() {\n        return CborEncoder.encodeArray([this.data.toCBOR(), this.inclusionProof.toCBOR()]);\n    }\n    /**\n     * Verify if the provided data matches the optional data hash.\n     * @param data Data to verify against the transaction's data hash\n     */\n    async containsData(data) {\n        if (this.data.dataHash) {\n            if (!data) {\n                return false;\n            }\n            const dataHash = await new DataHasher(this.data.dataHash.algorithm).update(data).digest();\n            return dataHash.equals(this.data.dataHash);\n        }\n        return !data;\n    }\n    /** Convert instance to readable string */\n    toString() {\n        return dedent `\n        Transaction:\n          ${this.data.toString()}\n          ${this.inclusionProof.toString()}`;\n    }\n}\n//# sourceMappingURL=Transaction.js.map","import { CborEncoder } from '@unicitylabs/commons/lib/cbor/CborEncoder.js';\nimport { DataHasher } from '@unicitylabs/commons/lib/hash/DataHasher.js';\nimport { HashAlgorithm } from '@unicitylabs/commons/lib/hash/HashAlgorithm.js';\nimport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\nimport { dedent } from '@unicitylabs/commons/lib/util/StringUtils.js';\n/**\n * Data describing a standard token transfer.\n */\nexport class TransactionData {\n    hash;\n    sourceState;\n    recipient;\n    salt;\n    dataHash;\n    _message;\n    nameTags;\n    /**\n     * @param hash        Hash of the encoded data\n     * @param sourceState Previous token state\n     * @param recipient   Address of the new owner\n     * @param salt        Salt used in the new predicate\n     * @param dataHash    Optional additional data hash\n     * @param _message    Optional message bytes\n     * @param nameTags    Optional name tag tokens\n     */\n    constructor(hash, sourceState, recipient, salt, dataHash, _message, nameTags = []) {\n        this.hash = hash;\n        this.sourceState = sourceState;\n        this.recipient = recipient;\n        this.salt = salt;\n        this.dataHash = dataHash;\n        this._message = _message;\n        this.nameTags = nameTags;\n        this._message = _message ? new Uint8Array(_message) : null;\n        this.nameTags = Array.from(nameTags);\n    }\n    /** Optional message attached to the transfer. */\n    get message() {\n        return this._message ? new Uint8Array(this._message) : null;\n    }\n    /** Hash algorithm for the data hash. */\n    get hashAlgorithm() {\n        return this.hash.algorithm;\n    }\n    /**\n     * Create a new transaction data object.\n     * @param state Token state used as source for the transfer\n     * @param recipient Address of the new token owner\n     * @param salt Random salt\n     * @param dataHash Hash of new token owners data\n     * @param message Message bytes\n     * @param nameTags\n     */\n    static async create(state, recipient, salt, dataHash, message, nameTags = []) {\n        return new TransactionData(await new DataHasher(HashAlgorithm.SHA256)\n            .update(CborEncoder.encodeArray([\n            state.hash.toCBOR(),\n            dataHash?.toCBOR() ?? CborEncoder.encodeNull(),\n            CborEncoder.encodeTextString(recipient),\n            CborEncoder.encodeByteString(salt),\n            CborEncoder.encodeOptional(message, CborEncoder.encodeByteString),\n        ]))\n            .digest(), state, recipient, salt, dataHash, message, nameTags);\n    }\n    /** Serialize this token to JSON. */\n    toJSON() {\n        return {\n            dataHash: this.dataHash?.toJSON() ?? null,\n            message: this._message ? HexConverter.encode(this._message) : null,\n            nameTags: this.nameTags.map((token) => token.toJSON()),\n            recipient: this.recipient,\n            salt: HexConverter.encode(this.salt),\n            sourceState: this.sourceState.toJSON(),\n        };\n    }\n    /** Serialize this token to CBOR. */\n    toCBOR() {\n        return CborEncoder.encodeArray([\n            this.sourceState.toCBOR(),\n            CborEncoder.encodeTextString(this.recipient),\n            CborEncoder.encodeByteString(this.salt),\n            this.dataHash?.toCBOR() ?? CborEncoder.encodeNull(),\n            this._message ? CborEncoder.encodeByteString(this._message) : CborEncoder.encodeNull(),\n            CborEncoder.encodeArray(this.nameTags.map((token) => token.toCBOR())),\n        ]);\n    }\n    /** Convert instance to readable string */\n    toString() {\n        return dedent `\n      TransactionData:\n        ${this.sourceState.toString()}\n        Recipient: ${this.recipient.toString()}\n        Salt: ${HexConverter.encode(this.salt)}\n        Data: ${this.dataHash?.toString() ?? null}\n        Message: ${this._message ? HexConverter.encode(this._message) : null}\n        NameTags: [\n          ${this.nameTags.map((token) => token.toString()).join('\\n')}\n        ]\n        Hash: ${this.hash.toString()}`;\n    }\n}\n//# sourceMappingURL=TransactionData.js.map","import { InclusionProofVerificationStatus } from '@unicitylabs/commons/lib/api/InclusionProof.js';\nimport { JsonRpcNetworkError } from '@unicitylabs/commons/lib/json-rpc/JsonRpcNetworkError.js';\nclass SleepError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = 'SleepError';\n    }\n}\nfunction sleep(ms, signal) {\n    return new Promise((resolve, reject) => {\n        const timeout = setTimeout(resolve, ms);\n        signal.addEventListener('abort', () => {\n            clearTimeout(timeout);\n            reject(signal.reason);\n        }, { once: true });\n    });\n}\nexport async function waitInclusionProof(client, commitment, signal = AbortSignal.timeout(10000), interval = 1000) {\n    while (true) {\n        try {\n            const inclusionProof = await client.getInclusionProof(commitment);\n            if ((await inclusionProof.verify(commitment.requestId.toBigInt())) === InclusionProofVerificationStatus.OK) {\n                return inclusionProof;\n            }\n        }\n        catch (err) {\n            if (!(err instanceof JsonRpcNetworkError && err.status === 404)) {\n                throw err;\n            }\n        }\n        try {\n            await sleep(interval, signal);\n        }\n        catch (err) {\n            throw new SleepError(String(err || 'Sleep was aborted'));\n        }\n    }\n}\n//# sourceMappingURL=InclusionProofUtils.js.map","/**\n * Utility functions for JSON serialization with BigInt support.\n */\nexport class JsonUtils {\n    /**\n     * JSON.stringify with BigInt support.\n     * Converts BigInt values to strings automatically.\n     *\n     * @param value The value to stringify\n     * @param space Optional spacing for formatting\n     * @returns JSON string with BigInt values converted to strings\n     */\n    static stringify(value, space) {\n        return JSON.stringify(value, (key, val) => {\n            if (typeof val === 'bigint') {\n                return val.toString();\n            }\n            return val;\n        }, space);\n    }\n    /**\n     * JSON.parse that can handle BigInt values that were stringified.\n     * This is a basic parser - for complex BigInt restoration,\n     * use the specific fromJSON methods of each class.\n     *\n     * @param text The JSON string to parse\n     * @returns Parsed object\n     */\n    static parse(text) {\n        return JSON.parse(text);\n    }\n    /**\n     * Safe serialization for objects that might contain BigInt values.\n     * First calls toJSON() if available, then applies BigInt-safe stringify.\n     *\n     * @param obj Object to serialize\n     * @param space Optional spacing for formatting\n     * @returns JSON string\n     */\n    static safeStringify(obj, space) {\n        // If object has toJSON method, use it first\n        if (obj && typeof obj === 'object' && 'toJSON' in obj && typeof obj.toJSON === 'function') {\n            const jsonObj = obj.toJSON();\n            return JsonUtils.stringify(jsonObj, space);\n        }\n        // Otherwise use BigInt-safe stringify directly\n        return JsonUtils.stringify(obj, space);\n    }\n}\n//# sourceMappingURL=JsonUtils.js.map","const randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);\nexport default { randomUUID };\n","export default /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-8][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000|ffffffff-ffff-ffff-ffff-ffffffffffff)$/i;\n","let getRandomValues;\nconst rnds8 = new Uint8Array(16);\nexport default function rng() {\n    if (!getRandomValues) {\n        if (typeof crypto === 'undefined' || !crypto.getRandomValues) {\n            throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');\n        }\n        getRandomValues = crypto.getRandomValues.bind(crypto);\n    }\n    return getRandomValues(rnds8);\n}\n","import validate from './validate.js';\nconst byteToHex = [];\nfor (let i = 0; i < 256; ++i) {\n    byteToHex.push((i + 0x100).toString(16).slice(1));\n}\nexport function unsafeStringify(arr, offset = 0) {\n    return (byteToHex[arr[offset + 0]] +\n        byteToHex[arr[offset + 1]] +\n        byteToHex[arr[offset + 2]] +\n        byteToHex[arr[offset + 3]] +\n        '-' +\n        byteToHex[arr[offset + 4]] +\n        byteToHex[arr[offset + 5]] +\n        '-' +\n        byteToHex[arr[offset + 6]] +\n        byteToHex[arr[offset + 7]] +\n        '-' +\n        byteToHex[arr[offset + 8]] +\n        byteToHex[arr[offset + 9]] +\n        '-' +\n        byteToHex[arr[offset + 10]] +\n        byteToHex[arr[offset + 11]] +\n        byteToHex[arr[offset + 12]] +\n        byteToHex[arr[offset + 13]] +\n        byteToHex[arr[offset + 14]] +\n        byteToHex[arr[offset + 15]]).toLowerCase();\n}\nfunction stringify(arr, offset = 0) {\n    const uuid = unsafeStringify(arr, offset);\n    if (!validate(uuid)) {\n        throw TypeError('Stringified UUID is invalid');\n    }\n    return uuid;\n}\nexport default stringify;\n","import native from './native.js';\nimport rng from './rng.js';\nimport { unsafeStringify } from './stringify.js';\nfunction v4(options, buf, offset) {\n    if (native.randomUUID && !buf && !options) {\n        return native.randomUUID();\n    }\n    options = options || {};\n    const rnds = options.random ?? options.rng?.() ?? rng();\n    if (rnds.length < 16) {\n        throw new Error('Random bytes length must be >= 16');\n    }\n    rnds[6] = (rnds[6] & 0x0f) | 0x40;\n    rnds[8] = (rnds[8] & 0x3f) | 0x80;\n    if (buf) {\n        offset = offset || 0;\n        if (offset < 0 || offset + 16 > buf.length) {\n            throw new RangeError(`UUID byte range ${offset}:${offset + 15} is out of buffer bounds`);\n        }\n        for (let i = 0; i < 16; ++i) {\n            buf[offset + i] = rnds[i];\n        }\n        return buf;\n    }\n    return unsafeStringify(rnds);\n}\nexport default v4;\n","import REGEX from './regex.js';\nfunction validate(uuid) {\n    return typeof uuid === 'string' && REGEX.test(uuid);\n}\nexport default validate;\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","export * from '@unicitylabs/state-transition-sdk';\n// Explicitly export offline classes that might not be in the main export\nexport { OfflineStateTransitionClient } from '@unicitylabs/state-transition-sdk/lib/OfflineStateTransitionClient.js';\nexport { OfflineCommitment } from '@unicitylabs/state-transition-sdk/lib/transaction/OfflineCommitment.js';\nexport { OfflineTransaction } from '@unicitylabs/state-transition-sdk/lib/transaction/OfflineTransaction.js';\n// Explicitly export transaction classes\nexport { MintTransactionData } from '@unicitylabs/state-transition-sdk/lib/transaction/MintTransactionData.js';\n// Explicitly export deserializer classes\nexport { TokenJsonDeserializer } from '@unicitylabs/state-transition-sdk/lib/serializer/token/TokenJsonDeserializer.js';\n// export * from './ISerializable.js';\n// export * from './StateTransitionClient.js';\n// export * from './hash/createDefaultDataHasherFactory.js';\n// Commons exports - Signing\nexport { SigningService } from '@unicitylabs/commons/lib/signing/SigningService.js';\nexport { Signature } from '@unicitylabs/commons/lib/signing/Signature.js';\n// Commons exports - Hashing\nexport { HashAlgorithm } from '@unicitylabs/commons/lib/hash/HashAlgorithm.js';\nexport { DataHasher } from '@unicitylabs/commons/lib/hash/DataHasher.js';\nexport { DataHash } from '@unicitylabs/commons/lib/hash/DataHash.js';\n// Commons exports - Utilities\nexport { HexConverter } from '@unicitylabs/commons/lib/util/HexConverter.js';\n// Commons exports - API/Inclusion Proof\nexport { InclusionProof, InclusionProofVerificationStatus } from '@unicitylabs/commons/lib/api/InclusionProof.js';\nexport { RequestId } from '@unicitylabs/commons/lib/api/RequestId.js';\nexport { Authenticator } from '@unicitylabs/commons/lib/api/Authenticator.js';\nexport { SubmitCommitmentRequest } from '@unicitylabs/commons/lib/api/SubmitCommitmentRequest.js';\nexport { SubmitCommitmentResponse, SubmitCommitmentStatus } from '@unicitylabs/commons/lib/api/SubmitCommitmentResponse.js';\n"],"names":[],"sourceRoot":""}